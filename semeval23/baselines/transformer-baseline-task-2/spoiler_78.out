Thu Aug  3 14:38:59 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.60.13    Driver Version: 525.60.13    CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100 80G...  On   | 00000000:41:00.0 Off |                    0 |
| N/A   42C    P0    45W / 300W |      0MiB / 81920MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
08/03/2023 14:39:06 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False
08/03/2023 14:39:06 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=True,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=../../results/deberta-v3-large-squad2/runs/Aug03_14-39-05_gpu-pr1-02,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=steps,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=3.0,
optim=adamw_torch,
optim_args=None,
output_dir=../../results/deberta-v3-large-squad2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['tensorboard', 'wandb'],
resume_from_checkpoint=None,
run_name=../../results/deberta-v3-large-squad2,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=steps,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
[INFO|configuration_utils.py:713] 2023-08-03 14:39:06,393 >> loading configuration file ../../output/deberta-v3-large-squad2/checkpoint-1000/config.json
[INFO|configuration_utils.py:771] 2023-08-03 14:39:06,400 >> Model config DebertaV2Config {
  "_name_or_path": "../../output/deberta-v3-large-squad2/checkpoint-1000",
  "architectures": [
    "DebertaV2ForQuestionAnswering"
  ],
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "language": "english",
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "name": "DebertaV2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 1024,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "summary_activation": "tanh",
  "summary_last_dropout": 0,
  "summary_type": "first",
  "summary_use_proj": false,
  "torch_dtype": "float32",
  "transformers_version": "4.32.0.dev0",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

[INFO|tokenization_utils_base.py:1842] 2023-08-03 14:39:06,403 >> loading file spm.model
[INFO|tokenization_utils_base.py:1842] 2023-08-03 14:39:06,403 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:1842] 2023-08-03 14:39:06,403 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:1842] 2023-08-03 14:39:06,403 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:1842] 2023-08-03 14:39:06,403 >> loading file tokenizer_config.json
[INFO|modeling_utils.py:2635] 2023-08-03 14:39:06,670 >> loading weights file ../../output/deberta-v3-large-squad2/checkpoint-1000/pytorch_model.bin
[INFO|modeling_utils.py:3370] 2023-08-03 14:39:09,940 >> All model checkpoint weights were used when initializing DebertaV2ForQuestionAnswering.

[INFO|modeling_utils.py:3378] 2023-08-03 14:39:09,940 >> All the weights of DebertaV2ForQuestionAnswering were initialized from the model checkpoint at ../../output/deberta-v3-large-squad2/checkpoint-1000.
If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForQuestionAnswering for predictions without further training.
{'id': 10, 'title': 'This may be the most brutal number in the CBO report', 'question': 'Analysis: This may be the most brutal number in the CBO report', 'context': 'This may be the most brutal number in the CBO report - Plenty has been made of the big Congressional Budget Office finding that 24 million people could lose their insurance under Republicans\' Obamacare replacement over the next decade. That\'s higher than expected and poses a clear and massive hurdle for Republicans as they attempt to convince dozens of skeptical members. But there\'s another number that paints a particularly dire picture for the GOP\'s alternative — especially in light of President Trump\'s populist rhetoric. According to the CBO, 64-year olds making $26,500 per year would see their premiums increase by an estimated 750 percent by 2026. While they are on track to pay $1,700 under the current law, the CBO projects the American Health Care Act would force them to pay $14,600. Even if you grant that inflation will allow them to make slightly more money by 2026, that\'s still about half of their income going to health care. Here\'s how that looks as a percentage of income (h/t Philip Bump): As skeptics of the law noted, that suggests the reason premiums as a whole will eventually decline is because older, poorer people simply won\'t be able to afford it. The legislation reduces premiums substantially for younger people but increases them substantially for older people — and especially poorer, older people — according to the CBO. The CBO\'s estimate of the premium increases for older, poorer Americans is actually worse than a previous one from AARP. Here\'s what AARP, which has announced its opposition to the bill, said last week: ... Our estimates find that, taken together, premiums for older adults could increase by as much as $3,600 for a 55-year old earning $25,000 a year, $7,000 for a 64-year old earning $25,000 a year and up to $8,400 for a 64-year old earning $15,000 a year. If you\'re a Republican looking at these numbers, you have to be concerned — just from a self-preservation standpoint. Republican leaders have made great pains to argue that the CBO\'s estimate of the millions who will lose insurance is faulty, or even that it\'s a necessary side effect of returning to a more free-market approach to health care. But the GOP\'s counter-argument is predicated on the idea that its alternative would at least allow people access to coverage. Paying such a substantial portion of one\'s income on health insurance doesn\'t meet that goal — if, in fact, the CBO\'s estimate is anywhere close to accurate. It also affects a group of voters who are integral to the Trump Coalition. Less-formally educated and lower-income white Americans were the backbone of the electoral shift that allowed President Trump to be elected, and he has promised them the world: Coverage that is even more affordable than the Affordable Care Act and "insurance for everybody." On top of all that, older people are much more likely to vote than younger people, especially in a midterm election like 2018. So basically, Trump\'s win was built on older, poorer people, for whom this law appears to drive up premiums and drive down the insurance rate, while benefiting the younger and wealthier. That\'s not something that will assure skeptical Republicans at all — even if they can get past that 24 million number.', 'answers': {'answer_start': [638], 'text': ['750 percent']}}
Running tokenizer on prediction dataset:   0%|          | 0/400 [00:00<?, ? examples/s]Running tokenizer on prediction dataset: 100%|██████████| 400/400 [00:01<00:00, 365.91 examples/s]                                                                                                  08/03/2023 14:39:12 - INFO - __main__ - *** Predict ***
[INFO|trainer.py:749] 2023-08-03 14:39:12,541 >> The following columns in the test set don't have a corresponding argument in `DebertaV2ForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping. If example_id, offset_mapping are not expected by `DebertaV2ForQuestionAnswering.forward`,  you can safely ignore this message.
[INFO|trainer.py:3083] 2023-08-03 14:39:12,546 >> ***** Running Prediction *****
[INFO|trainer.py:3085] 2023-08-03 14:39:12,546 >>   Num examples = 822
[INFO|trainer.py:3088] 2023-08-03 14:39:12,546 >>   Batch size = 8
  0%|          | 0/103 [00:00<?, ?it/s]  2%|▏         | 2/103 [00:00<00:13,  7.70it/s]  3%|▎         | 3/103 [00:00<00:18,  5.43it/s]  4%|▍         | 4/103 [00:00<00:21,  4.70it/s]  5%|▍         | 5/103 [00:01<00:22,  4.35it/s]  6%|▌         | 6/103 [00:01<00:23,  4.17it/s]  7%|▋         | 7/103 [00:01<00:23,  4.06it/s]  8%|▊         | 8/103 [00:01<00:23,  3.99it/s]  9%|▊         | 9/103 [00:02<00:23,  3.94it/s] 10%|▉         | 10/103 [00:02<00:23,  3.90it/s] 11%|█         | 11/103 [00:02<00:23,  3.89it/s] 12%|█▏        | 12/103 [00:02<00:23,  3.87it/s] 13%|█▎        | 13/103 [00:03<00:23,  3.85it/s] 14%|█▎        | 14/103 [00:03<00:23,  3.84it/s] 15%|█▍        | 15/103 [00:03<00:22,  3.84it/s] 16%|█▌        | 16/103 [00:03<00:22,  3.84it/s] 17%|█▋        | 17/103 [00:04<00:22,  3.84it/s] 17%|█▋        | 18/103 [00:04<00:22,  3.84it/s] 18%|█▊        | 19/103 [00:04<00:21,  3.84it/s] 19%|█▉        | 20/103 [00:04<00:21,  3.83it/s] 20%|██        | 21/103 [00:05<00:21,  3.82it/s] 21%|██▏       | 22/103 [00:05<00:21,  3.82it/s] 22%|██▏       | 23/103 [00:05<00:20,  3.82it/s] 23%|██▎       | 24/103 [00:06<00:20,  3.82it/s] 24%|██▍       | 25/103 [00:06<00:20,  3.82it/s] 25%|██▌       | 26/103 [00:06<00:20,  3.83it/s] 26%|██▌       | 27/103 [00:06<00:19,  3.82it/s] 27%|██▋       | 28/103 [00:07<00:19,  3.83it/s] 28%|██▊       | 29/103 [00:07<00:19,  3.83it/s] 29%|██▉       | 30/103 [00:07<00:19,  3.83it/s] 30%|███       | 31/103 [00:07<00:18,  3.82it/s] 31%|███       | 32/103 [00:08<00:18,  3.82it/s] 32%|███▏      | 33/103 [00:08<00:18,  3.82it/s] 33%|███▎      | 34/103 [00:08<00:18,  3.83it/s] 34%|███▍      | 35/103 [00:08<00:17,  3.83it/s] 35%|███▍      | 36/103 [00:09<00:17,  3.83it/s] 36%|███▌      | 37/103 [00:09<00:17,  3.83it/s] 37%|███▋      | 38/103 [00:09<00:16,  3.83it/s] 38%|███▊      | 39/103 [00:09<00:16,  3.82it/s] 39%|███▉      | 40/103 [00:10<00:16,  3.83it/s] 40%|███▉      | 41/103 [00:10<00:16,  3.82it/s] 41%|████      | 42/103 [00:10<00:15,  3.81it/s] 42%|████▏     | 43/103 [00:10<00:15,  3.81it/s] 43%|████▎     | 44/103 [00:11<00:15,  3.81it/s] 44%|████▎     | 45/103 [00:11<00:15,  3.82it/s] 45%|████▍     | 46/103 [00:11<00:14,  3.81it/s] 46%|████▌     | 47/103 [00:12<00:14,  3.81it/s] 47%|████▋     | 48/103 [00:12<00:14,  3.80it/s] 48%|████▊     | 49/103 [00:12<00:14,  3.81it/s] 49%|████▊     | 50/103 [00:12<00:13,  3.81it/s] 50%|████▉     | 51/103 [00:13<00:13,  3.81it/s] 50%|█████     | 52/103 [00:13<00:13,  3.80it/s] 51%|█████▏    | 53/103 [00:13<00:13,  3.81it/s] 52%|█████▏    | 54/103 [00:13<00:12,  3.81it/s] 53%|█████▎    | 55/103 [00:14<00:12,  3.81it/s] 54%|█████▍    | 56/103 [00:14<00:12,  3.81it/s] 55%|█████▌    | 57/103 [00:14<00:12,  3.80it/s] 56%|█████▋    | 58/103 [00:14<00:11,  3.80it/s] 57%|█████▋    | 59/103 [00:15<00:11,  3.81it/s] 58%|█████▊    | 60/103 [00:15<00:11,  3.81it/s] 59%|█████▉    | 61/103 [00:15<00:10,  3.82it/s] 60%|██████    | 62/103 [00:15<00:10,  3.82it/s] 61%|██████    | 63/103 [00:16<00:10,  3.82it/s] 62%|██████▏   | 64/103 [00:16<00:10,  3.83it/s] 63%|██████▎   | 65/103 [00:16<00:09,  3.82it/s] 64%|██████▍   | 66/103 [00:17<00:09,  3.80it/s] 65%|██████▌   | 67/103 [00:17<00:09,  3.80it/s] 66%|██████▌   | 68/103 [00:17<00:09,  3.80it/s] 67%|██████▋   | 69/103 [00:17<00:08,  3.80it/s] 68%|██████▊   | 70/103 [00:18<00:08,  3.80it/s] 69%|██████▉   | 71/103 [00:18<00:08,  3.79it/s] 70%|██████▉   | 72/103 [00:18<00:08,  3.80it/s] 71%|███████   | 73/103 [00:18<00:07,  3.81it/s] 72%|███████▏  | 74/103 [00:19<00:07,  3.80it/s] 73%|███████▎  | 75/103 [00:19<00:07,  3.79it/s] 74%|███████▍  | 76/103 [00:19<00:07,  3.80it/s] 75%|███████▍  | 77/103 [00:19<00:06,  3.80it/s] 76%|███████▌  | 78/103 [00:20<00:06,  3.80it/s] 77%|███████▋  | 79/103 [00:20<00:06,  3.79it/s] 78%|███████▊  | 80/103 [00:20<00:06,  3.79it/s] 79%|███████▊  | 81/103 [00:20<00:05,  3.80it/s] 80%|███████▉  | 82/103 [00:21<00:05,  3.80it/s] 81%|████████  | 83/103 [00:21<00:05,  3.80it/s] 82%|████████▏ | 84/103 [00:21<00:05,  3.79it/s] 83%|████████▎ | 85/103 [00:22<00:04,  3.79it/s] 83%|████████▎ | 86/103 [00:22<00:04,  3.79it/s] 84%|████████▍ | 87/103 [00:22<00:04,  3.78it/s] 85%|████████▌ | 88/103 [00:22<00:03,  3.79it/s] 86%|████████▋ | 89/103 [00:23<00:03,  3.79it/s] 87%|████████▋ | 90/103 [00:23<00:03,  3.79it/s] 88%|████████▊ | 91/103 [00:23<00:03,  3.79it/s] 89%|████████▉ | 92/103 [00:23<00:02,  3.80it/s] 90%|█████████ | 93/103 [00:24<00:02,  3.80it/s] 91%|█████████▏| 94/103 [00:24<00:02,  3.80it/s] 92%|█████████▏| 95/103 [00:24<00:02,  3.80it/s] 93%|█████████▎| 96/103 [00:24<00:01,  3.81it/s] 94%|█████████▍| 97/103 [00:25<00:01,  3.81it/s] 95%|█████████▌| 98/103 [00:25<00:01,  3.80it/s] 96%|█████████▌| 99/103 [00:25<00:01,  3.80it/s] 97%|█████████▋| 100/103 [00:25<00:00,  3.79it/s] 98%|█████████▊| 101/103 [00:26<00:00,  3.79it/s] 99%|█████████▉| 102/103 [00:26<00:00,  3.80it/s]100%|██████████| 103/103 [00:26<00:00,  4.11it/s]08/03/2023 14:39:41 - INFO - utils_qa_hf - Post-processing 400 example predictions split into 822 features.

  0%|          | 0/400 [00:00<?, ?it/s][A
  4%|▍         | 15/400 [00:00<00:02, 141.92it/s][A
  8%|▊         | 30/400 [00:00<00:02, 131.12it/s][A
 11%|█         | 44/400 [00:00<00:02, 132.26it/s][A
 14%|█▍        | 58/400 [00:00<00:02, 116.18it/s][A
 18%|█▊        | 72/400 [00:00<00:02, 115.37it/s][A
 21%|██        | 84/400 [00:00<00:02, 107.90it/s][A
 24%|██▍       | 98/400 [00:00<00:02, 116.63it/s][A
 28%|██▊       | 111/400 [00:00<00:02, 117.73it/s][A
 31%|███       | 124/400 [00:01<00:02, 121.23it/s][A
 36%|███▋      | 145/400 [00:01<00:01, 144.87it/s][A
 40%|████      | 160/400 [00:01<00:01, 145.78it/s][A
 44%|████▍     | 177/400 [00:01<00:01, 151.70it/s][A
 48%|████▊     | 193/400 [00:01<00:01, 144.66it/s][A
 52%|█████▏    | 208/400 [00:01<00:01, 134.12it/s][A
 56%|█████▌    | 222/400 [00:01<00:01, 129.84it/s][A
 60%|██████    | 240/400 [00:01<00:01, 142.66it/s][A
 64%|██████▍   | 258/400 [00:01<00:00, 152.71it/s][A
 68%|██████▊   | 274/400 [00:02<00:01, 113.20it/s][A
 72%|███████▏  | 287/400 [00:02<00:00, 113.05it/s][A
 75%|███████▌  | 300/400 [00:02<00:00, 115.68it/s][A
 80%|███████▉  | 318/400 [00:02<00:00, 131.15it/s][A
 83%|████████▎ | 332/400 [00:02<00:00, 116.22it/s][A
 87%|████████▋ | 349/400 [00:02<00:00, 128.55it/s][A
 92%|█████████▏| 369/400 [00:02<00:00, 143.90it/s][A
 97%|█████████▋| 387/400 [00:02<00:00, 153.05it/s][A100%|██████████| 400/400 [00:03<00:00, 130.08it/s]
08/03/2023 14:39:44 - INFO - utils_qa_hf - Saving predictions to ../../results/deberta-v3-large-squad2/predict_predictions.json.
08/03/2023 14:39:44 - INFO - utils_qa_hf - Saving nbest_preds to ../../results/deberta-v3-large-squad2/predict_nbest_predictions.json.
[INFO|modelcard.py:452] 2023-08-03 14:39:44,771 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Question Answering', 'type': 'question-answering'}}
100%|██████████| 103/103 [00:31<00:00,  3.29it/s]
***** predict metrics *****
  predict_samples         =        822
  test_exact_match        =        0.5
  test_f1                 =        0.0
  test_runtime            = 0:00:27.60
  test_samples_per_second =     29.779
  test_steps_per_second   =      3.731
