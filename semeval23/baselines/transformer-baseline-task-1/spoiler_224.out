Thu Aug  3 22:51:52 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.60.13    Driver Version: 525.60.13    CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100 80G...  On   | 00000000:C1:00.0 Off |                    0 |
| N/A   33C    P0    43W / 300W |      0MiB / 81920MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
08/03/2023 22:51:57 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False
08/03/2023 22:51:57 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=7e-06,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=../../output/task1-deberta-v2-xlarge-mnli-2-final/runs/Aug03_22-51-57_gpu-pr1-02,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=steps,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=16.0,
optim=adamw_torch,
optim_args=None,
output_dir=../../output/task1-deberta-v2-xlarge-mnli-2-final,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=16,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['tensorboard', 'wandb'],
resume_from_checkpoint=None,
run_name=task1-deberta-v2-xlarge-mnli-2-final,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
[INFO|configuration_utils.py:715] 2023-08-03 22:51:58,115 >> loading configuration file config.json from cache at /work/y53kang/.cache/huggingface/hub/models--microsoft--deberta-v2-xlarge-mnli/snapshots/5272422ce68b8d61766079390b96b033a64414d2/config.json
[INFO|configuration_utils.py:771] 2023-08-03 22:51:58,123 >> Model config DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v2-xlarge-mnli",
  "architectures": [
    "DebertaV2ForSequenceClassification"
  ],
  "attention_head_size": 64,
  "attention_probs_dropout_prob": 0.1,
  "conv_act": "gelu",
  "conv_kernel_size": 3,
  "finetuning_task": "text-classification",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1536,
  "id2label": {
    "0": "CONTRADICTION",
    "1": "NEUTRAL",
    "2": "ENTAILMENT"
  },
  "initializer_range": 0.02,
  "intermediate_size": 6144,
  "label2id": {
    "CONTRADICTION": 0,
    "ENTAILMENT": 2,
    "NEUTRAL": 1
  },
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 24,
  "num_hidden_layers": 24,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 1536,
  "pooling": {
    "dropout": 0,
    "hidden_act": "gelu"
  },
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.32.0.dev0",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

{'id': 10, 'context': 'Analysis: This may be the most brutal number in the CBO reportThis may be the most brutal number in the CBO report - Plenty has been made of the big Congressional Budget Office finding that 24 million people could lose their insurance under Republicans\' Obamacare replacement over the next decade. That\'s higher than expected and poses a clear and massive hurdle for Republicans as they attempt to convince dozens of skeptical members. But there\'s another number that paints a particularly dire picture for the GOP\'s alternative — especially in light of President Trump\'s populist rhetoric. According to the CBO, 64-year olds making $26,500 per year would see their premiums increase by an estimated 750 percent by 2026. While they are on track to pay $1,700 under the current law, the CBO projects the American Health Care Act would force them to pay $14,600. Even if you grant that inflation will allow them to make slightly more money by 2026, that\'s still about half of their income going to health care. Here\'s how that looks as a percentage of income (h/t Philip Bump): As skeptics of the law noted, that suggests the reason premiums as a whole will eventually decline is because older, poorer people simply won\'t be able to afford it. The legislation reduces premiums substantially for younger people but increases them substantially for older people — and especially poorer, older people — according to the CBO. The CBO\'s estimate of the premium increases for older, poorer Americans is actually worse than a previous one from AARP. Here\'s what AARP, which has announced its opposition to the bill, said last week: ... Our estimates find that, taken together, premiums for older adults could increase by as much as $3,600 for a 55-year old earning $25,000 a year, $7,000 for a 64-year old earning $25,000 a year and up to $8,400 for a 64-year old earning $15,000 a year. If you\'re a Republican looking at these numbers, you have to be concerned — just from a self-preservation standpoint. Republican leaders have made great pains to argue that the CBO\'s estimate of the millions who will lose insurance is faulty, or even that it\'s a necessary side effect of returning to a more free-market approach to health care. But the GOP\'s counter-argument is predicated on the idea that its alternative would at least allow people access to coverage. Paying such a substantial portion of one\'s income on health insurance doesn\'t meet that goal — if, in fact, the CBO\'s estimate is anywhere close to accurate. It also affects a group of voters who are integral to the Trump Coalition. Less-formally educated and lower-income white Americans were the backbone of the electoral shift that allowed President Trump to be elected, and he has promised them the world: Coverage that is even more affordable than the Affordable Care Act and "insurance for everybody." On top of all that, older people are much more likely to vote than younger people, especially in a midterm election like 2018. So basically, Trump\'s win was built on older, poorer people, for whom this law appears to drive up premiums and drive down the insurance rate, while benefiting the younger and wealthier. That\'s not something that will assure skeptical Republicans at all — even if they can get past that 24 million number.', 'tags': 'phrase'}
['multi', 'passage', 'phrase']
08/03/2023 22:51:58 - INFO - __main__ - setting problem type to single label classification
[INFO|configuration_utils.py:715] 2023-08-03 22:51:58,169 >> loading configuration file config.json from cache at /work/y53kang/.cache/huggingface/hub/models--microsoft--deberta-v2-xlarge-mnli/snapshots/5272422ce68b8d61766079390b96b033a64414d2/config.json
[INFO|configuration_utils.py:771] 2023-08-03 22:51:58,170 >> Model config DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v2-xlarge-mnli",
  "architectures": [
    "DebertaV2ForSequenceClassification"
  ],
  "attention_head_size": 64,
  "attention_probs_dropout_prob": 0.1,
  "conv_act": "gelu",
  "conv_kernel_size": 3,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1536,
  "id2label": {
    "0": "CONTRADICTION",
    "1": "NEUTRAL",
    "2": "ENTAILMENT"
  },
  "initializer_range": 0.02,
  "intermediate_size": 6144,
  "label2id": {
    "CONTRADICTION": 0,
    "ENTAILMENT": 2,
    "NEUTRAL": 1
  },
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 24,
  "num_hidden_layers": 24,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 1536,
  "pooling": {
    "dropout": 0,
    "hidden_act": "gelu"
  },
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.32.0.dev0",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

[INFO|tokenization_utils_base.py:1844] 2023-08-03 22:51:58,177 >> loading file spm.model from cache at /work/y53kang/.cache/huggingface/hub/models--microsoft--deberta-v2-xlarge-mnli/snapshots/5272422ce68b8d61766079390b96b033a64414d2/spm.model
[INFO|tokenization_utils_base.py:1844] 2023-08-03 22:51:58,177 >> loading file tokenizer.json from cache at None
[INFO|tokenization_utils_base.py:1844] 2023-08-03 22:51:58,177 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1844] 2023-08-03 22:51:58,177 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1844] 2023-08-03 22:51:58,177 >> loading file tokenizer_config.json from cache at /work/y53kang/.cache/huggingface/hub/models--microsoft--deberta-v2-xlarge-mnli/snapshots/5272422ce68b8d61766079390b96b033a64414d2/tokenizer_config.json
[INFO|configuration_utils.py:715] 2023-08-03 22:51:58,178 >> loading configuration file config.json from cache at /work/y53kang/.cache/huggingface/hub/models--microsoft--deberta-v2-xlarge-mnli/snapshots/5272422ce68b8d61766079390b96b033a64414d2/config.json
[INFO|configuration_utils.py:771] 2023-08-03 22:51:58,178 >> Model config DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v2-xlarge-mnli",
  "architectures": [
    "DebertaV2ForSequenceClassification"
  ],
  "attention_head_size": 64,
  "attention_probs_dropout_prob": 0.1,
  "conv_act": "gelu",
  "conv_kernel_size": 3,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1536,
  "id2label": {
    "0": "CONTRADICTION",
    "1": "NEUTRAL",
    "2": "ENTAILMENT"
  },
  "initializer_range": 0.02,
  "intermediate_size": 6144,
  "label2id": {
    "CONTRADICTION": 0,
    "ENTAILMENT": 2,
    "NEUTRAL": 1
  },
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 24,
  "num_hidden_layers": 24,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 1536,
  "pooling": {
    "dropout": 0,
    "hidden_act": "gelu"
  },
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.32.0.dev0",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

[INFO|tokenization_utils.py:426] 2023-08-03 22:51:58,573 >> Adding [MASK] to the vocabulary
[WARNING|logging.py:284] 2023-08-03 22:51:58,573 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:715] 2023-08-03 22:51:58,574 >> loading configuration file config.json from cache at /work/y53kang/.cache/huggingface/hub/models--microsoft--deberta-v2-xlarge-mnli/snapshots/5272422ce68b8d61766079390b96b033a64414d2/config.json
[INFO|configuration_utils.py:771] 2023-08-03 22:51:58,575 >> Model config DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v2-xlarge-mnli",
  "architectures": [
    "DebertaV2ForSequenceClassification"
  ],
  "attention_head_size": 64,
  "attention_probs_dropout_prob": 0.1,
  "conv_act": "gelu",
  "conv_kernel_size": 3,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1536,
  "id2label": {
    "0": "CONTRADICTION",
    "1": "NEUTRAL",
    "2": "ENTAILMENT"
  },
  "initializer_range": 0.02,
  "intermediate_size": 6144,
  "label2id": {
    "CONTRADICTION": 0,
    "ENTAILMENT": 2,
    "NEUTRAL": 1
  },
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 24,
  "num_hidden_layers": 24,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 1536,
  "pooling": {
    "dropout": 0,
    "hidden_act": "gelu"
  },
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.32.0.dev0",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

[WARNING|logging.py:284] 2023-08-03 22:51:58,781 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|modeling_utils.py:2638] 2023-08-03 22:51:58,878 >> loading weights file pytorch_model.bin from cache at /work/y53kang/.cache/huggingface/hub/models--microsoft--deberta-v2-xlarge-mnli/snapshots/5272422ce68b8d61766079390b96b033a64414d2/pytorch_model.bin
[INFO|modeling_utils.py:3370] 2023-08-03 22:52:04,634 >> All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.

[INFO|modeling_utils.py:3378] 2023-08-03 22:52:04,634 >> All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at microsoft/deberta-v2-xlarge-mnli.
If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.
08/03/2023 22:52:04 - WARNING - __main__ - The label2id key in the model config.json is not equal to the label2id key of this run. You can ignore this if you are doing finetuning.
Running tokenizer on train dataset:   0%|          | 0/3600 [00:00<?, ? examples/s]Running tokenizer on train dataset:  28%|██▊       | 1000/3600 [00:01<00:04, 573.65 examples/s]Running tokenizer on train dataset:  56%|█████▌    | 2000/3600 [00:03<00:02, 568.75 examples/s]Running tokenizer on train dataset:  83%|████████▎ | 3000/3600 [00:05<00:01, 568.14 examples/s]Running tokenizer on train dataset: 100%|██████████| 3600/3600 [00:06<00:00, 566.13 examples/s]                                                                                               08/03/2023 22:52:11 - INFO - __main__ - Shuffling the training dataset
Running tokenizer on validation dataset:   0%|          | 0/400 [00:00<?, ? examples/s]Running tokenizer on validation dataset: 100%|██████████| 400/400 [00:00<00:00, 543.13 examples/s]                                                                                                  08/03/2023 22:52:11 - INFO - __main__ - Sample 2619 of the training set: {'id': 1634, 'context': 'This man created his own sex doll and it’s as weird as you thinkThis man created his own sex doll and it’s as weird as you think The list - Samantha is a sex doll with a difference – she has to be seduced in order to want sex. Yes, this is the point society loses its balance and falls over the edge. Spanish engineer Sergi Santos built Samantha to be interactive. She likes to be touched. The doll, which has Angelina Jolie-esque cheekbones, piercing green eyes and oh, a functioning G-spot, has different modes of interaction. Samantha can want to be in family mode – which you can encourage by holding her hands or putting your arms around her waist. However if you’d like to stimulate her sexy side, you can touch her mouth "and the G spot". And lads, you can’t just "grab em by the p---y" – she wants you to be romantic and gentlemanly before getting down to it. The objective, the final objective of the sexual mode is to give her an orgasm. Imagine deriving pleasure from giving someone else pleasure. HT Metro More: Celebrity sex robots will soon be a reality More: Sex robots will \'come a lot sooner than you think\', scientist claims Keep scrolling for next article', 'label': 2, 'sentence': 'This man created his own sex doll and it’s as weird as you thinkThis man created his own sex doll and it’s as weird as you think The list - Samantha is a sex doll with a difference – she has to be seduced in order to want sex. Yes, this is the point society loses its balance and falls over the edge. Spanish engineer Sergi Santos built Samantha to be interactive. She likes to be touched. The doll, which has Angelina Jolie-esque cheekbones, piercing green eyes and oh, a functioning G-spot, has different modes of interaction. Samantha can want to be in family mode – which you can encourage by holding her hands or putting your arms around her waist. However if you’d like to stimulate her sexy side, you can touch her mouth "and the G spot". And lads, you can’t just "grab em by the p---y" – she wants you to be romantic and gentlemanly before getting down to it. The objective, the final objective of the sexual mode is to give her an orgasm. Imagine deriving pleasure from giving someone else pleasure. HT Metro More: Celebrity sex robots will soon be a reality More: Sex robots will \'come a lot sooner than you think\', scientist claims Keep scrolling for next article', 'input_ids': [1, 69, 400, 703, 60, 186, 10572, 12612, 7, 22, 20, 12, 27, 4518, 27, 17, 171, 2310, 400, 703, 60, 186, 10572, 12612, 7, 22, 20, 12, 27, 4518, 27, 17, 171, 23, 405, 91, 18315, 13, 10, 10572, 12612, 19, 10, 1169, 119, 121, 45, 8, 26, 54145, 11, 288, 8, 152, 10572, 4, 1270, 6, 32, 13, 5, 317, 1550, 10731, 107, 1699, 7, 4395, 105, 5, 2039, 4, 3061, 5949, 85457, 22997, 823, 18315, 8, 26, 4288, 4, 246, 5712, 8, 26, 6995, 4, 23, 12612, 6, 59, 45, 36340, 41156, 18, 16817, 67957, 6, 23161, 1205, 1041, 7, 5846, 6, 10, 6974, 789, 18, 22299, 6, 45, 204, 8124, 9, 4050, 4, 18315, 37, 152, 8, 26, 11, 239, 2266, 119, 59, 17, 37, 2394, 35, 2186, 86, 1033, 31, 1983, 29, 2724, 180, 86, 8279, 4, 407, 75, 17, 20, 147, 72, 8, 11545, 86, 47850, 362, 6, 17, 37, 1350, 86, 2549, 55, 431, 5, 789, 1584, 1195, 156, 30459, 6, 17, 37, 20, 38, 87, 55, 50715, 10072, 35, 5, 621, 16481, 331, 109, 119, 121, 1426, 17, 8, 26, 4882, 7, 13041, 406, 159, 377, 184, 8, 22, 4, 23, 3849, 6, 5, 840, 3849, 9, 5, 2822, 2266, 13, 8, 267, 86, 41, 85749, 4, 7148, 51728, 3343, 34, 888, 483, 698, 3343, 4, 23099, 6922, 1089, 43, 21722, 10572, 10407, 39, 669, 26, 10, 1622, 1089, 43, 25015, 10407, 39, 124, 18968, 10, 247, 7072, 97, 17, 171, 25, 6, 8436, 1905, 2466, 20667, 14, 245, 724, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
08/03/2023 22:52:11 - INFO - __main__ - Sample 456 of the training set: {'id': 2593, 'context': 'Google will deliver all the Costco groceries you want for $5Google Will Deliver All The Costco Groceries You Want For $5 - If you love Costco and live in Manhattan or West Los Angeles, your life is about to get a lot more convenient. Thanks to Google, you\'ll now be able to get your members-only groceries delivered to you for a small fee. Google announced Monday it\'s expanding its same-day delivery service to both areas, effective immediately. The service was first launched in 2013 in the San Francisco area. People in both West LA and Manhattan will be able to get anything they want from Costco, L\'Occitane, Staples, Target, Walgreens and Babies "R" Us through the service. New Yorkers will additionally be able to shop at Fairway Market, and Angelenos can also shop at Guitar Center, Toys "R" Us and Smart & Final. For now, Google is limiting its NYC-area service to Manhattan, though there are plans to expand to the outer boroughs in the future. Same-day delivery will cost $4.99 per store with no minimum price of purchase and no limit on how much you buy. So whether you want $200 worth of groceries or just an enormous box or Corn Flakes, Google is only charging you $4.99. That\'s significantly cheaper than Amazon\'s same-day delivery service, which costs $5.99 per order if you have Amazon Prime, a paid service that provides expedited shipping (among other perks). For non-Prime members, it\'s even more expensive: $9.98 for the first item ordered and $0.99 for each additional one. The upside to using Amazon for now? Its same-day service is available in a total of 12 cities across the U.S. That and the electronics and entertainment selection is almost definitely better, especially for existing Prime members. Online auction site eBay also has a same-day delivery service in San Francisco, Chicago, Dallas, San Jose and parts of NYC. For $5, you can get items from stores like Target, Urban Outfitters, Best Buy and Macy\'s delivered in just a few hours. There is a $25 minimum order.', 'label': 2, 'sentence': 'Google will deliver all the Costco groceries you want for $5Google Will Deliver All The Costco Groceries You Want For $5 - If you love Costco and live in Manhattan or West Los Angeles, your life is about to get a lot more convenient. Thanks to Google, you\'ll now be able to get your members-only groceries delivered to you for a small fee. Google announced Monday it\'s expanding its same-day delivery service to both areas, effective immediately. The service was first launched in 2013 in the San Francisco area. People in both West LA and Manhattan will be able to get anything they want from Costco, L\'Occitane, Staples, Target, Walgreens and Babies "R" Us through the service. New Yorkers will additionally be able to shop at Fairway Market, and Angelenos can also shop at Guitar Center, Toys "R" Us and Smart & Final. For now, Google is limiting its NYC-area service to Manhattan, though there are plans to expand to the outer boroughs in the future. Same-day delivery will cost $4.99 per store with no minimum price of purchase and no limit on how much you buy. So whether you want $200 worth of groceries or just an enormous box or Corn Flakes, Google is only charging you $4.99. That\'s significantly cheaper than Amazon\'s same-day delivery service, which costs $5.99 per order if you have Amazon Prime, a paid service that provides expedited shipping (among other perks). For non-Prime members, it\'s even more expensive: $9.98 for the first item ordered and $0.99 for each additional one. The upside to using Amazon for now? Its same-day service is available in a total of 12 cities across the U.S. That and the electronics and entertainment selection is almost definitely better, especially for existing Prime members. Online auction site eBay also has a same-day delivery service in San Francisco, Chicago, Dallas, San Jose and parts of NYC. For $5, you can get items from stores like Target, Urban Outfitters, Best Buy and Macy\'s delivered in just a few hours. There is a $25 minimum order.', 'input_ids': [1, 1073, 39, 1785, 46, 5, 24440, 16946, 17, 152, 14, 5592, 21697, 1567, 27571, 284, 23, 24440, 115796, 106, 4035, 174, 5592, 91, 110, 17, 206, 24440, 7, 410, 11, 8186, 31, 1056, 2617, 3001, 6, 29, 173, 13, 56, 8, 90, 10, 247, 52, 3446, 4, 858, 8, 1073, 6, 17, 25, 175, 136, 26, 265, 8, 90, 29, 488, 18, 6023, 16946, 2373, 8, 17, 14, 10, 271, 2033, 4, 1073, 1481, 1460, 22, 25, 12, 5534, 107, 193, 18, 1695, 1441, 238, 8, 202, 618, 6, 961, 1330, 4, 23, 238, 28, 108, 2557, 11, 1919, 11, 5, 1155, 3489, 274, 4, 1508, 11, 202, 1056, 4817, 7, 8186, 39, 26, 265, 8, 90, 509, 49, 152, 34, 24440, 6, 775, 25, 1360, 57544, 46099, 6, 30841, 6, 8481, 6, 40943, 7, 25915, 55, 1006, 109, 5786, 131, 5, 238, 4, 230, 34724, 39, 6621, 26, 265, 8, 1302, 33, 74802, 3041, 6, 7, 7518, 22598, 12, 37, 67, 1302, 33, 15355, 922, 6, 17847, 55, 1006, 109, 5786, 7, 4354, 169, 6118, 4, 174, 136, 6, 1073, 13, 9622, 107, 7312, 18, 15662, 238, 8, 8186, 6, 379, 83, 24, 1036, 8, 3385, 8, 5, 5821, 52287, 11, 5, 457, 4, 8283, 18, 1695, 1441, 39, 479, 65917, 376, 815, 19, 104, 2089, 451, 9, 992, 7, 104, 2367, 21, 100, 140, 17, 533, 4, 211, 535, 17, 152, 11418, 976, 9, 16946, 31, 87, 41, 5645, 1035, 31, 13800, 47913, 12, 6, 1073, 13, 103, 5993, 17, 65917, 4, 251, 25, 12, 2497, 4748, 97, 2076, 25, 12, 193, 18, 1695, 1441, 238, 6, 59, 1027, 91183, 376, 288, 75, 17, 30, 2076, 3757, 6, 10, 1234, 238, 15, 594, 41466, 2368, 36, 33733, 81, 17861, 142, 174, 465, 18, 52972, 488, 6, 22, 25, 12, 144, 52, 1960, 43, 3056, 113937, 14, 5, 108, 1537, 3070, 7, 70906, 14, 182, 849, 54, 4, 23, 9991, 8, 213, 2076, 14, 136, 44, 2627, 193, 18, 1695, 238, 13, 229, 11, 10, 799, 9, 515, 2114, 422, 5, 316, 4, 179, 4, 251, 7, 5, 7142, 7, 2982, 1512, 13, 555, 1131, 233, 6, 598, 14, 1453, 3757, 488, 4, 1916, 6583, 289, 8908, 67, 45, 10, 193, 18, 1695, 1441, 238, 11, 1155, 3489, 6, 2297, 6, 5230, 6, 1155, 7539, 7, 971, 9, 7312, 4, 174, 5592, 6, 17, 37, 90, 824, 34, 2268, 72, 8481, 6, 6867, 51897, 6, 1314, 2902, 7, 25627, 25, 12, 2373, 11, 87, 10, 215, 472, 4, 178, 13, 10, 9541, 2089, 288, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
08/03/2023 22:52:11 - INFO - __main__ - Sample 102 of the training set: {'id': 2391, 'context': '17 weird jobs you probably didn\'t know exist17 weird jobs you probably didn\'t know exist - It seems as though we can pay people to do anything for us these days: walk our dogs, build our furniture, organize our homes ... cuddle with us when we\'re feeling lonely. That\'s right: You can hire a professional cuddler to snuggle with you for about $60 an hour. You can also pay an "undercover bridesmaid" to stand next to you on your big day, or a professional mourner to cry with you at a loved one\'s funeral. Those are just a few of the weirdest jobs we found while compiling our list of the most unusual professionals.  Keep scrolling to see all 17. Snake milker Snake milkers extract venom from some of the world\'s most dangerous snakes, like rattlesnakes and cobras. The extracted venom is often used to create antivenom for hospital or laboratory use, and can be sold for up to $1,000 per gram. Odor judge Odor judges perform odor tests to rate the effectiveness of hygiene products like soaps and bodywashes, deodorant, and mouthwashes. Depending on what products are being studied,  judges smell subjects\' armpits, feet, or breath and rate their odors on a scale of one to 10. During one odor tester\'s 15-year career she sniffed approximately 5,600 feet and an indeterminate number of armpits, for which she won the Guiness World Record for most feet and armpits sniffed. Professional bridesmaid Professional bridesmaid Jen Glantz is the cofounder of Bridesmaid for Hire, a company that offers \'undercover bridesmaid\' and personal assistant-type services to brides and their wedding parties. "Essentially I\'m there as the bride\'s personal assistant and on-call therapist," Glanz tells Business Insider. "I help her manage and execute her personal to-do list of tasks, which can often be over 100 tasks long." She charges anywhere from $300 to $2,000 per wedding. Iceberg mover Iceberg mover became a profession after the disastrous sinking of the Titanic in 1912. The International Ice Patrol (IIP), which was founded a year later, is operated by the US Coast Guard. It tracks the location of icebergs and provides safe routes around them. If necessary, the iceberg will be towed out of the area. Professional mourner Professional mourners attend funerals and grieve for the deceased. A company in England called Rent A Mourner specializes in the industry, offering mourners for two hours for roughly $70.  Dog surfing instructor Dog surfing instructors, whom you can find at certain ocean resorts, are people you pay to teach you and your dog to surf. Some locations even offer classes strictly for dogs.  Panda nanny In 2014, the Giant Panda Protection and Research Center in China\'s Sichuan announced its worldwide search for panda cub caretakers. Contenders faced several elimination rounds including a top 500 list, top 50 list, top 10 list, and a final media event competition before getting the gig.  "Your work has only one mission: spending 365 days with the pandas and sharing in their joys and sorrows," Chinadaily.com reported organizers explaining. Professional mermaid Professional mermaids can make a decent amount of money performing at parties and teaching others how to "swim like a mermaid." They typically charge $300 per hour at birthday parties. But becoming a licensed mermaid and learning how to start your own mermaid business is pricey. Montreal-based company Aqua Mermaid charges entrepreneurs $3,800 for a five-day training course. Face feeler Face feelers, also known as \'sensory scientists,\' are trained to use their hands and judge the effectiveness of products like lotions, facial cleansers, and razors. Face feelers work part-time, but they can earn up to $25 per hour. Professional cuddler Professional cuddlers charge up to $80 an hour to snuggle with strangers. The downside: This work comes with its share of emotional burdens, says Portland-based cuddler Samantha Hess. Professional TV watcher Professional TV watcher is a real job — but it\'s not necessarily as easy as it sounds. According to an Investopedia.com article, pro TV watchers \'usually scan through different shows and news clips, and find the right clips that can be used on a television show or news program.\' The article also says when Jimmy Kimmel was looking for a TV watcher back in 2005, his show was offering pay of $500 to $600 per week. Ash artist Ash artists get creative with the remains of our loved ones. Following cremation, some people choose to hire these artists to create a token of remembrance, like a necklace or glass sculpture. Professional foreigner Some Chinese companies will pay men $1,000 a week to don a business suit and shake hands with Chinese businessmen, while others will hire foreigners to attend real-estate events and pose as celebrities. "It is a widespread belief in China that if foreigners are hired at an event, the whole thing is bumped up to another level," a real-estate agent from the outskirts of Chongqing told The Times. Dog food taster Human dog food tasters are hired by pet food companies to test the quality of their products. They also evaluate the nutritional value and usually spit out the food once they taste it. Chicken sexer Chicken sexers determine the sex of a chick, relying heavily on intuition. Usually hired by commercial hatcheries, these professionals (who are more common in the UK and Japan) make up to $60,000 a year. Professional line-stander Professional line-standers do one thing most of us have no patience for: wait in line. These professionals are especially busy during big sales (think Black Friday) and product launches (new iPhone releases, for example). Rates vary, but one professional line-stander told Business Insider he earns up to $1,000 a week. Fortune cookie writer Fortune cookie manufacturers usually hire freelancers or in-house writers to come up with inspiring or witty fortunes. EHow.com estimates that these professionals earn around $40,000 a year.', 'label': 0, 'sentence': '17 weird jobs you probably didn\'t know exist17 weird jobs you probably didn\'t know exist - It seems as though we can pay people to do anything for us these days: walk our dogs, build our furniture, organize our homes ... cuddle with us when we\'re feeling lonely. That\'s right: You can hire a professional cuddler to snuggle with you for about $60 an hour. You can also pay an "undercover bridesmaid" to stand next to you on your big day, or a professional mourner to cry with you at a loved one\'s funeral. Those are just a few of the weirdest jobs we found while compiling our list of the most unusual professionals.  Keep scrolling to see all 17. Snake milker Snake milkers extract venom from some of the world\'s most dangerous snakes, like rattlesnakes and cobras. The extracted venom is often used to create antivenom for hospital or laboratory use, and can be sold for up to $1,000 per gram. Odor judge Odor judges perform odor tests to rate the effectiveness of hygiene products like soaps and bodywashes, deodorant, and mouthwashes. Depending on what products are being studied,  judges smell subjects\' armpits, feet, or breath and rate their odors on a scale of one to 10. During one odor tester\'s 15-year career she sniffed approximately 5,600 feet and an indeterminate number of armpits, for which she won the Guiness World Record for most feet and armpits sniffed. Professional bridesmaid Professional bridesmaid Jen Glantz is the cofounder of Bridesmaid for Hire, a company that offers \'undercover bridesmaid\' and personal assistant-type services to brides and their wedding parties. "Essentially I\'m there as the bride\'s personal assistant and on-call therapist," Glanz tells Business Insider. "I help her manage and execute her personal to-do list of tasks, which can often be over 100 tasks long." She charges anywhere from $300 to $2,000 per wedding. Iceberg mover Iceberg mover became a profession after the disastrous sinking of the Titanic in 1912. The International Ice Patrol (IIP), which was founded a year later, is operated by the US Coast Guard. It tracks the location of icebergs and provides safe routes around them. If necessary, the iceberg will be towed out of the area. Professional mourner Professional mourners attend funerals and grieve for the deceased. A company in England called Rent A Mourner specializes in the industry, offering mourners for two hours for roughly $70.  Dog surfing instructor Dog surfing instructors, whom you can find at certain ocean resorts, are people you pay to teach you and your dog to surf. Some locations even offer classes strictly for dogs.  Panda nanny In 2014, the Giant Panda Protection and Research Center in China\'s Sichuan announced its worldwide search for panda cub caretakers. Contenders faced several elimination rounds including a top 500 list, top 50 list, top 10 list, and a final media event competition before getting the gig.  "Your work has only one mission: spending 365 days with the pandas and sharing in their joys and sorrows," Chinadaily.com reported organizers explaining. Professional mermaid Professional mermaids can make a decent amount of money performing at parties and teaching others how to "swim like a mermaid." They typically charge $300 per hour at birthday parties. But becoming a licensed mermaid and learning how to start your own mermaid business is pricey. Montreal-based company Aqua Mermaid charges entrepreneurs $3,800 for a five-day training course. Face feeler Face feelers, also known as \'sensory scientists,\' are trained to use their hands and judge the effectiveness of products like lotions, facial cleansers, and razors. Face feelers work part-time, but they can earn up to $25 per hour. Professional cuddler Professional cuddlers charge up to $80 an hour to snuggle with strangers. The downside: This work comes with its share of emotional burdens, says Portland-based cuddler Samantha Hess. Professional TV watcher Professional TV watcher is a real job — but it\'s not necessarily as easy as it sounds. According to an Investopedia.com article, pro TV watchers \'usually scan through different shows and news clips, and find the right clips that can be used on a television show or news program.\' The article also says when Jimmy Kimmel was looking for a TV watcher back in 2005, his show was offering pay of $500 to $600 per week. Ash artist Ash artists get creative with the remains of our loved ones. Following cremation, some people choose to hire these artists to create a token of remembrance, like a necklace or glass sculpture. Professional foreigner Some Chinese companies will pay men $1,000 a week to don a business suit and shake hands with Chinese businessmen, while others will hire foreigners to attend real-estate events and pose as celebrities. "It is a widespread belief in China that if foreigners are hired at an event, the whole thing is bumped up to another level," a real-estate agent from the outskirts of Chongqing told The Times. Dog food taster Human dog food tasters are hired by pet food companies to test the quality of their products. They also evaluate the nutritional value and usually spit out the food once they taste it. Chicken sexer Chicken sexers determine the sex of a chick, relying heavily on intuition. Usually hired by commercial hatcheries, these professionals (who are more common in the UK and Japan) make up to $60,000 a year. Professional line-stander Professional line-standers do one thing most of us have no patience for: wait in line. These professionals are especially busy during big sales (think Black Friday) and product launches (new iPhone releases, for example). Rates vary, but one professional line-stander told Business Insider he earns up to $1,000 a week. Fortune cookie writer Fortune cookie manufacturers usually hire freelancers or in-house writers to come up with inspiring or witty fortunes. EHow.com estimates that these professionals earn around $40,000 a year.', 'input_ids': [1, 1427, 4518, 1620, 17, 588, 335, 25, 38, 128, 2409, 6453, 4518, 1620, 17, 588, 335, 25, 38, 128, 2409, 91, 64, 717, 27, 379, 42, 37, 534, 98, 8, 71, 509, 14, 120, 116, 281, 43, 1057, 57, 2396, 6, 763, 57, 1697, 6, 6521, 57, 1771, 677, 32982, 19, 120, 76, 42, 25, 115, 1124, 10976, 4, 251, 25, 12, 164, 43, 106, 37, 2907, 10, 605, 32982, 543, 8, 34875, 19, 17, 14, 56, 18190, 41, 1179, 4, 106, 37, 67, 534, 41, 55, 8555, 21057, 41846, 109, 8, 1178, 245, 8, 17, 21, 29, 352, 149, 6, 31, 10, 605, 28569, 354, 8, 5713, 19, 17, 33, 10, 1214, 54, 25, 12, 6848, 4, 2110, 24, 87, 10, 215, 9, 5, 60843, 1620, 42, 248, 181, 26144, 57, 405, 9, 5, 112, 4260, 1988, 4, 2466, 20667, 8, 137, 46, 12627, 22008, 2664, 354, 22008, 2664, 1225, 5822, 37919, 34, 85, 9, 5, 183, 25, 12, 112, 2866, 18554, 6, 72, 73199, 12, 7, 65117, 12, 4, 23, 11476, 37919, 13, 338, 166, 8, 392, 1428, 90539, 14, 2001, 31, 6052, 118, 6, 7, 37, 26, 1545, 14, 62, 8, 13930, 376, 17703, 4, 62555, 3213, 62555, 7001, 1782, 14848, 2542, 8, 781, 5, 5747, 9, 11792, 360, 72, 28144, 7, 385, 20126, 816, 6, 36964, 6, 7, 62871, 816, 4, 7224, 21, 79, 360, 24, 157, 3954, 6, 7001, 4526, 3813, 25, 76889, 6, 1235, 6, 31, 3796, 7, 781, 51, 28940, 21, 10, 2032, 9, 54, 8, 257, 4, 1455, 54, 14848, 26748, 25, 12, 11595, 946, 977, 121, 62902, 2151, 259, 6, 9476, 1235, 7, 41, 67208, 236, 9, 76889, 6, 14, 59, 121, 474, 5, 24820, 1647, 723, 9454, 14, 112, 1235, 7, 76889, 62902, 4, 4026, 41846, 4026, 41846, 12199, 76626, 9110, 13, 5, 60683, 9, 72117, 14, 12864, 6, 10, 237, 15, 538, 124, 8555, 21057, 41846, 25, 7, 467, 4519, 18, 5538, 280, 8, 21136, 7, 51, 1454, 1751, 4, 55, 74080, 406, 16, 25, 99, 83, 27, 5, 8838, 25, 12, 467, 4519, 7, 21, 18, 13738, 8652, 466, 76626, 1555, 2662, 1436, 20811, 4, 55, 235, 150, 86, 1725, 7, 7577, 86, 467, 8, 18, 2709, 405, 9, 2930, 6, 59, 37, 338, 26, 105, 909, 2930, 195, 258, 246, 2573, 2277, 34, 14720, 8, 25607, 376, 1454, 4, 96760, 36657, 96760, 36657, 916, 10, 5948, 139, 5, 17855, 18847, 9, 5, 30425, 11, 64281, 23, 1010, 6300, 16926, 36, 235, 10257, 210, 59, 28, 3388, 10, 145, 481, 6, 13, 4530, 35, 5, 629, 3675, 8038, 4, 64, 3527, 5, 935, 9, 26579, 12, 7, 594, 998, 6336, 180, 88, 4, 110, 925, 6, 5, 26579, 39, 26, 36971, 61, 9, 5, 274, 4, 4026, 28569, 354, 4026, 79877, 2419, 42046, 7, 33895, 14, 5, 12137, 4, 78, 237, 11, 1837, 399, 8258, 78, 93618, 354, 8862, 11, 5, 510, 6, 1354, 79877, 14, 122, 472, 14, 5315, 27197, 4, 5340, 11507, 6756, 5340, 11507, 10826, 6, 2183, 17, 37, 170, 33, 702, 4018, 11963, 6, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
08/03/2023 22:52:12 - INFO - __main__ - Using metric accuracy for evaluation.
[INFO|trainer.py:749] 2023-08-03 22:52:13,836 >> The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: sentence, context, id. If sentence, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1681] 2023-08-03 22:52:13,847 >> ***** Running training *****
[INFO|trainer.py:1682] 2023-08-03 22:52:13,847 >>   Num examples = 3,600
[INFO|trainer.py:1683] 2023-08-03 22:52:13,847 >>   Num Epochs = 16
[INFO|trainer.py:1684] 2023-08-03 22:52:13,847 >>   Instantaneous batch size per device = 16
[INFO|trainer.py:1687] 2023-08-03 22:52:13,847 >>   Total train batch size (w. parallel, distributed & accumulation) = 64
[INFO|trainer.py:1688] 2023-08-03 22:52:13,847 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:1689] 2023-08-03 22:52:13,847 >>   Total optimization steps = 896
[INFO|trainer.py:1690] 2023-08-03 22:52:13,848 >>   Number of trainable parameters = 886,958,595
[INFO|integrations.py:716] 2023-08-03 22:52:13,853 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: ym_k. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.7
wandb: Run data is saved locally in /mnt/hpc/work/y53kang/pan-code/semeval23/baselines/transformer-baseline-task-1/wandb/run-20230803_225215-6izkxu5g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run task1-deberta-v2-xlarge-mnli-2-final
wandb: ⭐️ View project at https://wandb.ai/ym_k/huggingface
wandb: 🚀 View run at https://wandb.ai/ym_k/huggingface/runs/6izkxu5g
  0%|          | 0/896 [00:00<?, ?it/s]  0%|          | 1/896 [00:12<3:02:53, 12.26s/it]  0%|          | 2/896 [00:23<2:53:52, 11.67s/it]  0%|          | 3/896 [00:34<2:51:26, 11.52s/it]  0%|          | 4/896 [00:46<2:50:18, 11.46s/it]  1%|          | 5/896 [00:57<2:49:47, 11.43s/it]  1%|          | 6/896 [01:09<2:49:24, 11.42s/it]  1%|          | 7/896 [01:20<2:49:11, 11.42s/it]  1%|          | 8/896 [01:31<2:49:01, 11.42s/it]  1%|          | 9/896 [01:43<2:49:01, 11.43s/it]  1%|          | 10/896 [01:54<2:49:03, 11.45s/it]  1%|          | 11/896 [02:06<2:48:49, 11.45s/it]  1%|▏         | 12/896 [02:17<2:48:45, 11.45s/it]  1%|▏         | 13/896 [02:29<2:48:43, 11.46s/it]  2%|▏         | 14/896 [02:40<2:48:31, 11.46s/it]  2%|▏         | 15/896 [02:52<2:48:26, 11.47s/it]  2%|▏         | 16/896 [03:03<2:48:21, 11.48s/it]  2%|▏         | 17/896 [03:15<2:48:15, 11.49s/it]  2%|▏         | 18/896 [03:26<2:48:09, 11.49s/it]  2%|▏         | 19/896 [03:38<2:48:01, 11.50s/it]  2%|▏         | 20/896 [03:49<2:47:48, 11.49s/it]  2%|▏         | 21/896 [04:01<2:47:48, 11.51s/it]  2%|▏         | 22/896 [04:12<2:47:36, 11.51s/it]  3%|▎         | 23/896 [04:24<2:47:25, 11.51s/it]  3%|▎         | 24/896 [04:35<2:47:14, 11.51s/it]  3%|▎         | 25/896 [04:47<2:47:03, 11.51s/it]  3%|▎         | 26/896 [04:58<2:46:58, 11.51s/it]  3%|▎         | 27/896 [05:10<2:46:49, 11.52s/it]  3%|▎         | 28/896 [05:21<2:46:38, 11.52s/it]  3%|▎         | 29/896 [05:33<2:46:26, 11.52s/it]  3%|▎         | 30/896 [05:44<2:46:10, 11.51s/it]  3%|▎         | 31/896 [05:56<2:45:54, 11.51s/it]  4%|▎         | 32/896 [06:07<2:45:42, 11.51s/it]  4%|▎         | 33/896 [06:19<2:45:33, 11.51s/it]  4%|▍         | 34/896 [06:30<2:45:19, 11.51s/it]  4%|▍         | 35/896 [06:42<2:45:07, 11.51s/it]  4%|▍         | 36/896 [06:53<2:44:55, 11.51s/it]  4%|▍         | 37/896 [07:05<2:44:40, 11.50s/it]  4%|▍         | 38/896 [07:16<2:44:29, 11.50s/it]  4%|▍         | 39/896 [07:28<2:44:11, 11.50s/it]  4%|▍         | 40/896 [07:39<2:44:00, 11.50s/it]  5%|▍         | 41/896 [07:51<2:43:50, 11.50s/it]  5%|▍         | 42/896 [08:02<2:43:45, 11.51s/it]  5%|▍         | 43/896 [08:14<2:43:34, 11.51s/it]  5%|▍         | 44/896 [08:25<2:43:28, 11.51s/it]  5%|▌         | 45/896 [08:37<2:43:19, 11.51s/it]  5%|▌         | 46/896 [08:48<2:43:03, 11.51s/it]  5%|▌         | 47/896 [09:00<2:42:49, 11.51s/it]  5%|▌         | 48/896 [09:11<2:42:41, 11.51s/it]  5%|▌         | 49/896 [09:23<2:42:42, 11.53s/it]  6%|▌         | 50/896 [09:35<2:42:35, 11.53s/it]  6%|▌         | 51/896 [09:46<2:42:30, 11.54s/it]  6%|▌         | 52/896 [09:58<2:42:22, 11.54s/it]  6%|▌         | 53/896 [10:09<2:42:12, 11.55s/it]  6%|▌         | 54/896 [10:21<2:42:07, 11.55s/it]  6%|▌         | 55/896 [10:32<2:41:51, 11.55s/it]  6%|▋         | 56/896 [10:44<2:41:44, 11.55s/it][INFO|trainer.py:749] 2023-08-03 23:03:07,058 >> The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: sentence, context, id. If sentence, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3083] 2023-08-03 23:03:07,060 >> ***** Running Evaluation *****
[INFO|trainer.py:3085] 2023-08-03 23:03:07,060 >>   Num examples = 400
[INFO|trainer.py:3088] 2023-08-03 23:03:07,060 >>   Batch size = 8

  0%|          | 0/50 [00:00<?, ?it/s][A
  4%|▍         | 2/50 [00:00<00:12,  3.92it/s][A
  6%|▌         | 3/50 [00:01<00:16,  2.78it/s][A
  8%|▊         | 4/50 [00:01<00:19,  2.40it/s][A
 10%|█         | 5/50 [00:02<00:20,  2.23it/s][A
 12%|█▏        | 6/50 [00:02<00:20,  2.13it/s][A
 14%|█▍        | 7/50 [00:03<00:20,  2.07it/s][A
 16%|█▌        | 8/50 [00:03<00:20,  2.04it/s][A
 18%|█▊        | 9/50 [00:04<00:20,  2.01it/s][A
 20%|██        | 10/50 [00:04<00:19,  2.00it/s][A
 22%|██▏       | 11/50 [00:05<00:19,  1.99it/s][A
 24%|██▍       | 12/50 [00:05<00:19,  1.98it/s][A
 26%|██▌       | 13/50 [00:06<00:18,  1.97it/s][A
 28%|██▊       | 14/50 [00:06<00:18,  1.97it/s][A
 30%|███       | 15/50 [00:07<00:17,  1.97it/s][A
 32%|███▏      | 16/50 [00:07<00:17,  1.97it/s][A
 34%|███▍      | 17/50 [00:08<00:16,  1.97it/s][A
 36%|███▌      | 18/50 [00:08<00:16,  1.97it/s][A
 38%|███▊      | 19/50 [00:09<00:15,  1.97it/s][A
 40%|████      | 20/50 [00:09<00:15,  1.96it/s][A
 42%|████▏     | 21/50 [00:10<00:14,  1.96it/s][A
 44%|████▍     | 22/50 [00:10<00:14,  1.97it/s][A
 46%|████▌     | 23/50 [00:11<00:13,  1.96it/s][A
 48%|████▊     | 24/50 [00:11<00:13,  1.96it/s][A
 50%|█████     | 25/50 [00:12<00:12,  1.96it/s][A
 52%|█████▏    | 26/50 [00:12<00:12,  1.96it/s][A
 54%|█████▍    | 27/50 [00:13<00:11,  1.96it/s][A
 56%|█████▌    | 28/50 [00:13<00:11,  1.96it/s][A
 58%|█████▊    | 29/50 [00:14<00:10,  1.96it/s][A
 60%|██████    | 30/50 [00:14<00:10,  1.96it/s][A
 62%|██████▏   | 31/50 [00:15<00:09,  1.96it/s][A
 64%|██████▍   | 32/50 [00:15<00:09,  1.96it/s][A
 66%|██████▌   | 33/50 [00:16<00:08,  1.96it/s][A
 68%|██████▊   | 34/50 [00:16<00:08,  1.96it/s][A
 70%|███████   | 35/50 [00:17<00:07,  1.96it/s][A
 72%|███████▏  | 36/50 [00:17<00:07,  1.96it/s][A
 74%|███████▍  | 37/50 [00:18<00:06,  1.96it/s][A
 76%|███████▌  | 38/50 [00:18<00:06,  1.96it/s][A
 78%|███████▊  | 39/50 [00:19<00:05,  1.96it/s][A
 80%|████████  | 40/50 [00:19<00:05,  1.96it/s][A
 82%|████████▏ | 41/50 [00:20<00:04,  1.96it/s][A
 84%|████████▍ | 42/50 [00:20<00:04,  1.96it/s][A
 86%|████████▌ | 43/50 [00:21<00:03,  1.96it/s][A
 88%|████████▊ | 44/50 [00:21<00:03,  1.96it/s][A
 90%|█████████ | 45/50 [00:22<00:02,  1.90it/s][A
 92%|█████████▏| 46/50 [00:23<00:02,  1.92it/s][A
 94%|█████████▍| 47/50 [00:23<00:01,  1.93it/s][A
 96%|█████████▌| 48/50 [00:24<00:01,  1.94it/s][A
 98%|█████████▊| 49/50 [00:24<00:00,  1.95it/s][A
100%|██████████| 50/50 [00:25<00:00,  1.96it/s][A                                                  
                                               [A  6%|▋         | 56/896 [11:12<2:41:44, 11.55s/it]
100%|██████████| 50/50 [00:25<00:00,  1.96it/s][A
                                               [A[INFO|trainer.py:2809] 2023-08-03 23:03:32,640 >> Saving model checkpoint to ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-56
[INFO|configuration_utils.py:460] 2023-08-03 23:03:32,643 >> Configuration saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-56/config.json
[INFO|modeling_utils.py:1874] 2023-08-03 23:04:06,984 >> Model weights saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-56/pytorch_model.bin
[INFO|tokenization_utils_base.py:2227] 2023-08-03 23:04:06,990 >> tokenizer config file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-56/tokenizer_config.json
[INFO|tokenization_utils_base.py:2234] 2023-08-03 23:04:06,992 >> Special tokens file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-56/special_tokens_map.json
  6%|▋         | 57/896 [13:09<12:01:18, 51.58s/it]  6%|▋         | 58/896 [13:20<9:12:08, 39.53s/it]   7%|▋         | 59/896 [13:32<7:13:51, 31.10s/it]  7%|▋         | 60/896 [13:43<5:51:19, 25.21s/it]  7%|▋         | 61/896 [13:55<4:53:40, 21.10s/it]  7%|▋         | 62/896 [14:06<4:13:27, 18.23s/it]  7%|▋         | 63/896 [14:18<3:45:19, 16.23s/it]  7%|▋         | 64/896 [14:29<3:25:35, 14.83s/it]  7%|▋         | 65/896 [14:41<3:11:42, 13.84s/it]  7%|▋         | 66/896 [14:52<3:01:58, 13.15s/it]  7%|▋         | 67/896 [15:04<2:55:06, 12.67s/it]  8%|▊         | 68/896 [15:15<2:50:09, 12.33s/it]  8%|▊         | 69/896 [15:27<2:46:45, 12.10s/it]  8%|▊         | 70/896 [15:39<2:44:20, 11.94s/it]  8%|▊         | 71/896 [15:50<2:42:37, 11.83s/it]  8%|▊         | 72/896 [16:02<2:41:20, 11.75s/it]  8%|▊         | 73/896 [16:13<2:40:26, 11.70s/it]  8%|▊         | 74/896 [16:25<2:39:42, 11.66s/it]  8%|▊         | 75/896 [16:36<2:39:09, 11.63s/it]  8%|▊         | 76/896 [16:48<2:38:47, 11.62s/it]  9%|▊         | 77/896 [17:00<2:38:23, 11.60s/it]  9%|▊         | 78/896 [17:11<2:38:08, 11.60s/it]  9%|▉         | 79/896 [17:23<2:37:44, 11.58s/it]  9%|▉         | 80/896 [17:34<2:37:24, 11.57s/it]  9%|▉         | 81/896 [17:46<2:37:08, 11.57s/it]  9%|▉         | 82/896 [17:57<2:36:49, 11.56s/it]  9%|▉         | 83/896 [18:09<2:36:40, 11.56s/it]  9%|▉         | 84/896 [18:21<2:36:30, 11.56s/it]  9%|▉         | 85/896 [18:32<2:36:14, 11.56s/it] 10%|▉         | 86/896 [18:44<2:35:57, 11.55s/it] 10%|▉         | 87/896 [18:55<2:35:46, 11.55s/it] 10%|▉         | 88/896 [19:07<2:35:36, 11.56s/it] 10%|▉         | 89/896 [19:18<2:35:24, 11.55s/it] 10%|█         | 90/896 [19:30<2:35:11, 11.55s/it] 10%|█         | 91/896 [19:41<2:35:01, 11.55s/it] 10%|█         | 92/896 [19:53<2:34:48, 11.55s/it] 10%|█         | 93/896 [20:04<2:34:34, 11.55s/it] 10%|█         | 94/896 [20:16<2:34:22, 11.55s/it] 11%|█         | 95/896 [20:28<2:34:10, 11.55s/it] 11%|█         | 96/896 [20:39<2:33:55, 11.54s/it] 11%|█         | 97/896 [20:51<2:33:41, 11.54s/it] 11%|█         | 98/896 [21:02<2:33:27, 11.54s/it] 11%|█         | 99/896 [21:14<2:33:16, 11.54s/it] 11%|█         | 100/896 [21:25<2:33:05, 11.54s/it] 11%|█▏        | 101/896 [21:37<2:32:56, 11.54s/it] 11%|█▏        | 102/896 [21:48<2:32:47, 11.55s/it] 11%|█▏        | 103/896 [22:00<2:32:34, 11.54s/it] 12%|█▏        | 104/896 [22:11<2:32:24, 11.55s/it] 12%|█▏        | 105/896 [22:23<2:32:12, 11.55s/it] 12%|█▏        | 106/896 [22:35<2:31:56, 11.54s/it] 12%|█▏        | 107/896 [22:46<2:31:42, 11.54s/it] 12%|█▏        | 108/896 [22:58<2:31:33, 11.54s/it] 12%|█▏        | 109/896 [23:09<2:31:27, 11.55s/it] 12%|█▏        | 110/896 [23:21<2:31:11, 11.54s/it] 12%|█▏        | 111/896 [23:32<2:30:59, 11.54s/it] 12%|█▎        | 112/896 [23:44<2:30:53, 11.55s/it][INFO|trainer.py:749] 2023-08-03 23:16:09,891 >> The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: sentence, context, id. If sentence, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3083] 2023-08-03 23:16:09,893 >> ***** Running Evaluation *****
[INFO|trainer.py:3085] 2023-08-03 23:16:09,893 >>   Num examples = 400
[INFO|trainer.py:3088] 2023-08-03 23:16:09,894 >>   Batch size = 8
{'eval_loss': 0.9019345045089722, 'eval_accuracy': 0.595, 'eval_runtime': 25.5691, 'eval_samples_per_second': 15.644, 'eval_steps_per_second': 1.955, 'epoch': 1.0}

  0%|          | 0/50 [00:00<?, ?it/s][A
  4%|▍         | 2/50 [00:00<00:12,  3.92it/s][A
  6%|▌         | 3/50 [00:01<00:16,  2.78it/s][A
  8%|▊         | 4/50 [00:01<00:19,  2.41it/s][A
 10%|█         | 5/50 [00:02<00:20,  2.23it/s][A
 12%|█▏        | 6/50 [00:02<00:20,  2.13it/s][A
 14%|█▍        | 7/50 [00:03<00:20,  2.08it/s][A
 16%|█▌        | 8/50 [00:03<00:20,  2.04it/s][A
 18%|█▊        | 9/50 [00:04<00:20,  2.02it/s][A
 20%|██        | 10/50 [00:04<00:19,  2.00it/s][A
 22%|██▏       | 11/50 [00:05<00:19,  1.99it/s][A
 24%|██▍       | 12/50 [00:05<00:19,  1.98it/s][A
 26%|██▌       | 13/50 [00:06<00:18,  1.97it/s][A
 28%|██▊       | 14/50 [00:06<00:18,  1.97it/s][A
 30%|███       | 15/50 [00:07<00:17,  1.97it/s][A
 32%|███▏      | 16/50 [00:07<00:17,  1.97it/s][A
 34%|███▍      | 17/50 [00:08<00:16,  1.97it/s][A
 36%|███▌      | 18/50 [00:08<00:16,  1.97it/s][A
 38%|███▊      | 19/50 [00:09<00:15,  1.97it/s][A
 40%|████      | 20/50 [00:09<00:15,  1.96it/s][A
 42%|████▏     | 21/50 [00:10<00:14,  1.95it/s][A
 44%|████▍     | 22/50 [00:10<00:14,  1.95it/s][A
 46%|████▌     | 23/50 [00:11<00:13,  1.95it/s][A
 48%|████▊     | 24/50 [00:11<00:13,  1.95it/s][A
 50%|█████     | 25/50 [00:12<00:12,  1.96it/s][A
 52%|█████▏    | 26/50 [00:12<00:12,  1.96it/s][A
 54%|█████▍    | 27/50 [00:13<00:11,  1.96it/s][A
 56%|█████▌    | 28/50 [00:13<00:11,  1.96it/s][A
 58%|█████▊    | 29/50 [00:14<00:10,  1.96it/s][A
 60%|██████    | 30/50 [00:14<00:10,  1.96it/s][A
 62%|██████▏   | 31/50 [00:15<00:09,  1.96it/s][A
 64%|██████▍   | 32/50 [00:15<00:09,  1.97it/s][A
 66%|██████▌   | 33/50 [00:16<00:08,  1.96it/s][A
 68%|██████▊   | 34/50 [00:16<00:08,  1.96it/s][A
 70%|███████   | 35/50 [00:17<00:07,  1.96it/s][A
 72%|███████▏  | 36/50 [00:17<00:07,  1.96it/s][A
 74%|███████▍  | 37/50 [00:18<00:06,  1.96it/s][A
 76%|███████▌  | 38/50 [00:18<00:06,  1.96it/s][A
 78%|███████▊  | 39/50 [00:19<00:05,  1.97it/s][A
 80%|████████  | 40/50 [00:19<00:05,  1.97it/s][A
 82%|████████▏ | 41/50 [00:20<00:04,  1.96it/s][A
 84%|████████▍ | 42/50 [00:20<00:04,  1.96it/s][A
 86%|████████▌ | 43/50 [00:21<00:03,  1.96it/s][A
 88%|████████▊ | 44/50 [00:21<00:03,  1.96it/s][A
 90%|█████████ | 45/50 [00:22<00:02,  1.96it/s][A
 92%|█████████▏| 46/50 [00:22<00:02,  1.96it/s][A
 94%|█████████▍| 47/50 [00:23<00:01,  1.97it/s][A
 96%|█████████▌| 48/50 [00:23<00:01,  1.97it/s][A
 98%|█████████▊| 49/50 [00:24<00:00,  1.96it/s][A
100%|██████████| 50/50 [00:24<00:00,  1.97it/s][A                                                   
                                               [A 12%|█▎        | 112/896 [24:15<2:30:53, 11.55s/it]
100%|██████████| 50/50 [00:24<00:00,  1.97it/s][A
                                               [A[INFO|trainer.py:2809] 2023-08-03 23:16:35,405 >> Saving model checkpoint to ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-112
[INFO|configuration_utils.py:460] 2023-08-03 23:16:35,408 >> Configuration saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-112/config.json
[INFO|modeling_utils.py:1874] 2023-08-03 23:17:09,206 >> Model weights saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-112/pytorch_model.bin
[INFO|tokenization_utils_base.py:2227] 2023-08-03 23:17:09,209 >> tokenizer config file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-112/tokenizer_config.json
[INFO|tokenization_utils_base.py:2234] 2023-08-03 23:17:09,210 >> Special tokens file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-112/special_tokens_map.json
 13%|█▎        | 113/896 [26:04<10:53:05, 50.04s/it] 13%|█▎        | 114/896 [26:15<8:21:05, 38.45s/it]  13%|█▎        | 115/896 [26:27<6:35:05, 30.35s/it] 13%|█▎        | 116/896 [26:38<5:20:58, 24.69s/it] 13%|█▎        | 117/896 [26:50<4:29:16, 20.74s/it] 13%|█▎        | 118/896 [27:01<3:53:08, 17.98s/it] 13%|█▎        | 119/896 [27:13<3:27:43, 16.04s/it] 13%|█▎        | 120/896 [27:24<3:10:01, 14.69s/it] 14%|█▎        | 121/896 [27:36<2:57:39, 13.75s/it] 14%|█▎        | 122/896 [27:47<2:48:53, 13.09s/it] 14%|█▎        | 123/896 [27:59<2:42:38, 12.62s/it] 14%|█▍        | 124/896 [28:10<2:38:16, 12.30s/it] 14%|█▍        | 125/896 [28:22<2:35:01, 12.06s/it] 14%|█▍        | 126/896 [28:33<2:32:48, 11.91s/it] 14%|█▍        | 127/896 [28:45<2:31:07, 11.79s/it] 14%|█▍        | 128/896 [28:56<2:29:49, 11.70s/it] 14%|█▍        | 129/896 [29:08<2:28:52, 11.65s/it] 15%|█▍        | 130/896 [29:19<2:28:13, 11.61s/it] 15%|█▍        | 131/896 [29:31<2:27:31, 11.57s/it] 15%|█▍        | 132/896 [29:42<2:27:01, 11.55s/it] 15%|█▍        | 133/896 [29:54<2:26:30, 11.52s/it] 15%|█▍        | 134/896 [30:05<2:26:11, 11.51s/it] 15%|█▌        | 135/896 [30:17<2:25:54, 11.50s/it] 15%|█▌        | 136/896 [30:28<2:25:44, 11.51s/it] 15%|█▌        | 137/896 [30:40<2:25:26, 11.50s/it] 15%|█▌        | 138/896 [30:51<2:25:10, 11.49s/it] 16%|█▌        | 139/896 [31:03<2:25:00, 11.49s/it] 16%|█▌        | 140/896 [31:14<2:24:43, 11.49s/it] 16%|█▌        | 141/896 [31:26<2:24:33, 11.49s/it] 16%|█▌        | 142/896 [31:37<2:24:21, 11.49s/it] 16%|█▌        | 143/896 [31:49<2:24:09, 11.49s/it] 16%|█▌        | 144/896 [32:00<2:24:04, 11.50s/it] 16%|█▌        | 145/896 [32:12<2:23:52, 11.49s/it] 16%|█▋        | 146/896 [32:23<2:23:43, 11.50s/it] 16%|█▋        | 147/896 [32:35<2:23:30, 11.50s/it] 17%|█▋        | 148/896 [32:46<2:23:14, 11.49s/it] 17%|█▋        | 149/896 [32:58<2:23:02, 11.49s/it] 17%|█▋        | 150/896 [33:09<2:22:48, 11.49s/it] 17%|█▋        | 151/896 [33:21<2:22:42, 11.49s/it] 17%|█▋        | 152/896 [33:32<2:22:29, 11.49s/it] 17%|█▋        | 153/896 [33:44<2:22:18, 11.49s/it] 17%|█▋        | 154/896 [33:55<2:22:06, 11.49s/it] 17%|█▋        | 155/896 [34:07<2:21:53, 11.49s/it] 17%|█▋        | 156/896 [34:18<2:21:40, 11.49s/it] 18%|█▊        | 157/896 [34:30<2:21:28, 11.49s/it] 18%|█▊        | 158/896 [34:41<2:21:19, 11.49s/it] 18%|█▊        | 159/896 [34:53<2:21:08, 11.49s/it] 18%|█▊        | 160/896 [35:04<2:20:58, 11.49s/it] 18%|█▊        | 161/896 [35:16<2:20:45, 11.49s/it] 18%|█▊        | 162/896 [35:27<2:20:35, 11.49s/it] 18%|█▊        | 163/896 [35:39<2:20:24, 11.49s/it] 18%|█▊        | 164/896 [35:50<2:20:14, 11.50s/it] 18%|█▊        | 165/896 [36:02<2:20:05, 11.50s/it] 19%|█▊        | 166/896 [36:13<2:19:50, 11.49s/it] 19%|█▊        | 167/896 [36:25<2:19:42, 11.50s/it] 19%|█▉        | 168/896 [36:36<2:19:34, 11.50s/it][INFO|trainer.py:749] 2023-08-03 23:29:05,023 >> The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: sentence, context, id. If sentence, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3083] 2023-08-03 23:29:05,025 >> ***** Running Evaluation *****
[INFO|trainer.py:3085] 2023-08-03 23:29:05,025 >>   Num examples = 400
[INFO|trainer.py:3088] 2023-08-03 23:29:05,026 >>   Batch size = 8
{'eval_loss': 0.584882915019989, 'eval_accuracy': 0.79, 'eval_runtime': 25.5037, 'eval_samples_per_second': 15.684, 'eval_steps_per_second': 1.96, 'epoch': 1.99}

  0%|          | 0/50 [00:00<?, ?it/s][A
  4%|▍         | 2/50 [00:00<00:12,  3.93it/s][A
  6%|▌         | 3/50 [00:01<00:16,  2.79it/s][A
  8%|▊         | 4/50 [00:01<00:19,  2.41it/s][A
 10%|█         | 5/50 [00:02<00:20,  2.24it/s][A
 12%|█▏        | 6/50 [00:02<00:20,  2.14it/s][A
 14%|█▍        | 7/50 [00:03<00:20,  2.08it/s][A
 16%|█▌        | 8/50 [00:03<00:20,  2.05it/s][A
 18%|█▊        | 9/50 [00:04<00:20,  2.02it/s][A
 20%|██        | 10/50 [00:04<00:19,  2.01it/s][A
 22%|██▏       | 11/50 [00:05<00:19,  1.99it/s][A
 24%|██▍       | 12/50 [00:05<00:19,  1.99it/s][A
 26%|██▌       | 13/50 [00:06<00:18,  1.98it/s][A
 28%|██▊       | 14/50 [00:06<00:18,  1.97it/s][A
 30%|███       | 15/50 [00:07<00:17,  1.98it/s][A
 32%|███▏      | 16/50 [00:07<00:17,  1.98it/s][A
 34%|███▍      | 17/50 [00:08<00:16,  1.98it/s][A
 36%|███▌      | 18/50 [00:08<00:16,  1.98it/s][A
 38%|███▊      | 19/50 [00:09<00:15,  1.98it/s][A
 40%|████      | 20/50 [00:09<00:15,  1.98it/s][A
 42%|████▏     | 21/50 [00:10<00:14,  1.98it/s][A
 44%|████▍     | 22/50 [00:10<00:14,  1.98it/s][A
 46%|████▌     | 23/50 [00:11<00:13,  1.97it/s][A
 48%|████▊     | 24/50 [00:11<00:13,  1.97it/s][A
 50%|█████     | 25/50 [00:12<00:12,  1.97it/s][A
 52%|█████▏    | 26/50 [00:12<00:12,  1.97it/s][A
 54%|█████▍    | 27/50 [00:13<00:11,  1.97it/s][A
 56%|█████▌    | 28/50 [00:13<00:11,  1.97it/s][A
 58%|█████▊    | 29/50 [00:14<00:10,  1.97it/s][A
 60%|██████    | 30/50 [00:14<00:10,  1.97it/s][A
 62%|██████▏   | 31/50 [00:15<00:09,  1.97it/s][A
 64%|██████▍   | 32/50 [00:15<00:09,  1.97it/s][A
 66%|██████▌   | 33/50 [00:16<00:08,  1.97it/s][A
 68%|██████▊   | 34/50 [00:16<00:08,  1.97it/s][A
 70%|███████   | 35/50 [00:17<00:07,  1.97it/s][A
 72%|███████▏  | 36/50 [00:17<00:07,  1.97it/s][A
 74%|███████▍  | 37/50 [00:18<00:06,  1.97it/s][A
 76%|███████▌  | 38/50 [00:18<00:06,  1.97it/s][A
 78%|███████▊  | 39/50 [00:19<00:05,  1.97it/s][A
 80%|████████  | 40/50 [00:19<00:05,  1.97it/s][A
 82%|████████▏ | 41/50 [00:20<00:04,  1.97it/s][A
 84%|████████▍ | 42/50 [00:20<00:04,  1.97it/s][A
 86%|████████▌ | 43/50 [00:21<00:03,  1.97it/s][A
 88%|████████▊ | 44/50 [00:21<00:03,  1.97it/s][A
 90%|█████████ | 45/50 [00:22<00:02,  1.97it/s][A
 92%|█████████▏| 46/50 [00:22<00:02,  1.97it/s][A
 94%|█████████▍| 47/50 [00:23<00:01,  1.97it/s][A
 96%|█████████▌| 48/50 [00:23<00:01,  1.98it/s][A
 98%|█████████▊| 49/50 [00:24<00:00,  1.97it/s][A
100%|██████████| 50/50 [00:24<00:00,  1.98it/s][A                                                   
                                               [A 19%|█▉        | 168/896 [37:10<2:19:34, 11.50s/it]
100%|██████████| 50/50 [00:24<00:00,  1.98it/s][A
                                               [A[INFO|trainer.py:2809] 2023-08-03 23:29:30,413 >> Saving model checkpoint to ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-168
[INFO|configuration_utils.py:460] 2023-08-03 23:29:30,417 >> Configuration saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-168/config.json
[INFO|modeling_utils.py:1874] 2023-08-03 23:30:04,791 >> Model weights saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-168/pytorch_model.bin
[INFO|tokenization_utils_base.py:2227] 2023-08-03 23:30:04,797 >> tokenizer config file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-168/tokenizer_config.json
[INFO|tokenization_utils_base.py:2234] 2023-08-03 23:30:04,799 >> Special tokens file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-168/special_tokens_map.json
 19%|█▉        | 169/896 [39:04<10:34:54, 52.40s/it] 19%|█▉        | 170/896 [39:15<8:04:55, 40.08s/it]  19%|█▉        | 171/896 [39:27<6:20:13, 31.47s/it] 19%|█▉        | 172/896 [39:38<5:07:06, 25.45s/it] 19%|█▉        | 173/896 [39:49<4:16:00, 21.25s/it] 19%|█▉        | 174/896 [40:01<3:40:22, 18.31s/it] 20%|█▉        | 175/896 [40:12<3:15:33, 16.27s/it] 20%|█▉        | 176/896 [40:24<2:58:10, 14.85s/it] 20%|█▉        | 177/896 [40:35<2:45:57, 13.85s/it] 20%|█▉        | 178/896 [40:47<2:37:17, 13.14s/it] 20%|█▉        | 179/896 [40:59<2:31:15, 12.66s/it] 20%|██        | 180/896 [41:10<2:27:00, 12.32s/it] 20%|██        | 181/896 [41:22<2:23:55, 12.08s/it] 20%|██        | 182/896 [41:33<2:21:42, 11.91s/it] 20%|██        | 183/896 [41:45<2:20:04, 11.79s/it] 21%|██        | 184/896 [41:56<2:18:52, 11.70s/it] 21%|██        | 185/896 [42:08<2:17:58, 11.64s/it] 21%|██        | 186/896 [42:19<2:17:17, 11.60s/it] 21%|██        | 187/896 [42:31<2:16:45, 11.57s/it] 21%|██        | 188/896 [42:42<2:16:16, 11.55s/it] 21%|██        | 189/896 [42:54<2:15:56, 11.54s/it] 21%|██        | 190/896 [43:05<2:15:38, 11.53s/it] 21%|██▏       | 191/896 [43:17<2:15:21, 11.52s/it] 21%|██▏       | 192/896 [43:28<2:15:07, 11.52s/it] 22%|██▏       | 193/896 [43:40<2:14:50, 11.51s/it] 22%|██▏       | 194/896 [43:51<2:14:40, 11.51s/it] 22%|██▏       | 195/896 [44:03<2:14:27, 11.51s/it] 22%|██▏       | 196/896 [44:14<2:14:16, 11.51s/it] 22%|██▏       | 197/896 [44:26<2:14:02, 11.51s/it] 22%|██▏       | 198/896 [44:37<2:13:44, 11.50s/it] 22%|██▏       | 199/896 [44:49<2:13:35, 11.50s/it] 22%|██▏       | 200/896 [45:00<2:13:20, 11.49s/it] 22%|██▏       | 201/896 [45:12<2:13:08, 11.49s/it] 23%|██▎       | 202/896 [45:23<2:12:55, 11.49s/it] 23%|██▎       | 203/896 [45:35<2:12:46, 11.50s/it] 23%|██▎       | 204/896 [45:46<2:12:32, 11.49s/it] 23%|██▎       | 205/896 [45:58<2:12:25, 11.50s/it] 23%|██▎       | 206/896 [46:09<2:12:17, 11.50s/it] 23%|██▎       | 207/896 [46:21<2:12:02, 11.50s/it] 23%|██▎       | 208/896 [46:32<2:11:50, 11.50s/it] 23%|██▎       | 209/896 [46:44<2:11:41, 11.50s/it] 23%|██▎       | 210/896 [46:55<2:11:23, 11.49s/it] 24%|██▎       | 211/896 [47:07<2:11:12, 11.49s/it] 24%|██▎       | 212/896 [47:18<2:11:02, 11.50s/it] 24%|██▍       | 213/896 [47:30<2:10:56, 11.50s/it] 24%|██▍       | 214/896 [47:41<2:10:44, 11.50s/it] 24%|██▍       | 215/896 [47:53<2:10:34, 11.50s/it] 24%|██▍       | 216/896 [48:04<2:10:25, 11.51s/it] 24%|██▍       | 217/896 [48:16<2:10:12, 11.51s/it] 24%|██▍       | 218/896 [48:27<2:10:01, 11.51s/it] 24%|██▍       | 219/896 [48:39<2:09:48, 11.50s/it] 25%|██▍       | 220/896 [48:50<2:09:32, 11.50s/it] 25%|██▍       | 221/896 [49:02<2:09:19, 11.50s/it] 25%|██▍       | 222/896 [49:13<2:09:04, 11.49s/it] 25%|██▍       | 223/896 [49:25<2:08:56, 11.49s/it] 25%|██▌       | 224/896 [49:36<2:08:46, 11.50s/it] 25%|██▌       | 225/896 [49:48<2:08:31, 11.49s/it][INFO|trainer.py:749] 2023-08-03 23:42:07,859 >> The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: sentence, context, id. If sentence, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3083] 2023-08-03 23:42:07,861 >> ***** Running Evaluation *****
[INFO|trainer.py:3085] 2023-08-03 23:42:07,861 >>   Num examples = 400
[INFO|trainer.py:3088] 2023-08-03 23:42:07,861 >>   Batch size = 8
{'eval_loss': 0.39916905760765076, 'eval_accuracy': 0.86, 'eval_runtime': 25.3769, 'eval_samples_per_second': 15.762, 'eval_steps_per_second': 1.97, 'epoch': 2.99}

  0%|          | 0/50 [00:00<?, ?it/s][A
  4%|▍         | 2/50 [00:00<00:12,  3.93it/s][A
  6%|▌         | 3/50 [00:01<00:16,  2.79it/s][A
  8%|▊         | 4/50 [00:01<00:19,  2.42it/s][A
 10%|█         | 5/50 [00:02<00:20,  2.24it/s][A
 12%|█▏        | 6/50 [00:02<00:20,  2.15it/s][A
 14%|█▍        | 7/50 [00:03<00:20,  2.09it/s][A
 16%|█▌        | 8/50 [00:03<00:20,  2.06it/s][A
 18%|█▊        | 9/50 [00:04<00:20,  2.03it/s][A
 20%|██        | 10/50 [00:04<00:19,  2.02it/s][A
 22%|██▏       | 11/50 [00:05<00:19,  2.00it/s][A
 24%|██▍       | 12/50 [00:05<00:19,  1.99it/s][A
 26%|██▌       | 13/50 [00:06<00:18,  1.98it/s][A
 28%|██▊       | 14/50 [00:06<00:18,  1.98it/s][A
 30%|███       | 15/50 [00:07<00:17,  1.98it/s][A
 32%|███▏      | 16/50 [00:07<00:17,  1.98it/s][A
 34%|███▍      | 17/50 [00:08<00:16,  1.98it/s][A
 36%|███▌      | 18/50 [00:08<00:16,  1.98it/s][A
 38%|███▊      | 19/50 [00:09<00:15,  1.98it/s][A
 40%|████      | 20/50 [00:09<00:15,  1.98it/s][A
 42%|████▏     | 21/50 [00:10<00:14,  1.98it/s][A
 44%|████▍     | 22/50 [00:10<00:14,  1.98it/s][A
 46%|████▌     | 23/50 [00:11<00:13,  1.98it/s][A
 48%|████▊     | 24/50 [00:11<00:13,  1.97it/s][A
 50%|█████     | 25/50 [00:12<00:12,  1.97it/s][A
 52%|█████▏    | 26/50 [00:12<00:12,  1.97it/s][A
 54%|█████▍    | 27/50 [00:13<00:11,  1.97it/s][A
 56%|█████▌    | 28/50 [00:13<00:11,  1.97it/s][A
 58%|█████▊    | 29/50 [00:14<00:10,  1.98it/s][A
 60%|██████    | 30/50 [00:14<00:10,  1.98it/s][A
 62%|██████▏   | 31/50 [00:15<00:09,  1.98it/s][A
 64%|██████▍   | 32/50 [00:15<00:09,  1.97it/s][A
 66%|██████▌   | 33/50 [00:16<00:08,  1.97it/s][A
 68%|██████▊   | 34/50 [00:16<00:08,  1.97it/s][A
 70%|███████   | 35/50 [00:17<00:07,  1.97it/s][A
 72%|███████▏  | 36/50 [00:17<00:07,  1.97it/s][A
 74%|███████▍  | 37/50 [00:18<00:06,  1.98it/s][A
 76%|███████▌  | 38/50 [00:18<00:06,  1.98it/s][A
 78%|███████▊  | 39/50 [00:19<00:05,  1.98it/s][A
 80%|████████  | 40/50 [00:19<00:05,  1.97it/s][A
 82%|████████▏ | 41/50 [00:20<00:04,  1.97it/s][A
 84%|████████▍ | 42/50 [00:20<00:04,  1.98it/s][A
 86%|████████▌ | 43/50 [00:21<00:03,  1.97it/s][A
 88%|████████▊ | 44/50 [00:21<00:03,  1.98it/s][A
 90%|█████████ | 45/50 [00:22<00:02,  1.98it/s][A
 92%|█████████▏| 46/50 [00:22<00:02,  1.98it/s][A
 94%|█████████▍| 47/50 [00:23<00:01,  1.98it/s][A
 96%|█████████▌| 48/50 [00:23<00:01,  1.98it/s][A
 98%|█████████▊| 49/50 [00:24<00:00,  1.98it/s][A
100%|██████████| 50/50 [00:24<00:00,  1.98it/s][A                                                   
                                               [A 25%|██▌       | 225/896 [50:13<2:08:31, 11.49s/it]
100%|██████████| 50/50 [00:24<00:00,  1.98it/s][A
                                               [A[INFO|trainer.py:2809] 2023-08-03 23:42:33,258 >> Saving model checkpoint to ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-225
[INFO|configuration_utils.py:460] 2023-08-03 23:42:33,267 >> Configuration saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-225/config.json
[INFO|modeling_utils.py:1874] 2023-08-03 23:43:09,054 >> Model weights saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-225/pytorch_model.bin
[INFO|tokenization_utils_base.py:2227] 2023-08-03 23:43:09,058 >> tokenizer config file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-225/tokenizer_config.json
[INFO|tokenization_utils_base.py:2234] 2023-08-03 23:43:09,059 >> Special tokens file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-225/special_tokens_map.json
 25%|██▌       | 226/896 [52:28<10:26:06, 56.07s/it] 25%|██▌       | 227/896 [52:39<7:55:38, 42.66s/it]  25%|██▌       | 228/896 [52:50<6:10:22, 33.27s/it] 26%|██▌       | 229/896 [53:02<4:56:59, 26.72s/it] 26%|██▌       | 230/896 [53:13<4:05:46, 22.14s/it] 26%|██▌       | 231/896 [53:25<3:29:55, 18.94s/it] 26%|██▌       | 232/896 [53:36<3:04:45, 16.69s/it] 26%|██▌       | 233/896 [53:48<2:47:16, 15.14s/it] 26%|██▌       | 234/896 [53:59<2:34:51, 14.04s/it] 26%|██▌       | 235/896 [54:11<2:26:15, 13.28s/it] 26%|██▋       | 236/896 [54:22<2:20:08, 12.74s/it] 26%|██▋       | 237/896 [54:34<2:15:47, 12.36s/it] 27%|██▋       | 238/896 [54:45<2:12:44, 12.10s/it] 27%|██▋       | 239/896 [54:57<2:10:32, 11.92s/it] 27%|██▋       | 240/896 [55:08<2:08:55, 11.79s/it] 27%|██▋       | 241/896 [55:20<2:07:41, 11.70s/it] 27%|██▋       | 242/896 [55:31<2:06:51, 11.64s/it] 27%|██▋       | 243/896 [55:43<2:06:03, 11.58s/it] 27%|██▋       | 244/896 [55:54<2:05:36, 11.56s/it] 27%|██▋       | 245/896 [56:06<2:05:09, 11.53s/it] 27%|██▋       | 246/896 [56:17<2:04:48, 11.52s/it] 28%|██▊       | 247/896 [56:28<2:04:31, 11.51s/it] 28%|██▊       | 248/896 [56:40<2:04:14, 11.50s/it] 28%|██▊       | 249/896 [56:51<2:03:53, 11.49s/it] 28%|██▊       | 250/896 [57:03<2:03:39, 11.49s/it] 28%|██▊       | 251/896 [57:14<2:03:28, 11.49s/it] 28%|██▊       | 252/896 [57:26<2:03:12, 11.48s/it] 28%|██▊       | 253/896 [57:37<2:03:02, 11.48s/it] 28%|██▊       | 254/896 [57:49<2:02:52, 11.48s/it] 28%|██▊       | 255/896 [58:00<2:02:43, 11.49s/it] 29%|██▊       | 256/896 [58:12<2:02:29, 11.48s/it] 29%|██▊       | 257/896 [58:23<2:02:13, 11.48s/it] 29%|██▉       | 258/896 [58:35<2:02:08, 11.49s/it] 29%|██▉       | 259/896 [58:46<2:01:56, 11.49s/it] 29%|██▉       | 260/896 [58:58<2:01:37, 11.47s/it] 29%|██▉       | 261/896 [59:09<2:01:27, 11.48s/it] 29%|██▉       | 262/896 [59:21<2:01:14, 11.47s/it] 29%|██▉       | 263/896 [59:32<2:01:08, 11.48s/it] 29%|██▉       | 264/896 [59:44<2:00:59, 11.49s/it] 30%|██▉       | 265/896 [59:55<2:00:43, 11.48s/it] 30%|██▉       | 266/896 [1:00:07<2:00:34, 11.48s/it] 30%|██▉       | 267/896 [1:00:18<2:00:24, 11.49s/it] 30%|██▉       | 268/896 [1:00:30<2:00:10, 11.48s/it] 30%|███       | 269/896 [1:00:41<2:00:04, 11.49s/it] 30%|███       | 270/896 [1:00:53<1:59:49, 11.48s/it] 30%|███       | 271/896 [1:01:04<1:59:41, 11.49s/it] 30%|███       | 272/896 [1:01:16<1:59:31, 11.49s/it] 30%|███       | 273/896 [1:01:27<1:59:25, 11.50s/it] 31%|███       | 274/896 [1:01:39<1:59:19, 11.51s/it] 31%|███       | 275/896 [1:01:50<1:59:11, 11.52s/it] 31%|███       | 276/896 [1:02:02<1:59:01, 11.52s/it] 31%|███       | 277/896 [1:02:13<1:58:47, 11.51s/it] 31%|███       | 278/896 [1:02:25<1:58:38, 11.52s/it] 31%|███       | 279/896 [1:02:36<1:58:26, 11.52s/it] 31%|███▏      | 280/896 [1:02:48<1:58:16, 11.52s/it] 31%|███▏      | 281/896 [1:02:59<1:58:02, 11.52s/it][INFO|trainer.py:749] 2023-08-03 23:55:22,443 >> The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: sentence, context, id. If sentence, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3083] 2023-08-03 23:55:22,445 >> ***** Running Evaluation *****
[INFO|trainer.py:3085] 2023-08-03 23:55:22,445 >>   Num examples = 400
[INFO|trainer.py:3088] 2023-08-03 23:55:22,446 >>   Batch size = 8
{'eval_loss': 0.25373849272727966, 'eval_accuracy': 0.9, 'eval_runtime': 25.3707, 'eval_samples_per_second': 15.766, 'eval_steps_per_second': 1.971, 'epoch': 4.0}

  0%|          | 0/50 [00:00<?, ?it/s][A
  4%|▍         | 2/50 [00:00<00:12,  3.93it/s][A
  6%|▌         | 3/50 [00:01<00:16,  2.78it/s][A
  8%|▊         | 4/50 [00:01<00:19,  2.41it/s][A
 10%|█         | 5/50 [00:02<00:20,  2.24it/s][A
 12%|█▏        | 6/50 [00:02<00:20,  2.14it/s][A
 14%|█▍        | 7/50 [00:03<00:20,  2.08it/s][A
 16%|█▌        | 8/50 [00:03<00:20,  2.05it/s][A
 18%|█▊        | 9/50 [00:04<00:20,  2.02it/s][A
 20%|██        | 10/50 [00:04<00:19,  2.00it/s][A
 22%|██▏       | 11/50 [00:05<00:19,  1.99it/s][A
 24%|██▍       | 12/50 [00:05<00:19,  1.98it/s][A
 26%|██▌       | 13/50 [00:06<00:18,  1.98it/s][A
 28%|██▊       | 14/50 [00:06<00:18,  1.97it/s][A
 30%|███       | 15/50 [00:07<00:17,  1.97it/s][A
 32%|███▏      | 16/50 [00:07<00:17,  1.97it/s][A
 34%|███▍      | 17/50 [00:08<00:16,  1.97it/s][A
 36%|███▌      | 18/50 [00:08<00:16,  1.97it/s][A
 38%|███▊      | 19/50 [00:09<00:15,  1.97it/s][A
 40%|████      | 20/50 [00:09<00:15,  1.98it/s][A
 42%|████▏     | 21/50 [00:10<00:14,  1.98it/s][A
 44%|████▍     | 22/50 [00:10<00:14,  1.98it/s][A
 46%|████▌     | 23/50 [00:11<00:13,  1.97it/s][A
 48%|████▊     | 24/50 [00:11<00:13,  1.97it/s][A
 50%|█████     | 25/50 [00:12<00:12,  1.97it/s][A
 52%|█████▏    | 26/50 [00:12<00:12,  1.97it/s][A
 54%|█████▍    | 27/50 [00:13<00:11,  1.96it/s][A
 56%|█████▌    | 28/50 [00:13<00:11,  1.97it/s][A
 58%|█████▊    | 29/50 [00:14<00:10,  1.97it/s][A
 60%|██████    | 30/50 [00:14<00:10,  1.97it/s][A
 62%|██████▏   | 31/50 [00:15<00:09,  1.97it/s][A
 64%|██████▍   | 32/50 [00:15<00:09,  1.97it/s][A
 66%|██████▌   | 33/50 [00:16<00:08,  1.96it/s][A
 68%|██████▊   | 34/50 [00:16<00:08,  1.97it/s][A
 70%|███████   | 35/50 [00:17<00:07,  1.96it/s][A
 72%|███████▏  | 36/50 [00:17<00:07,  1.97it/s][A
 74%|███████▍  | 37/50 [00:18<00:06,  1.97it/s][A
 76%|███████▌  | 38/50 [00:18<00:06,  1.97it/s][A
 78%|███████▊  | 39/50 [00:19<00:05,  1.97it/s][A
 80%|████████  | 40/50 [00:19<00:05,  1.97it/s][A
 82%|████████▏ | 41/50 [00:20<00:04,  1.97it/s][A
 84%|████████▍ | 42/50 [00:20<00:04,  1.97it/s][A
 86%|████████▌ | 43/50 [00:21<00:03,  1.96it/s][A
 88%|████████▊ | 44/50 [00:21<00:03,  1.97it/s][A
 90%|█████████ | 45/50 [00:22<00:02,  1.97it/s][A
 92%|█████████▏| 46/50 [00:22<00:02,  1.97it/s][A
 94%|█████████▍| 47/50 [00:23<00:01,  1.97it/s][A
 96%|█████████▌| 48/50 [00:23<00:01,  1.97it/s][A
 98%|█████████▊| 49/50 [00:24<00:00,  1.97it/s][A
100%|██████████| 50/50 [00:24<00:00,  1.97it/s][A                                                     
                                               [A 31%|███▏      | 281/896 [1:03:28<1:58:02, 11.52s/it]
100%|██████████| 50/50 [00:24<00:00,  1.97it/s][A
                                               [A[INFO|trainer.py:2809] 2023-08-03 23:55:47,871 >> Saving model checkpoint to ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-281
[INFO|configuration_utils.py:460] 2023-08-03 23:55:47,873 >> Configuration saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-281/config.json
[INFO|modeling_utils.py:1874] 2023-08-03 23:56:22,272 >> Model weights saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-281/pytorch_model.bin
[INFO|tokenization_utils_base.py:2227] 2023-08-03 23:56:22,276 >> tokenizer config file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-281/tokenizer_config.json
[INFO|tokenization_utils_base.py:2234] 2023-08-03 23:56:22,277 >> Special tokens file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-281/special_tokens_map.json
 31%|███▏      | 282/896 [1:05:37<9:27:42, 55.48s/it] 32%|███▏      | 283/896 [1:05:49<7:11:37, 42.25s/it] 32%|███▏      | 284/896 [1:06:00<5:36:32, 32.99s/it] 32%|███▏      | 285/896 [1:06:12<4:30:12, 26.53s/it] 32%|███▏      | 286/896 [1:06:23<3:43:53, 22.02s/it] 32%|███▏      | 287/896 [1:06:35<3:11:23, 18.86s/it] 32%|███▏      | 288/896 [1:06:46<2:48:41, 16.65s/it] 32%|███▏      | 289/896 [1:06:57<2:32:44, 15.10s/it] 32%|███▏      | 290/896 [1:07:09<2:21:33, 14.02s/it] 32%|███▏      | 291/896 [1:07:20<2:13:36, 13.25s/it] 33%|███▎      | 292/896 [1:07:32<2:08:05, 12.72s/it] 33%|███▎      | 293/896 [1:07:43<2:04:12, 12.36s/it] 33%|███▎      | 294/896 [1:07:55<2:01:23, 12.10s/it] 33%|███▎      | 295/896 [1:08:06<1:59:23, 11.92s/it] 33%|███▎      | 296/896 [1:08:18<1:57:52, 11.79s/it] 33%|███▎      | 297/896 [1:08:29<1:56:46, 11.70s/it] 33%|███▎      | 298/896 [1:08:41<1:55:58, 11.64s/it] 33%|███▎      | 299/896 [1:08:52<1:55:23, 11.60s/it] 33%|███▎      | 300/896 [1:09:04<1:54:51, 11.56s/it] 34%|███▎      | 301/896 [1:09:15<1:54:27, 11.54s/it] 34%|███▎      | 302/896 [1:09:27<1:54:09, 11.53s/it] 34%|███▍      | 303/896 [1:09:38<1:53:53, 11.52s/it] 34%|███▍      | 304/896 [1:09:50<1:53:36, 11.51s/it] 34%|███▍      | 305/896 [1:10:01<1:53:17, 11.50s/it] 34%|███▍      | 306/896 [1:10:13<1:53:03, 11.50s/it] 34%|███▍      | 307/896 [1:10:24<1:52:49, 11.49s/it] 34%|███▍      | 308/896 [1:10:36<1:52:40, 11.50s/it] 34%|███▍      | 309/896 [1:10:47<1:52:27, 11.49s/it] 35%|███▍      | 310/896 [1:10:59<1:52:13, 11.49s/it] 35%|███▍      | 311/896 [1:11:10<1:51:57, 11.48s/it] 35%|███▍      | 312/896 [1:11:22<1:51:46, 11.48s/it] 35%|███▍      | 313/896 [1:11:33<1:51:33, 11.48s/it] 35%|███▌      | 314/896 [1:11:45<1:51:26, 11.49s/it] 35%|███▌      | 315/896 [1:11:56<1:51:08, 11.48s/it] 35%|███▌      | 316/896 [1:12:08<1:50:56, 11.48s/it] 35%|███▌      | 317/896 [1:12:19<1:50:49, 11.48s/it] 35%|███▌      | 318/896 [1:12:31<1:50:35, 11.48s/it] 36%|███▌      | 319/896 [1:12:42<1:50:26, 11.48s/it] 36%|███▌      | 320/896 [1:12:54<1:50:15, 11.49s/it] 36%|███▌      | 321/896 [1:13:05<1:50:00, 11.48s/it] 36%|███▌      | 322/896 [1:13:17<1:49:50, 11.48s/it] 36%|███▌      | 323/896 [1:13:28<1:49:41, 11.49s/it] 36%|███▌      | 324/896 [1:13:40<1:49:31, 11.49s/it] 36%|███▋      | 325/896 [1:13:51<1:49:15, 11.48s/it] 36%|███▋      | 326/896 [1:14:02<1:49:00, 11.48s/it] 36%|███▋      | 327/896 [1:14:14<1:48:53, 11.48s/it] 37%|███▋      | 328/896 [1:14:25<1:48:43, 11.49s/it] 37%|███▋      | 329/896 [1:14:37<1:48:29, 11.48s/it] 37%|███▋      | 330/896 [1:14:48<1:48:19, 11.48s/it] 37%|███▋      | 331/896 [1:15:00<1:48:00, 11.47s/it] 37%|███▋      | 332/896 [1:15:11<1:47:51, 11.47s/it] 37%|███▋      | 333/896 [1:15:23<1:47:44, 11.48s/it] 37%|███▋      | 334/896 [1:15:34<1:47:30, 11.48s/it] 37%|███▋      | 335/896 [1:15:46<1:47:24, 11.49s/it] 38%|███▊      | 336/896 [1:15:57<1:47:11, 11.49s/it] 38%|███▊      | 337/896 [1:16:09<1:46:59, 11.48s/it][INFO|trainer.py:749] 2023-08-04 00:08:34,834 >> The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: sentence, context, id. If sentence, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3083] 2023-08-04 00:08:34,836 >> ***** Running Evaluation *****
[INFO|trainer.py:3085] 2023-08-04 00:08:34,836 >>   Num examples = 400
[INFO|trainer.py:3088] 2023-08-04 00:08:34,836 >>   Batch size = 8
{'eval_loss': 0.135370135307312, 'eval_accuracy': 0.96, 'eval_runtime': 25.4179, 'eval_samples_per_second': 15.737, 'eval_steps_per_second': 1.967, 'epoch': 5.0}

  0%|          | 0/50 [00:00<?, ?it/s][A
  4%|▍         | 2/50 [00:00<00:12,  3.96it/s][A
  6%|▌         | 3/50 [00:01<00:16,  2.80it/s][A
  8%|▊         | 4/50 [00:01<00:19,  2.42it/s][A
 10%|█         | 5/50 [00:02<00:20,  2.25it/s][A
 12%|█▏        | 6/50 [00:02<00:20,  2.14it/s][A
 14%|█▍        | 7/50 [00:03<00:20,  2.08it/s][A
 16%|█▌        | 8/50 [00:03<00:20,  2.05it/s][A
 18%|█▊        | 9/50 [00:04<00:20,  2.02it/s][A
 20%|██        | 10/50 [00:04<00:19,  2.01it/s][A
 22%|██▏       | 11/50 [00:05<00:19,  2.00it/s][A
 24%|██▍       | 12/50 [00:05<00:19,  1.99it/s][A
 26%|██▌       | 13/50 [00:06<00:18,  1.98it/s][A
 28%|██▊       | 14/50 [00:06<00:18,  1.98it/s][A
 30%|███       | 15/50 [00:07<00:17,  1.98it/s][A
 32%|███▏      | 16/50 [00:07<00:17,  1.98it/s][A
 34%|███▍      | 17/50 [00:08<00:16,  1.98it/s][A
 36%|███▌      | 18/50 [00:08<00:16,  1.98it/s][A
 38%|███▊      | 19/50 [00:09<00:15,  1.98it/s][A
 40%|████      | 20/50 [00:09<00:15,  1.98it/s][A
 42%|████▏     | 21/50 [00:10<00:14,  1.98it/s][A
 44%|████▍     | 22/50 [00:10<00:14,  1.98it/s][A
 46%|████▌     | 23/50 [00:11<00:13,  1.98it/s][A
 48%|████▊     | 24/50 [00:11<00:13,  1.97it/s][A
 50%|█████     | 25/50 [00:12<00:12,  1.97it/s][A
 52%|█████▏    | 26/50 [00:12<00:12,  1.97it/s][A
 54%|█████▍    | 27/50 [00:13<00:11,  1.97it/s][A
 56%|█████▌    | 28/50 [00:13<00:11,  1.97it/s][A
 58%|█████▊    | 29/50 [00:14<00:10,  1.97it/s][A
 60%|██████    | 30/50 [00:14<00:10,  1.97it/s][A
 62%|██████▏   | 31/50 [00:15<00:09,  1.97it/s][A
 64%|██████▍   | 32/50 [00:15<00:09,  1.97it/s][A
 66%|██████▌   | 33/50 [00:16<00:08,  1.97it/s][A
 68%|██████▊   | 34/50 [00:16<00:08,  1.97it/s][A
 70%|███████   | 35/50 [00:17<00:07,  1.97it/s][A
 72%|███████▏  | 36/50 [00:17<00:07,  1.97it/s][A
 74%|███████▍  | 37/50 [00:18<00:06,  1.97it/s][A
 76%|███████▌  | 38/50 [00:18<00:06,  1.97it/s][A
 78%|███████▊  | 39/50 [00:19<00:05,  1.97it/s][A
 80%|████████  | 40/50 [00:19<00:05,  1.97it/s][A
 82%|████████▏ | 41/50 [00:20<00:04,  1.97it/s][A
 84%|████████▍ | 42/50 [00:20<00:04,  1.97it/s][A
 86%|████████▌ | 43/50 [00:21<00:03,  1.97it/s][A
 88%|████████▊ | 44/50 [00:21<00:03,  1.97it/s][A
 90%|█████████ | 45/50 [00:22<00:02,  1.97it/s][A
 92%|█████████▏| 46/50 [00:22<00:02,  1.97it/s][A
 94%|█████████▍| 47/50 [00:23<00:01,  1.98it/s][A
 96%|█████████▌| 48/50 [00:23<00:01,  1.98it/s][A
 98%|█████████▊| 49/50 [00:24<00:00,  1.98it/s][A
100%|██████████| 50/50 [00:24<00:00,  1.98it/s][A                                                     
                                               [A 38%|███▊      | 337/896 [1:16:40<1:46:59, 11.48s/it]
100%|██████████| 50/50 [00:24<00:00,  1.98it/s][A
                                               [A[INFO|trainer.py:2809] 2023-08-04 00:09:00,202 >> Saving model checkpoint to ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-337
[INFO|configuration_utils.py:460] 2023-08-04 00:09:00,205 >> Configuration saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-337/config.json
[INFO|modeling_utils.py:1874] 2023-08-04 00:09:37,592 >> Model weights saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-337/pytorch_model.bin
[INFO|tokenization_utils_base.py:2227] 2023-08-04 00:09:37,596 >> tokenizer config file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-337/tokenizer_config.json
[INFO|tokenization_utils_base.py:2234] 2023-08-04 00:09:37,598 >> Special tokens file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-337/special_tokens_map.json
 38%|███▊      | 338/896 [1:18:55<8:58:54, 57.95s/it] 38%|███▊      | 339/896 [1:19:07<6:48:10, 43.97s/it] 38%|███▊      | 340/896 [1:19:18<5:16:50, 34.19s/it] 38%|███▊      | 341/896 [1:19:29<4:13:02, 27.36s/it] 38%|███▊      | 342/896 [1:19:41<3:28:30, 22.58s/it] 38%|███▊      | 343/896 [1:19:52<2:57:26, 19.25s/it] 38%|███▊      | 344/896 [1:20:04<2:35:42, 16.92s/it] 39%|███▊      | 345/896 [1:20:15<2:20:27, 15.30s/it] 39%|███▊      | 346/896 [1:20:27<2:09:45, 14.16s/it] 39%|███▊      | 347/896 [1:20:38<2:02:12, 13.36s/it] 39%|███▉      | 348/896 [1:20:50<1:56:52, 12.80s/it] 39%|███▉      | 349/896 [1:21:01<1:53:06, 12.41s/it] 39%|███▉      | 350/896 [1:21:13<1:50:22, 12.13s/it] 39%|███▉      | 351/896 [1:21:24<1:48:24, 11.94s/it] 39%|███▉      | 352/896 [1:21:36<1:46:58, 11.80s/it] 39%|███▉      | 353/896 [1:21:47<1:45:51, 11.70s/it] 40%|███▉      | 354/896 [1:21:59<1:45:04, 11.63s/it] 40%|███▉      | 355/896 [1:22:10<1:44:27, 11.59s/it] 40%|███▉      | 356/896 [1:22:22<1:43:58, 11.55s/it] 40%|███▉      | 357/896 [1:22:33<1:43:29, 11.52s/it] 40%|███▉      | 358/896 [1:22:44<1:43:13, 11.51s/it] 40%|████      | 359/896 [1:22:56<1:42:53, 11.50s/it] 40%|████      | 360/896 [1:23:07<1:42:39, 11.49s/it] 40%|████      | 361/896 [1:23:19<1:42:24, 11.49s/it] 40%|████      | 362/896 [1:23:30<1:42:12, 11.49s/it] 41%|████      | 363/896 [1:23:42<1:42:04, 11.49s/it] 41%|████      | 364/896 [1:23:53<1:41:55, 11.50s/it] 41%|████      | 365/896 [1:24:05<1:41:43, 11.49s/it] 41%|████      | 366/896 [1:24:16<1:41:32, 11.49s/it] 41%|████      | 367/896 [1:24:28<1:41:18, 11.49s/it] 41%|████      | 368/896 [1:24:39<1:41:07, 11.49s/it] 41%|████      | 369/896 [1:24:51<1:40:56, 11.49s/it] 41%|████▏     | 370/896 [1:25:02<1:40:42, 11.49s/it] 41%|████▏     | 371/896 [1:25:14<1:40:32, 11.49s/it] 42%|████▏     | 372/896 [1:25:25<1:40:22, 11.49s/it] 42%|████▏     | 373/896 [1:25:37<1:40:09, 11.49s/it] 42%|████▏     | 374/896 [1:25:48<1:40:00, 11.49s/it] 42%|████▏     | 375/896 [1:26:00<1:39:47, 11.49s/it] 42%|████▏     | 376/896 [1:26:11<1:39:37, 11.49s/it] 42%|████▏     | 377/896 [1:26:23<1:39:30, 11.50s/it] 42%|████▏     | 378/896 [1:26:34<1:39:15, 11.50s/it] 42%|████▏     | 379/896 [1:26:46<1:39:03, 11.50s/it] 42%|████▏     | 380/896 [1:26:57<1:38:48, 11.49s/it] 43%|████▎     | 381/896 [1:27:09<1:38:39, 11.49s/it] 43%|████▎     | 382/896 [1:27:20<1:38:27, 11.49s/it] 43%|████▎     | 383/896 [1:27:32<1:38:21, 11.50s/it] 43%|████▎     | 384/896 [1:27:43<1:38:11, 11.51s/it] 43%|████▎     | 385/896 [1:27:55<1:38:00, 11.51s/it] 43%|████▎     | 386/896 [1:28:06<1:37:41, 11.49s/it] 43%|████▎     | 387/896 [1:28:18<1:37:27, 11.49s/it] 43%|████▎     | 388/896 [1:28:29<1:37:20, 11.50s/it] 43%|████▎     | 389/896 [1:28:41<1:37:08, 11.50s/it] 44%|████▎     | 390/896 [1:28:52<1:36:59, 11.50s/it] 44%|████▎     | 391/896 [1:29:04<1:36:43, 11.49s/it] 44%|████▍     | 392/896 [1:29:15<1:36:33, 11.49s/it] 44%|████▍     | 393/896 [1:29:27<1:36:20, 11.49s/it][INFO|trainer.py:749] 2023-08-04 00:21:55,617 >> The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: sentence, context, id. If sentence, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3083] 2023-08-04 00:21:55,619 >> ***** Running Evaluation *****
[INFO|trainer.py:3085] 2023-08-04 00:21:55,619 >>   Num examples = 400
[INFO|trainer.py:3088] 2023-08-04 00:21:55,619 >>   Batch size = 8
{'eval_loss': 0.10497087240219116, 'eval_accuracy': 0.97, 'eval_runtime': 25.3559, 'eval_samples_per_second': 15.775, 'eval_steps_per_second': 1.972, 'epoch': 5.99}

  0%|          | 0/50 [00:00<?, ?it/s][A
  4%|▍         | 2/50 [00:00<00:12,  3.95it/s][A
  6%|▌         | 3/50 [00:01<00:16,  2.79it/s][A
  8%|▊         | 4/50 [00:01<00:19,  2.41it/s][A
 10%|█         | 5/50 [00:02<00:20,  2.24it/s][A
 12%|█▏        | 6/50 [00:02<00:20,  2.14it/s][A
 14%|█▍        | 7/50 [00:03<00:20,  2.08it/s][A
 16%|█▌        | 8/50 [00:03<00:20,  2.05it/s][A
 18%|█▊        | 9/50 [00:04<00:20,  2.02it/s][A
 20%|██        | 10/50 [00:04<00:19,  2.01it/s][A
 22%|██▏       | 11/50 [00:05<00:19,  1.99it/s][A
 24%|██▍       | 12/50 [00:05<00:19,  1.98it/s][A
 26%|██▌       | 13/50 [00:06<00:18,  1.98it/s][A
 28%|██▊       | 14/50 [00:06<00:18,  1.97it/s][A
 30%|███       | 15/50 [00:07<00:17,  1.97it/s][A
 32%|███▏      | 16/50 [00:07<00:17,  1.97it/s][A
 34%|███▍      | 17/50 [00:08<00:16,  1.97it/s][A
 36%|███▌      | 18/50 [00:08<00:16,  1.97it/s][A
 38%|███▊      | 19/50 [00:09<00:15,  1.98it/s][A
 40%|████      | 20/50 [00:09<00:15,  1.98it/s][A
 42%|████▏     | 21/50 [00:10<00:14,  1.98it/s][A
 44%|████▍     | 22/50 [00:10<00:14,  1.98it/s][A
 46%|████▌     | 23/50 [00:11<00:13,  1.97it/s][A
 48%|████▊     | 24/50 [00:11<00:13,  1.97it/s][A
 50%|█████     | 25/50 [00:12<00:12,  1.97it/s][A
 52%|█████▏    | 26/50 [00:12<00:12,  1.97it/s][A
 54%|█████▍    | 27/50 [00:13<00:11,  1.97it/s][A
 56%|█████▌    | 28/50 [00:13<00:11,  1.97it/s][A
 58%|█████▊    | 29/50 [00:14<00:10,  1.97it/s][A
 60%|██████    | 30/50 [00:14<00:10,  1.97it/s][A
 62%|██████▏   | 31/50 [00:15<00:09,  1.97it/s][A
 64%|██████▍   | 32/50 [00:15<00:09,  1.97it/s][A
 66%|██████▌   | 33/50 [00:16<00:08,  1.96it/s][A
 68%|██████▊   | 34/50 [00:16<00:08,  1.96it/s][A
 70%|███████   | 35/50 [00:17<00:07,  1.96it/s][A
 72%|███████▏  | 36/50 [00:17<00:07,  1.96it/s][A
 74%|███████▍  | 37/50 [00:18<00:06,  1.97it/s][A
 76%|███████▌  | 38/50 [00:18<00:06,  1.97it/s][A
 78%|███████▊  | 39/50 [00:19<00:05,  1.97it/s][A
 80%|████████  | 40/50 [00:19<00:05,  1.97it/s][A
 82%|████████▏ | 41/50 [00:20<00:04,  1.97it/s][A
 84%|████████▍ | 42/50 [00:20<00:04,  1.97it/s][A
 86%|████████▌ | 43/50 [00:21<00:03,  1.97it/s][A
 88%|████████▊ | 44/50 [00:21<00:03,  1.97it/s][A
 90%|█████████ | 45/50 [00:22<00:02,  1.97it/s][A
 92%|█████████▏| 46/50 [00:22<00:02,  1.97it/s][A
 94%|█████████▍| 47/50 [00:23<00:01,  1.97it/s][A
 96%|█████████▌| 48/50 [00:23<00:01,  1.97it/s][A
 98%|█████████▊| 49/50 [00:24<00:00,  1.97it/s][A
100%|██████████| 50/50 [00:24<00:00,  1.97it/s][A                                                     
                                               [A 44%|████▍     | 393/896 [1:30:01<1:36:20, 11.49s/it]
100%|██████████| 50/50 [00:24<00:00,  1.97it/s][A
                                               [A[INFO|trainer.py:2809] 2023-08-04 00:22:21,036 >> Saving model checkpoint to ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-393
[INFO|configuration_utils.py:460] 2023-08-04 00:22:21,039 >> Configuration saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-393/config.json
[INFO|modeling_utils.py:1874] 2023-08-04 00:22:55,949 >> Model weights saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-393/pytorch_model.bin
[INFO|tokenization_utils_base.py:2227] 2023-08-04 00:22:55,954 >> tokenizer config file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-393/tokenizer_config.json
[INFO|tokenization_utils_base.py:2234] 2023-08-04 00:22:55,956 >> Special tokens file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-393/special_tokens_map.json
 44%|████▍     | 394/896 [1:32:22<8:27:25, 60.65s/it] 44%|████▍     | 395/896 [1:32:33<6:23:06, 45.88s/it] 44%|████▍     | 396/896 [1:32:45<4:56:08, 35.54s/it] 44%|████▍     | 397/896 [1:32:56<3:55:23, 28.30s/it] 44%|████▍     | 398/896 [1:33:08<3:13:02, 23.26s/it] 45%|████▍     | 399/896 [1:33:19<2:43:19, 19.72s/it] 45%|████▍     | 400/896 [1:33:31<2:22:31, 17.24s/it] 45%|████▍     | 401/896 [1:33:42<2:07:58, 15.51s/it] 45%|████▍     | 402/896 [1:33:54<1:57:51, 14.32s/it] 45%|████▍     | 403/896 [1:34:05<1:50:40, 13.47s/it] 45%|████▌     | 404/896 [1:34:17<1:45:34, 12.87s/it] 45%|████▌     | 405/896 [1:34:28<1:41:58, 12.46s/it] 45%|████▌     | 406/896 [1:34:40<1:39:21, 12.17s/it] 45%|████▌     | 407/896 [1:34:51<1:37:28, 11.96s/it] 46%|████▌     | 408/896 [1:35:03<1:36:07, 11.82s/it] 46%|████▌     | 409/896 [1:35:14<1:35:07, 11.72s/it] 46%|████▌     | 410/896 [1:35:26<1:34:24, 11.66s/it] 46%|████▌     | 411/896 [1:35:37<1:33:46, 11.60s/it] 46%|████▌     | 412/896 [1:35:49<1:33:17, 11.57s/it] 46%|████▌     | 413/896 [1:36:00<1:32:54, 11.54s/it] 46%|████▌     | 414/896 [1:36:12<1:32:36, 11.53s/it] 46%|████▋     | 415/896 [1:36:23<1:32:21, 11.52s/it] 46%|████▋     | 416/896 [1:36:35<1:32:07, 11.51s/it] 47%|████▋     | 417/896 [1:36:46<1:31:51, 11.51s/it] 47%|████▋     | 418/896 [1:36:58<1:31:36, 11.50s/it] 47%|████▋     | 419/896 [1:37:09<1:31:26, 11.50s/it] 47%|████▋     | 420/896 [1:37:21<1:31:11, 11.49s/it] 47%|████▋     | 421/896 [1:37:32<1:30:58, 11.49s/it] 47%|████▋     | 422/896 [1:37:44<1:30:48, 11.50s/it] 47%|████▋     | 423/896 [1:37:55<1:30:38, 11.50s/it] 47%|████▋     | 424/896 [1:38:07<1:30:25, 11.49s/it] 47%|████▋     | 425/896 [1:38:18<1:30:12, 11.49s/it] 48%|████▊     | 426/896 [1:38:29<1:29:59, 11.49s/it] 48%|████▊     | 427/896 [1:38:41<1:29:46, 11.49s/it] 48%|████▊     | 428/896 [1:38:52<1:29:33, 11.48s/it] 48%|████▊     | 429/896 [1:39:04<1:29:25, 11.49s/it] 48%|████▊     | 430/896 [1:39:15<1:29:10, 11.48s/it] 48%|████▊     | 431/896 [1:39:27<1:29:01, 11.49s/it] 48%|████▊     | 432/896 [1:39:38<1:28:52, 11.49s/it] 48%|████▊     | 433/896 [1:39:50<1:28:41, 11.49s/it] 48%|████▊     | 434/896 [1:40:01<1:28:29, 11.49s/it] 49%|████▊     | 435/896 [1:40:13<1:28:15, 11.49s/it] 49%|████▊     | 436/896 [1:40:24<1:28:02, 11.48s/it] 49%|████▉     | 437/896 [1:40:36<1:27:50, 11.48s/it] 49%|████▉     | 438/896 [1:40:47<1:27:40, 11.49s/it] 49%|████▉     | 439/896 [1:40:59<1:27:27, 11.48s/it] 49%|████▉     | 440/896 [1:41:10<1:27:14, 11.48s/it] 49%|████▉     | 441/896 [1:41:22<1:27:03, 11.48s/it] 49%|████▉     | 442/896 [1:41:33<1:26:52, 11.48s/it] 49%|████▉     | 443/896 [1:41:45<1:26:42, 11.48s/it] 50%|████▉     | 444/896 [1:41:56<1:26:32, 11.49s/it] 50%|████▉     | 445/896 [1:42:08<1:26:21, 11.49s/it] 50%|████▉     | 446/896 [1:42:19<1:26:10, 11.49s/it] 50%|████▉     | 447/896 [1:42:31<1:26:01, 11.49s/it] 50%|█████     | 448/896 [1:42:42<1:25:48, 11.49s/it] 50%|█████     | 449/896 [1:42:54<1:25:34, 11.49s/it] 50%|█████     | 450/896 [1:43:05<1:25:23, 11.49s/it][INFO|trainer.py:749] 2023-08-04 00:35:25,462 >> The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: sentence, context, id. If sentence, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3083] 2023-08-04 00:35:25,464 >> ***** Running Evaluation *****
[INFO|trainer.py:3085] 2023-08-04 00:35:25,464 >>   Num examples = 400
[INFO|trainer.py:3088] 2023-08-04 00:35:25,464 >>   Batch size = 8
{'eval_loss': 0.046848364174366, 'eval_accuracy': 0.9875, 'eval_runtime': 25.4072, 'eval_samples_per_second': 15.744, 'eval_steps_per_second': 1.968, 'epoch': 6.99}

  0%|          | 0/50 [00:00<?, ?it/s][A
  4%|▍         | 2/50 [00:00<00:12,  3.94it/s][A
  6%|▌         | 3/50 [00:01<00:16,  2.78it/s][A
  8%|▊         | 4/50 [00:01<00:19,  2.41it/s][A
 10%|█         | 5/50 [00:02<00:20,  2.24it/s][A
 12%|█▏        | 6/50 [00:02<00:20,  2.14it/s][A
 14%|█▍        | 7/50 [00:03<00:20,  2.09it/s][A
 16%|█▌        | 8/50 [00:03<00:20,  2.05it/s][A
 18%|█▊        | 9/50 [00:04<00:20,  2.02it/s][A
 20%|██        | 10/50 [00:04<00:19,  2.01it/s][A
 22%|██▏       | 11/50 [00:05<00:19,  2.00it/s][A
 24%|██▍       | 12/50 [00:05<00:19,  1.99it/s][A
 26%|██▌       | 13/50 [00:06<00:18,  1.98it/s][A
 28%|██▊       | 14/50 [00:06<00:18,  1.97it/s][A
 30%|███       | 15/50 [00:07<00:17,  1.98it/s][A
 32%|███▏      | 16/50 [00:07<00:17,  1.97it/s][A
 34%|███▍      | 17/50 [00:08<00:16,  1.98it/s][A
 36%|███▌      | 18/50 [00:08<00:16,  1.98it/s][A
 38%|███▊      | 19/50 [00:09<00:15,  1.98it/s][A
 40%|████      | 20/50 [00:09<00:15,  1.98it/s][A
 42%|████▏     | 21/50 [00:10<00:14,  1.98it/s][A
 44%|████▍     | 22/50 [00:10<00:14,  1.98it/s][A
 46%|████▌     | 23/50 [00:11<00:13,  1.98it/s][A
 48%|████▊     | 24/50 [00:11<00:13,  1.97it/s][A
 50%|█████     | 25/50 [00:12<00:12,  1.97it/s][A
 52%|█████▏    | 26/50 [00:12<00:12,  1.97it/s][A
 54%|█████▍    | 27/50 [00:13<00:11,  1.97it/s][A
 56%|█████▌    | 28/50 [00:13<00:11,  1.97it/s][A
 58%|█████▊    | 29/50 [00:14<00:10,  1.97it/s][A
 60%|██████    | 30/50 [00:14<00:10,  1.97it/s][A
 62%|██████▏   | 31/50 [00:15<00:09,  1.97it/s][A
 64%|██████▍   | 32/50 [00:15<00:09,  1.97it/s][A
 66%|██████▌   | 33/50 [00:16<00:08,  1.97it/s][A
 68%|██████▊   | 34/50 [00:16<00:08,  1.97it/s][A
 70%|███████   | 35/50 [00:17<00:07,  1.97it/s][A
 72%|███████▏  | 36/50 [00:17<00:07,  1.97it/s][A
 74%|███████▍  | 37/50 [00:18<00:06,  1.97it/s][A
 76%|███████▌  | 38/50 [00:18<00:06,  1.97it/s][A
 78%|███████▊  | 39/50 [00:19<00:05,  1.98it/s][A
 80%|████████  | 40/50 [00:19<00:05,  1.97it/s][A
 82%|████████▏ | 41/50 [00:20<00:04,  1.97it/s][A
 84%|████████▍ | 42/50 [00:20<00:04,  1.97it/s][A
 86%|████████▌ | 43/50 [00:21<00:03,  1.97it/s][A
 88%|████████▊ | 44/50 [00:21<00:03,  1.97it/s][A
 90%|█████████ | 45/50 [00:22<00:02,  1.97it/s][A
 92%|█████████▏| 46/50 [00:22<00:02,  1.97it/s][A
 94%|█████████▍| 47/50 [00:23<00:01,  1.98it/s][A
 96%|█████████▌| 48/50 [00:23<00:01,  1.98it/s][A
 98%|█████████▊| 49/50 [00:24<00:00,  1.98it/s][A
100%|██████████| 50/50 [00:24<00:00,  1.98it/s][A                                                     
                                               [A 50%|█████     | 450/896 [1:43:31<1:25:23, 11.49s/it]
100%|██████████| 50/50 [00:24<00:00,  1.98it/s][A
                                               [A[INFO|trainer.py:2809] 2023-08-04 00:35:50,916 >> Saving model checkpoint to ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-450
[INFO|configuration_utils.py:460] 2023-08-04 00:35:51,139 >> Configuration saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-450/config.json
[INFO|modeling_utils.py:1874] 2023-08-04 00:36:27,273 >> Model weights saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-450/pytorch_model.bin
[INFO|tokenization_utils_base.py:2227] 2023-08-04 00:36:27,278 >> tokenizer config file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-450/tokenizer_config.json
[INFO|tokenization_utils_base.py:2234] 2023-08-04 00:36:27,280 >> Special tokens file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-450/special_tokens_map.json
 50%|█████     | 451/896 [1:46:12<7:55:13, 64.07s/it] 50%|█████     | 452/896 [1:46:23<5:57:08, 48.26s/it] 51%|█████     | 453/896 [1:46:35<4:34:41, 37.20s/it] 51%|█████     | 454/896 [1:46:46<3:37:04, 29.47s/it] 51%|█████     | 455/896 [1:46:58<2:56:51, 24.06s/it] 51%|█████     | 456/896 [1:47:09<2:28:46, 20.29s/it] 51%|█████     | 457/896 [1:47:21<2:09:07, 17.65s/it] 51%|█████     | 458/896 [1:47:32<1:55:21, 15.80s/it] 51%|█████     | 459/896 [1:47:44<1:45:40, 14.51s/it] 51%|█████▏    | 460/896 [1:47:55<1:38:50, 13.60s/it] 51%|█████▏    | 461/896 [1:48:06<1:33:59, 12.96s/it] 52%|█████▏    | 462/896 [1:48:18<1:30:34, 12.52s/it] 52%|█████▏    | 463/896 [1:48:29<1:28:06, 12.21s/it] 52%|█████▏    | 464/896 [1:48:41<1:26:19, 11.99s/it] 52%|█████▏    | 465/896 [1:48:52<1:25:02, 11.84s/it] 52%|█████▏    | 466/896 [1:49:04<1:24:03, 11.73s/it] 52%|█████▏    | 467/896 [1:49:15<1:23:21, 11.66s/it] 52%|█████▏    | 468/896 [1:49:27<1:22:49, 11.61s/it] 52%|█████▏    | 469/896 [1:49:38<1:22:20, 11.57s/it] 52%|█████▏    | 470/896 [1:49:50<1:21:58, 11.55s/it] 53%|█████▎    | 471/896 [1:50:01<1:21:40, 11.53s/it] 53%|█████▎    | 472/896 [1:50:13<1:21:19, 11.51s/it] 53%|█████▎    | 473/896 [1:50:24<1:21:01, 11.49s/it] 53%|█████▎    | 474/896 [1:50:36<1:20:48, 11.49s/it] 53%|█████▎    | 475/896 [1:50:47<1:20:35, 11.49s/it] 53%|█████▎    | 476/896 [1:50:59<1:20:22, 11.48s/it] 53%|█████▎    | 477/896 [1:51:10<1:20:08, 11.48s/it] 53%|█████▎    | 478/896 [1:51:22<1:20:01, 11.49s/it] 53%|█████▎    | 479/896 [1:51:33<1:19:48, 11.48s/it] 54%|█████▎    | 480/896 [1:51:45<1:19:37, 11.48s/it] 54%|█████▎    | 481/896 [1:51:56<1:19:27, 11.49s/it] 54%|█████▍    | 482/896 [1:52:08<1:19:13, 11.48s/it] 54%|█████▍    | 483/896 [1:52:19<1:19:02, 11.48s/it] 54%|█████▍    | 484/896 [1:52:31<1:18:49, 11.48s/it] 54%|█████▍    | 485/896 [1:52:42<1:18:36, 11.48s/it] 54%|█████▍    | 486/896 [1:52:53<1:18:24, 11.48s/it] 54%|█████▍    | 487/896 [1:53:05<1:18:11, 11.47s/it] 54%|█████▍    | 488/896 [1:53:16<1:17:57, 11.47s/it] 55%|█████▍    | 489/896 [1:53:28<1:17:48, 11.47s/it] 55%|█████▍    | 490/896 [1:53:39<1:17:37, 11.47s/it] 55%|█████▍    | 491/896 [1:53:51<1:17:28, 11.48s/it] 55%|█████▍    | 492/896 [1:54:02<1:17:18, 11.48s/it] 55%|█████▌    | 493/896 [1:54:14<1:17:05, 11.48s/it] 55%|█████▌    | 494/896 [1:54:25<1:16:52, 11.47s/it] 55%|█████▌    | 495/896 [1:54:37<1:16:40, 11.47s/it] 55%|█████▌    | 496/896 [1:54:48<1:16:31, 11.48s/it] 55%|█████▌    | 497/896 [1:55:00<1:16:18, 11.48s/it] 56%|█████▌    | 498/896 [1:55:11<1:16:09, 11.48s/it] 56%|█████▌    | 499/896 [1:55:23<1:15:58, 11.48s/it] 56%|█████▌    | 500/896 [1:55:34<1:15:48, 11.49s/it]                                                      56%|█████▌    | 500/896 [1:55:34<1:15:48, 11.49s/it] 56%|█████▌    | 501/896 [1:55:46<1:15:37, 11.49s/it] 56%|█████▌    | 502/896 [1:55:57<1:15:24, 11.48s/it] 56%|█████▌    | 503/896 [1:56:09<1:15:11, 11.48s/it] 56%|█████▋    | 504/896 [1:56:20<1:14:58, 11.48s/it] 56%|█████▋    | 505/896 [1:56:32<1:14:47, 11.48s/it] 56%|█████▋    | 506/896 [1:56:43<1:14:35, 11.48s/it][INFO|trainer.py:749] 2023-08-04 00:49:06,228 >> The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: sentence, context, id. If sentence, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3083] 2023-08-04 00:49:06,230 >> ***** Running Evaluation *****
[INFO|trainer.py:3085] 2023-08-04 00:49:06,230 >>   Num examples = 400
[INFO|trainer.py:3088] 2023-08-04 00:49:06,230 >>   Batch size = 8
{'eval_loss': 0.04030741751194, 'eval_accuracy': 0.99, 'eval_runtime': 25.4174, 'eval_samples_per_second': 15.737, 'eval_steps_per_second': 1.967, 'epoch': 8.0}
{'loss': 0.4259, 'learning_rate': 3.09375e-06, 'epoch': 8.89}

  0%|          | 0/50 [00:00<?, ?it/s][A
  4%|▍         | 2/50 [00:00<00:12,  3.96it/s][A
  6%|▌         | 3/50 [00:01<00:16,  2.79it/s][A
  8%|▊         | 4/50 [00:01<00:19,  2.42it/s][A
 10%|█         | 5/50 [00:02<00:20,  2.25it/s][A
 12%|█▏        | 6/50 [00:02<00:20,  2.15it/s][A
 14%|█▍        | 7/50 [00:03<00:20,  2.09it/s][A
 16%|█▌        | 8/50 [00:03<00:20,  2.05it/s][A
 18%|█▊        | 9/50 [00:04<00:20,  2.02it/s][A
 20%|██        | 10/50 [00:04<00:19,  2.01it/s][A
 22%|██▏       | 11/50 [00:05<00:19,  2.00it/s][A
 24%|██▍       | 12/50 [00:05<00:19,  1.99it/s][A
 26%|██▌       | 13/50 [00:06<00:18,  1.98it/s][A
 28%|██▊       | 14/50 [00:06<00:18,  1.98it/s][A
 30%|███       | 15/50 [00:07<00:17,  1.98it/s][A
 32%|███▏      | 16/50 [00:07<00:17,  1.97it/s][A
 34%|███▍      | 17/50 [00:08<00:16,  1.98it/s][A
 36%|███▌      | 18/50 [00:08<00:16,  1.98it/s][A
 38%|███▊      | 19/50 [00:09<00:15,  1.98it/s][A
 40%|████      | 20/50 [00:09<00:15,  1.98it/s][A
 42%|████▏     | 21/50 [00:10<00:14,  1.98it/s][A
 44%|████▍     | 22/50 [00:10<00:14,  1.98it/s][A
 46%|████▌     | 23/50 [00:11<00:13,  1.98it/s][A
 48%|████▊     | 24/50 [00:11<00:13,  1.97it/s][A
 50%|█████     | 25/50 [00:12<00:12,  1.97it/s][A
 52%|█████▏    | 26/50 [00:12<00:12,  1.97it/s][A
 54%|█████▍    | 27/50 [00:13<00:11,  1.97it/s][A
 56%|█████▌    | 28/50 [00:13<00:11,  1.97it/s][A
 58%|█████▊    | 29/50 [00:14<00:10,  1.97it/s][A
 60%|██████    | 30/50 [00:14<00:10,  1.98it/s][A
 62%|██████▏   | 31/50 [00:15<00:09,  1.97it/s][A
 64%|██████▍   | 32/50 [00:15<00:09,  1.97it/s][A
 66%|██████▌   | 33/50 [00:16<00:08,  1.97it/s][A
 68%|██████▊   | 34/50 [00:16<00:08,  1.97it/s][A
 70%|███████   | 35/50 [00:17<00:07,  1.97it/s][A
 72%|███████▏  | 36/50 [00:17<00:07,  1.97it/s][A
 74%|███████▍  | 37/50 [00:18<00:06,  1.98it/s][A
 76%|███████▌  | 38/50 [00:18<00:06,  1.98it/s][A
 78%|███████▊  | 39/50 [00:19<00:05,  1.98it/s][A
 80%|████████  | 40/50 [00:19<00:05,  1.98it/s][A
 82%|████████▏ | 41/50 [00:20<00:04,  1.97it/s][A
 84%|████████▍ | 42/50 [00:20<00:04,  1.98it/s][A
 86%|████████▌ | 43/50 [00:21<00:03,  1.97it/s][A
 88%|████████▊ | 44/50 [00:21<00:03,  1.98it/s][A
 90%|█████████ | 45/50 [00:22<00:02,  1.98it/s][A
 92%|█████████▏| 46/50 [00:22<00:02,  1.97it/s][A
 94%|█████████▍| 47/50 [00:23<00:01,  1.97it/s][A
 96%|█████████▌| 48/50 [00:23<00:01,  1.97it/s][A
 98%|█████████▊| 49/50 [00:24<00:00,  1.97it/s][A
100%|██████████| 50/50 [00:24<00:00,  1.97it/s][A                                                     
                                               [A 56%|█████▋    | 506/896 [1:57:11<1:14:35, 11.48s/it]
100%|██████████| 50/50 [00:24<00:00,  1.97it/s][A
                                               [A[INFO|trainer.py:2809] 2023-08-04 00:49:31,596 >> Saving model checkpoint to ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-506
[INFO|configuration_utils.py:460] 2023-08-04 00:49:31,603 >> Configuration saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-506/config.json
[INFO|modeling_utils.py:1874] 2023-08-04 00:50:07,061 >> Model weights saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-506/pytorch_model.bin
[INFO|tokenization_utils_base.py:2227] 2023-08-04 00:50:07,066 >> tokenizer config file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-506/tokenizer_config.json
[INFO|tokenization_utils_base.py:2234] 2023-08-04 00:50:07,067 >> Special tokens file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-506/special_tokens_map.json
 57%|█████▋    | 507/896 [1:59:58<7:10:54, 66.46s/it] 57%|█████▋    | 508/896 [2:00:09<5:22:55, 49.94s/it] 57%|█████▋    | 509/896 [2:00:21<4:07:28, 38.37s/it] 57%|█████▋    | 510/896 [2:00:32<3:14:49, 30.28s/it] 57%|█████▋    | 511/896 [2:00:43<2:38:04, 24.63s/it] 57%|█████▋    | 512/896 [2:00:55<2:12:22, 20.68s/it] 57%|█████▋    | 513/896 [2:01:06<1:54:22, 17.92s/it] 57%|█████▋    | 514/896 [2:01:18<1:41:46, 15.99s/it] 57%|█████▋    | 515/896 [2:01:29<1:32:57, 14.64s/it] 58%|█████▊    | 516/896 [2:01:41<1:26:42, 13.69s/it] 58%|█████▊    | 517/896 [2:01:52<1:22:18, 13.03s/it] 58%|█████▊    | 518/896 [2:02:04<1:19:09, 12.56s/it] 58%|█████▊    | 519/896 [2:02:15<1:16:55, 12.24s/it] 58%|█████▊    | 520/896 [2:02:27<1:15:17, 12.02s/it] 58%|█████▊    | 521/896 [2:02:38<1:14:05, 11.85s/it] 58%|█████▊    | 522/896 [2:02:50<1:13:14, 11.75s/it] 58%|█████▊    | 523/896 [2:03:01<1:12:35, 11.68s/it] 58%|█████▊    | 524/896 [2:03:13<1:12:03, 11.62s/it] 59%|█████▊    | 525/896 [2:03:24<1:11:40, 11.59s/it] 59%|█████▊    | 526/896 [2:03:36<1:11:16, 11.56s/it] 59%|█████▉    | 527/896 [2:03:47<1:10:58, 11.54s/it] 59%|█████▉    | 528/896 [2:03:59<1:10:44, 11.53s/it] 59%|█████▉    | 529/896 [2:04:10<1:10:26, 11.52s/it] 59%|█████▉    | 530/896 [2:04:22<1:10:13, 11.51s/it] 59%|█████▉    | 531/896 [2:04:33<1:09:59, 11.51s/it] 59%|█████▉    | 532/896 [2:04:45<1:09:45, 11.50s/it] 59%|█████▉    | 533/896 [2:04:56<1:09:34, 11.50s/it] 60%|█████▉    | 534/896 [2:05:08<1:09:18, 11.49s/it] 60%|█████▉    | 535/896 [2:05:19<1:09:04, 11.48s/it] 60%|█████▉    | 536/896 [2:05:31<1:08:51, 11.48s/it] 60%|█████▉    | 537/896 [2:05:42<1:08:39, 11.47s/it] 60%|██████    | 538/896 [2:05:54<1:08:28, 11.48s/it] 60%|██████    | 539/896 [2:06:05<1:08:16, 11.47s/it] 60%|██████    | 540/896 [2:06:16<1:08:03, 11.47s/it] 60%|██████    | 541/896 [2:06:28<1:07:51, 11.47s/it] 60%|██████    | 542/896 [2:06:39<1:07:42, 11.48s/it] 61%|██████    | 543/896 [2:06:51<1:07:31, 11.48s/it] 61%|██████    | 544/896 [2:07:02<1:07:22, 11.48s/it] 61%|██████    | 545/896 [2:07:14<1:07:09, 11.48s/it] 61%|██████    | 546/896 [2:07:25<1:06:56, 11.48s/it] 61%|██████    | 547/896 [2:07:37<1:06:44, 11.48s/it] 61%|██████    | 548/896 [2:07:48<1:06:32, 11.47s/it] 61%|██████▏   | 549/896 [2:08:00<1:06:20, 11.47s/it] 61%|██████▏   | 550/896 [2:08:11<1:06:05, 11.46s/it] 61%|██████▏   | 551/896 [2:08:23<1:05:53, 11.46s/it] 62%|██████▏   | 552/896 [2:08:34<1:05:44, 11.47s/it] 62%|██████▏   | 553/896 [2:08:46<1:05:29, 11.46s/it] 62%|██████▏   | 554/896 [2:08:57<1:05:19, 11.46s/it] 62%|██████▏   | 555/896 [2:09:08<1:05:08, 11.46s/it] 62%|██████▏   | 556/896 [2:09:20<1:04:58, 11.47s/it] 62%|██████▏   | 557/896 [2:09:31<1:04:48, 11.47s/it] 62%|██████▏   | 558/896 [2:09:43<1:04:38, 11.48s/it] 62%|██████▏   | 559/896 [2:09:54<1:04:26, 11.47s/it] 62%|██████▎   | 560/896 [2:10:06<1:04:11, 11.46s/it] 63%|██████▎   | 561/896 [2:10:17<1:04:00, 11.46s/it] 63%|██████▎   | 562/896 [2:10:29<1:03:49, 11.46s/it][INFO|trainer.py:749] 2023-08-04 01:02:54,813 >> The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: sentence, context, id. If sentence, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3083] 2023-08-04 01:02:54,815 >> ***** Running Evaluation *****
[INFO|trainer.py:3085] 2023-08-04 01:02:54,815 >>   Num examples = 400
[INFO|trainer.py:3088] 2023-08-04 01:02:54,815 >>   Batch size = 8
{'eval_loss': 0.015238490886986256, 'eval_accuracy': 0.995, 'eval_runtime': 25.3517, 'eval_samples_per_second': 15.778, 'eval_steps_per_second': 1.972, 'epoch': 9.0}

  0%|          | 0/50 [00:00<?, ?it/s][A
  4%|▍         | 2/50 [00:00<00:12,  3.96it/s][A
  6%|▌         | 3/50 [00:01<00:16,  2.80it/s][A
  8%|▊         | 4/50 [00:01<00:18,  2.42it/s][A
 10%|█         | 5/50 [00:02<00:19,  2.25it/s][A
 12%|█▏        | 6/50 [00:02<00:20,  2.15it/s][A
 14%|█▍        | 7/50 [00:03<00:20,  2.09it/s][A
 16%|█▌        | 8/50 [00:03<00:20,  2.05it/s][A
 18%|█▊        | 9/50 [00:04<00:20,  2.02it/s][A
 20%|██        | 10/50 [00:04<00:19,  2.01it/s][A
 22%|██▏       | 11/50 [00:05<00:19,  2.00it/s][A
 24%|██▍       | 12/50 [00:05<00:19,  1.99it/s][A
 26%|██▌       | 13/50 [00:06<00:18,  1.98it/s][A
 28%|██▊       | 14/50 [00:06<00:18,  1.98it/s][A
 30%|███       | 15/50 [00:07<00:17,  1.98it/s][A
 32%|███▏      | 16/50 [00:07<00:17,  1.98it/s][A
 34%|███▍      | 17/50 [00:08<00:16,  1.98it/s][A
 36%|███▌      | 18/50 [00:08<00:16,  1.98it/s][A
 38%|███▊      | 19/50 [00:09<00:15,  1.98it/s][A
 40%|████      | 20/50 [00:09<00:15,  1.98it/s][A
 42%|████▏     | 21/50 [00:10<00:14,  1.98it/s][A
 44%|████▍     | 22/50 [00:10<00:14,  1.98it/s][A
 46%|████▌     | 23/50 [00:11<00:13,  1.98it/s][A
 48%|████▊     | 24/50 [00:11<00:13,  1.98it/s][A
 50%|█████     | 25/50 [00:12<00:12,  1.97it/s][A
 52%|█████▏    | 26/50 [00:12<00:12,  1.98it/s][A
 54%|█████▍    | 27/50 [00:13<00:11,  1.97it/s][A
 56%|█████▌    | 28/50 [00:13<00:11,  1.97it/s][A
 58%|█████▊    | 29/50 [00:14<00:10,  1.97it/s][A
 60%|██████    | 30/50 [00:14<00:10,  1.98it/s][A
 62%|██████▏   | 31/50 [00:15<00:09,  1.98it/s][A
 64%|██████▍   | 32/50 [00:15<00:09,  1.98it/s][A
 66%|██████▌   | 33/50 [00:16<00:08,  1.97it/s][A
 68%|██████▊   | 34/50 [00:16<00:08,  1.97it/s][A
 70%|███████   | 35/50 [00:17<00:07,  1.97it/s][A
 72%|███████▏  | 36/50 [00:17<00:07,  1.97it/s][A
 74%|███████▍  | 37/50 [00:18<00:06,  1.98it/s][A
 76%|███████▌  | 38/50 [00:18<00:06,  1.98it/s][A
 78%|███████▊  | 39/50 [00:19<00:05,  1.98it/s][A
 80%|████████  | 40/50 [00:19<00:05,  1.98it/s][A
 82%|████████▏ | 41/50 [00:20<00:04,  1.97it/s][A
 84%|████████▍ | 42/50 [00:20<00:04,  1.98it/s][A
 86%|████████▌ | 43/50 [00:21<00:03,  1.97it/s][A
 88%|████████▊ | 44/50 [00:21<00:03,  1.97it/s][A
 90%|█████████ | 45/50 [00:22<00:02,  1.98it/s][A
 92%|█████████▏| 46/50 [00:22<00:02,  1.97it/s][A
 94%|█████████▍| 47/50 [00:23<00:01,  1.98it/s][A
 96%|█████████▌| 48/50 [00:23<00:01,  1.98it/s][A
 98%|█████████▊| 49/50 [00:24<00:00,  1.98it/s][A
100%|██████████| 50/50 [00:24<00:00,  1.98it/s][A                                                     
                                               [A 63%|██████▎   | 562/896 [2:11:00<1:03:49, 11.46s/it]
100%|██████████| 50/50 [00:24<00:00,  1.98it/s][A
                                               [A[INFO|trainer.py:2809] 2023-08-04 01:03:20,179 >> Saving model checkpoint to ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-562
[INFO|configuration_utils.py:460] 2023-08-04 01:03:20,182 >> Configuration saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-562/config.json
[INFO|modeling_utils.py:1874] 2023-08-04 01:03:54,678 >> Model weights saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-562/pytorch_model.bin
[INFO|tokenization_utils_base.py:2227] 2023-08-04 01:03:54,696 >> tokenizer config file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-562/tokenizer_config.json
[INFO|tokenization_utils_base.py:2234] 2023-08-04 01:03:54,698 >> Special tokens file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-562/special_tokens_map.json
 63%|██████▎   | 563/896 [2:13:39<6:01:57, 65.22s/it] 63%|██████▎   | 564/896 [2:13:51<4:31:26, 49.05s/it] 63%|██████▎   | 565/896 [2:14:02<3:28:16, 37.75s/it] 63%|██████▎   | 566/896 [2:14:14<2:44:10, 29.85s/it] 63%|██████▎   | 567/896 [2:14:25<2:13:21, 24.32s/it] 63%|██████▎   | 568/896 [2:14:36<1:51:48, 20.45s/it] 64%|██████▎   | 569/896 [2:14:48<1:36:45, 17.75s/it] 64%|██████▎   | 570/896 [2:14:59<1:26:16, 15.88s/it] 64%|██████▎   | 571/896 [2:15:11<1:18:52, 14.56s/it] 64%|██████▍   | 572/896 [2:15:22<1:13:38, 13.64s/it] 64%|██████▍   | 573/896 [2:15:34<1:09:56, 12.99s/it] 64%|██████▍   | 574/896 [2:15:45<1:07:15, 12.53s/it] 64%|██████▍   | 575/896 [2:15:57<1:05:23, 12.22s/it] 64%|██████▍   | 576/896 [2:16:08<1:03:59, 12.00s/it] 64%|██████▍   | 577/896 [2:16:20<1:02:57, 11.84s/it] 65%|██████▍   | 578/896 [2:16:31<1:02:08, 11.73s/it] 65%|██████▍   | 579/896 [2:16:43<1:01:32, 11.65s/it] 65%|██████▍   | 580/896 [2:16:54<1:01:06, 11.60s/it] 65%|██████▍   | 581/896 [2:17:06<1:00:44, 11.57s/it] 65%|██████▍   | 582/896 [2:17:17<1:00:26, 11.55s/it] 65%|██████▌   | 583/896 [2:17:29<1:00:10, 11.53s/it] 65%|██████▌   | 584/896 [2:17:40<59:54, 11.52s/it]   65%|██████▌   | 585/896 [2:17:52<59:39, 11.51s/it] 65%|██████▌   | 586/896 [2:18:03<59:26, 11.50s/it] 66%|██████▌   | 587/896 [2:18:15<59:14, 11.50s/it] 66%|██████▌   | 588/896 [2:18:26<59:01, 11.50s/it] 66%|██████▌   | 589/896 [2:18:38<58:47, 11.49s/it] 66%|██████▌   | 590/896 [2:18:49<58:33, 11.48s/it] 66%|██████▌   | 591/896 [2:19:00<58:21, 11.48s/it] 66%|██████▌   | 592/896 [2:19:12<58:08, 11.48s/it] 66%|██████▌   | 593/896 [2:19:23<57:56, 11.47s/it] 66%|██████▋   | 594/896 [2:19:35<57:42, 11.47s/it] 66%|██████▋   | 595/896 [2:19:46<57:31, 11.47s/it] 67%|██████▋   | 596/896 [2:19:58<57:20, 11.47s/it] 67%|██████▋   | 597/896 [2:20:09<57:10, 11.47s/it] 67%|██████▋   | 598/896 [2:20:21<56:58, 11.47s/it] 67%|██████▋   | 599/896 [2:20:32<56:46, 11.47s/it] 67%|██████▋   | 600/896 [2:20:44<56:35, 11.47s/it] 67%|██████▋   | 601/896 [2:20:55<56:24, 11.47s/it] 67%|██████▋   | 602/896 [2:21:07<56:13, 11.48s/it] 67%|██████▋   | 603/896 [2:21:18<56:02, 11.48s/it] 67%|██████▋   | 604/896 [2:21:30<55:51, 11.48s/it] 68%|██████▊   | 605/896 [2:21:41<55:37, 11.47s/it] 68%|██████▊   | 606/896 [2:21:53<55:25, 11.47s/it] 68%|██████▊   | 607/896 [2:22:04<55:11, 11.46s/it] 68%|██████▊   | 608/896 [2:22:15<55:02, 11.47s/it] 68%|██████▊   | 609/896 [2:22:27<54:52, 11.47s/it] 68%|██████▊   | 610/896 [2:22:38<54:40, 11.47s/it] 68%|██████▊   | 611/896 [2:22:50<54:30, 11.47s/it] 68%|██████▊   | 612/896 [2:23:01<54:18, 11.47s/it] 68%|██████▊   | 613/896 [2:23:13<54:08, 11.48s/it] 69%|██████▊   | 614/896 [2:23:24<53:55, 11.47s/it] 69%|██████▊   | 615/896 [2:23:36<53:43, 11.47s/it] 69%|██████▉   | 616/896 [2:23:47<53:34, 11.48s/it] 69%|██████▉   | 617/896 [2:23:59<53:25, 11.49s/it] 69%|██████▉   | 618/896 [2:24:10<53:11, 11.48s/it][INFO|trainer.py:749] 2023-08-04 01:16:39,158 >> The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: sentence, context, id. If sentence, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3083] 2023-08-04 01:16:39,160 >> ***** Running Evaluation *****
[INFO|trainer.py:3085] 2023-08-04 01:16:39,160 >>   Num examples = 400
[INFO|trainer.py:3088] 2023-08-04 01:16:39,160 >>   Batch size = 8
{'eval_loss': 0.004280812572687864, 'eval_accuracy': 1.0, 'eval_runtime': 25.3301, 'eval_samples_per_second': 15.792, 'eval_steps_per_second': 1.974, 'epoch': 9.99}

  0%|          | 0/50 [00:00<?, ?it/s][A
  4%|▍         | 2/50 [00:00<00:12,  3.93it/s][A
  6%|▌         | 3/50 [00:01<00:16,  2.78it/s][A
  8%|▊         | 4/50 [00:01<00:19,  2.41it/s][A
 10%|█         | 5/50 [00:02<00:20,  2.24it/s][A
 12%|█▏        | 6/50 [00:02<00:20,  2.14it/s][A
 14%|█▍        | 7/50 [00:03<00:20,  2.08it/s][A
 16%|█▌        | 8/50 [00:03<00:20,  2.05it/s][A
 18%|█▊        | 9/50 [00:04<00:20,  2.02it/s][A
 20%|██        | 10/50 [00:04<00:19,  2.01it/s][A
 22%|██▏       | 11/50 [00:05<00:19,  1.99it/s][A
 24%|██▍       | 12/50 [00:05<00:19,  1.98it/s][A
 26%|██▌       | 13/50 [00:06<00:18,  1.98it/s][A
 28%|██▊       | 14/50 [00:06<00:18,  1.97it/s][A
 30%|███       | 15/50 [00:07<00:17,  1.97it/s][A
 32%|███▏      | 16/50 [00:07<00:17,  1.97it/s][A
 34%|███▍      | 17/50 [00:08<00:16,  1.97it/s][A
 36%|███▌      | 18/50 [00:08<00:16,  1.97it/s][A
 38%|███▊      | 19/50 [00:09<00:15,  1.97it/s][A
 40%|████      | 20/50 [00:09<00:15,  1.98it/s][A
 42%|████▏     | 21/50 [00:10<00:14,  1.98it/s][A
 44%|████▍     | 22/50 [00:10<00:14,  1.98it/s][A
 46%|████▌     | 23/50 [00:11<00:13,  1.97it/s][A
 48%|████▊     | 24/50 [00:11<00:13,  1.97it/s][A
 50%|█████     | 25/50 [00:12<00:12,  1.97it/s][A
 52%|█████▏    | 26/50 [00:12<00:12,  1.97it/s][A
 54%|█████▍    | 27/50 [00:13<00:11,  1.97it/s][A
 56%|█████▌    | 28/50 [00:13<00:11,  1.97it/s][A
 58%|█████▊    | 29/50 [00:14<00:10,  1.97it/s][A
 60%|██████    | 30/50 [00:14<00:10,  1.97it/s][A
 62%|██████▏   | 31/50 [00:15<00:09,  1.97it/s][A
 64%|██████▍   | 32/50 [00:15<00:09,  1.97it/s][A
 66%|██████▌   | 33/50 [00:16<00:08,  1.97it/s][A
 68%|██████▊   | 34/50 [00:16<00:08,  1.97it/s][A
 70%|███████   | 35/50 [00:17<00:07,  1.97it/s][A
 72%|███████▏  | 36/50 [00:17<00:07,  1.97it/s][A
 74%|███████▍  | 37/50 [00:18<00:06,  1.97it/s][A
 76%|███████▌  | 38/50 [00:18<00:06,  1.97it/s][A
 78%|███████▊  | 39/50 [00:19<00:05,  1.97it/s][A
 80%|████████  | 40/50 [00:19<00:05,  1.97it/s][A
 82%|████████▏ | 41/50 [00:20<00:04,  1.97it/s][A
 84%|████████▍ | 42/50 [00:20<00:04,  1.97it/s][A
 86%|████████▌ | 43/50 [00:21<00:03,  1.97it/s][A
 88%|████████▊ | 44/50 [00:21<00:03,  1.97it/s][A
 90%|█████████ | 45/50 [00:22<00:02,  1.97it/s][A
 92%|█████████▏| 46/50 [00:22<00:02,  1.97it/s][A
 94%|█████████▍| 47/50 [00:23<00:01,  1.97it/s][A
 96%|█████████▌| 48/50 [00:23<00:01,  1.97it/s][A
 98%|█████████▊| 49/50 [00:24<00:00,  1.97it/s][A
100%|██████████| 50/50 [00:24<00:00,  1.98it/s][A                                                   
                                               [A 69%|██████▉   | 618/896 [2:24:44<53:11, 11.48s/it]
100%|██████████| 50/50 [00:24<00:00,  1.98it/s][A
                                               [A[INFO|trainer.py:2809] 2023-08-04 01:17:04,580 >> Saving model checkpoint to ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-618
[INFO|configuration_utils.py:460] 2023-08-04 01:17:04,583 >> Configuration saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-618/config.json
[INFO|modeling_utils.py:1874] 2023-08-04 01:17:44,473 >> Model weights saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-618/pytorch_model.bin
[INFO|tokenization_utils_base.py:2227] 2023-08-04 01:17:44,714 >> tokenizer config file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-618/tokenizer_config.json
[INFO|tokenization_utils_base.py:2234] 2023-08-04 01:17:44,865 >> Special tokens file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-618/special_tokens_map.json
 69%|██████▉   | 619/896 [2:27:17<4:56:12, 64.16s/it] 69%|██████▉   | 620/896 [2:27:29<3:42:14, 48.31s/it] 69%|██████▉   | 621/896 [2:27:40<2:50:37, 37.23s/it] 69%|██████▉   | 622/896 [2:27:51<2:14:40, 29.49s/it] 70%|██████▉   | 623/896 [2:28:03<1:49:31, 24.07s/it] 70%|██████▉   | 624/896 [2:28:14<1:31:55, 20.28s/it] 70%|██████▉   | 625/896 [2:28:26<1:19:38, 17.63s/it] 70%|██████▉   | 626/896 [2:28:37<1:11:01, 15.79s/it] 70%|██████▉   | 627/896 [2:28:49<1:04:56, 14.49s/it] 70%|███████   | 628/896 [2:29:00<1:00:41, 13.59s/it] 70%|███████   | 629/896 [2:29:12<57:37, 12.95s/it]   70%|███████   | 630/896 [2:29:23<55:28, 12.51s/it] 70%|███████   | 631/896 [2:29:35<53:54, 12.21s/it] 71%|███████   | 632/896 [2:29:46<52:44, 11.99s/it] 71%|███████   | 633/896 [2:29:58<51:54, 11.84s/it] 71%|███████   | 634/896 [2:30:09<51:12, 11.73s/it] 71%|███████   | 635/896 [2:30:21<50:42, 11.66s/it] 71%|███████   | 636/896 [2:30:32<50:18, 11.61s/it] 71%|███████   | 637/896 [2:30:44<49:58, 11.58s/it] 71%|███████   | 638/896 [2:30:55<49:39, 11.55s/it] 71%|███████▏  | 639/896 [2:31:07<49:22, 11.53s/it] 71%|███████▏  | 640/896 [2:31:18<49:10, 11.53s/it] 72%|███████▏  | 641/896 [2:31:30<48:55, 11.51s/it] 72%|███████▏  | 642/896 [2:31:41<48:42, 11.50s/it] 72%|███████▏  | 643/896 [2:31:53<48:28, 11.50s/it] 72%|███████▏  | 644/896 [2:32:04<48:16, 11.50s/it] 72%|███████▏  | 645/896 [2:32:16<48:07, 11.50s/it] 72%|███████▏  | 646/896 [2:32:27<47:54, 11.50s/it] 72%|███████▏  | 647/896 [2:32:39<47:42, 11.50s/it] 72%|███████▏  | 648/896 [2:32:50<47:30, 11.50s/it] 72%|███████▏  | 649/896 [2:33:02<47:19, 11.50s/it] 73%|███████▎  | 650/896 [2:33:13<47:08, 11.50s/it] 73%|███████▎  | 651/896 [2:33:24<46:56, 11.50s/it] 73%|███████▎  | 652/896 [2:33:36<46:45, 11.50s/it] 73%|███████▎  | 653/896 [2:33:47<46:33, 11.49s/it] 73%|███████▎  | 654/896 [2:33:59<46:20, 11.49s/it] 73%|███████▎  | 655/896 [2:34:10<46:09, 11.49s/it] 73%|███████▎  | 656/896 [2:34:22<45:55, 11.48s/it] 73%|███████▎  | 657/896 [2:34:33<45:45, 11.49s/it] 73%|███████▎  | 658/896 [2:34:45<45:32, 11.48s/it] 74%|███████▎  | 659/896 [2:34:56<45:22, 11.49s/it] 74%|███████▎  | 660/896 [2:35:08<45:12, 11.49s/it] 74%|███████▍  | 661/896 [2:35:19<44:58, 11.48s/it] 74%|███████▍  | 662/896 [2:35:31<44:46, 11.48s/it] 74%|███████▍  | 663/896 [2:35:42<44:33, 11.47s/it] 74%|███████▍  | 664/896 [2:35:54<44:22, 11.48s/it] 74%|███████▍  | 665/896 [2:36:05<44:12, 11.48s/it] 74%|███████▍  | 666/896 [2:36:17<44:02, 11.49s/it] 74%|███████▍  | 667/896 [2:36:28<43:50, 11.49s/it] 75%|███████▍  | 668/896 [2:36:40<43:39, 11.49s/it] 75%|███████▍  | 669/896 [2:36:51<43:27, 11.49s/it] 75%|███████▍  | 670/896 [2:37:03<43:17, 11.50s/it] 75%|███████▍  | 671/896 [2:37:14<43:06, 11.49s/it] 75%|███████▌  | 672/896 [2:37:26<42:55, 11.50s/it] 75%|███████▌  | 673/896 [2:37:37<42:44, 11.50s/it] 75%|███████▌  | 674/896 [2:37:49<42:30, 11.49s/it] 75%|███████▌  | 675/896 [2:38:00<42:15, 11.47s/it][INFO|trainer.py:749] 2023-08-04 01:30:20,465 >> The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: sentence, context, id. If sentence, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3083] 2023-08-04 01:30:20,467 >> ***** Running Evaluation *****
[INFO|trainer.py:3085] 2023-08-04 01:30:20,467 >>   Num examples = 400
[INFO|trainer.py:3088] 2023-08-04 01:30:20,467 >>   Batch size = 8
{'eval_loss': 0.001313300570473075, 'eval_accuracy': 1.0, 'eval_runtime': 25.4006, 'eval_samples_per_second': 15.748, 'eval_steps_per_second': 1.968, 'epoch': 10.99}

  0%|          | 0/50 [00:00<?, ?it/s][A
  4%|▍         | 2/50 [00:00<00:12,  3.96it/s][A
  6%|▌         | 3/50 [00:01<00:16,  2.79it/s][A
  8%|▊         | 4/50 [00:01<00:19,  2.42it/s][A
 10%|█         | 5/50 [00:02<00:20,  2.24it/s][A
 12%|█▏        | 6/50 [00:02<00:20,  2.14it/s][A
 14%|█▍        | 7/50 [00:03<00:20,  2.08it/s][A
 16%|█▌        | 8/50 [00:03<00:20,  2.05it/s][A
 18%|█▊        | 9/50 [00:04<00:20,  2.03it/s][A
 20%|██        | 10/50 [00:04<00:19,  2.01it/s][A
 22%|██▏       | 11/50 [00:05<00:19,  2.00it/s][A
 24%|██▍       | 12/50 [00:05<00:19,  1.99it/s][A
 26%|██▌       | 13/50 [00:06<00:18,  1.98it/s][A
 28%|██▊       | 14/50 [00:06<00:18,  1.98it/s][A
 30%|███       | 15/50 [00:07<00:17,  1.98it/s][A
 32%|███▏      | 16/50 [00:07<00:17,  1.98it/s][A
 34%|███▍      | 17/50 [00:08<00:16,  1.98it/s][A
 36%|███▌      | 18/50 [00:08<00:16,  1.98it/s][A
 38%|███▊      | 19/50 [00:09<00:15,  1.98it/s][A
 40%|████      | 20/50 [00:09<00:15,  1.98it/s][A
 42%|████▏     | 21/50 [00:10<00:14,  1.99it/s][A
 44%|████▍     | 22/50 [00:10<00:14,  1.98it/s][A
 46%|████▌     | 23/50 [00:11<00:13,  1.98it/s][A
 48%|████▊     | 24/50 [00:11<00:13,  1.97it/s][A
 50%|█████     | 25/50 [00:12<00:12,  1.97it/s][A
 52%|█████▏    | 26/50 [00:12<00:12,  1.97it/s][A
 54%|█████▍    | 27/50 [00:13<00:11,  1.97it/s][A
 56%|█████▌    | 28/50 [00:13<00:11,  1.97it/s][A
 58%|█████▊    | 29/50 [00:14<00:10,  1.97it/s][A
 60%|██████    | 30/50 [00:14<00:10,  1.97it/s][A
 62%|██████▏   | 31/50 [00:15<00:09,  1.97it/s][A
 64%|██████▍   | 32/50 [00:15<00:09,  1.97it/s][A
 66%|██████▌   | 33/50 [00:16<00:08,  1.97it/s][A
 68%|██████▊   | 34/50 [00:16<00:08,  1.97it/s][A
 70%|███████   | 35/50 [00:17<00:07,  1.97it/s][A
 72%|███████▏  | 36/50 [00:17<00:07,  1.97it/s][A
 74%|███████▍  | 37/50 [00:18<00:06,  1.97it/s][A
 76%|███████▌  | 38/50 [00:18<00:06,  1.97it/s][A
 78%|███████▊  | 39/50 [00:19<00:05,  1.97it/s][A
 80%|████████  | 40/50 [00:19<00:05,  1.97it/s][A
 82%|████████▏ | 41/50 [00:20<00:04,  1.97it/s][A
 84%|████████▍ | 42/50 [00:20<00:04,  1.98it/s][A
 86%|████████▌ | 43/50 [00:21<00:03,  1.97it/s][A
 88%|████████▊ | 44/50 [00:21<00:03,  1.97it/s][A
 90%|█████████ | 45/50 [00:22<00:02,  1.97it/s][A
 92%|█████████▏| 46/50 [00:22<00:02,  1.97it/s][A
 94%|█████████▍| 47/50 [00:23<00:01,  1.97it/s][A
 96%|█████████▌| 48/50 [00:23<00:01,  1.98it/s][A
 98%|█████████▊| 49/50 [00:24<00:00,  1.98it/s][A
100%|██████████| 50/50 [00:24<00:00,  1.98it/s][A                                                   
                                               [A 75%|███████▌  | 675/896 [2:38:26<42:15, 11.47s/it]
100%|██████████| 50/50 [00:24<00:00,  1.98it/s][A
                                               [A[INFO|trainer.py:2809] 2023-08-04 01:30:45,886 >> Saving model checkpoint to ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-675
[INFO|configuration_utils.py:460] 2023-08-04 01:30:45,889 >> Configuration saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-675/config.json
[INFO|modeling_utils.py:1874] 2023-08-04 01:31:34,998 >> Model weights saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-675/pytorch_model.bin
[INFO|tokenization_utils_base.py:2227] 2023-08-04 01:31:35,230 >> tokenizer config file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-675/tokenizer_config.json
[INFO|tokenization_utils_base.py:2234] 2023-08-04 01:31:35,400 >> Special tokens file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-675/special_tokens_map.json
 75%|███████▌  | 676/896 [2:41:12<4:00:44, 65.66s/it] 76%|███████▌  | 677/896 [2:41:24<3:00:10, 49.36s/it] 76%|███████▌  | 678/896 [2:41:35<2:17:57, 37.97s/it] 76%|███████▌  | 679/896 [2:41:46<1:48:31, 30.01s/it] 76%|███████▌  | 680/896 [2:41:58<1:27:58, 24.44s/it] 76%|███████▌  | 681/896 [2:42:09<1:13:35, 20.54s/it] 76%|███████▌  | 682/896 [2:42:21<1:03:31, 17.81s/it] 76%|███████▌  | 683/896 [2:42:32<56:26, 15.90s/it]   76%|███████▋  | 684/896 [2:42:44<51:27, 14.56s/it] 76%|███████▋  | 685/896 [2:42:55<47:57, 13.64s/it] 77%|███████▋  | 686/896 [2:43:07<45:29, 13.00s/it] 77%|███████▋  | 687/896 [2:43:18<43:42, 12.55s/it] 77%|███████▋  | 688/896 [2:43:30<42:26, 12.24s/it] 77%|███████▋  | 689/896 [2:43:41<41:28, 12.02s/it] 77%|███████▋  | 690/896 [2:43:53<40:43, 11.86s/it] 77%|███████▋  | 691/896 [2:44:04<40:09, 11.76s/it] 77%|███████▋  | 692/896 [2:44:16<39:42, 11.68s/it] 77%|███████▋  | 693/896 [2:44:27<39:20, 11.63s/it] 77%|███████▋  | 694/896 [2:44:39<39:01, 11.59s/it] 78%|███████▊  | 695/896 [2:44:50<38:43, 11.56s/it] 78%|███████▊  | 696/896 [2:45:02<38:27, 11.54s/it] 78%|███████▊  | 697/896 [2:45:13<38:13, 11.53s/it] 78%|███████▊  | 698/896 [2:45:25<38:00, 11.52s/it] 78%|███████▊  | 699/896 [2:45:36<37:49, 11.52s/it] 78%|███████▊  | 700/896 [2:45:48<37:37, 11.52s/it] 78%|███████▊  | 701/896 [2:45:59<37:24, 11.51s/it] 78%|███████▊  | 702/896 [2:46:11<37:11, 11.50s/it] 78%|███████▊  | 703/896 [2:46:22<36:59, 11.50s/it] 79%|███████▊  | 704/896 [2:46:34<36:48, 11.50s/it] 79%|███████▊  | 705/896 [2:46:45<36:35, 11.49s/it] 79%|███████▉  | 706/896 [2:46:57<36:23, 11.49s/it] 79%|███████▉  | 707/896 [2:47:08<36:13, 11.50s/it] 79%|███████▉  | 708/896 [2:47:20<36:02, 11.50s/it] 79%|███████▉  | 709/896 [2:47:31<35:50, 11.50s/it] 79%|███████▉  | 710/896 [2:47:43<35:38, 11.50s/it] 79%|███████▉  | 711/896 [2:47:54<35:26, 11.49s/it] 79%|███████▉  | 712/896 [2:48:06<35:14, 11.49s/it] 80%|███████▉  | 713/896 [2:48:17<35:01, 11.48s/it] 80%|███████▉  | 714/896 [2:48:29<34:50, 11.49s/it] 80%|███████▉  | 715/896 [2:48:40<34:40, 11.50s/it] 80%|███████▉  | 716/896 [2:48:52<34:30, 11.50s/it] 80%|████████  | 717/896 [2:49:03<34:17, 11.49s/it] 80%|████████  | 718/896 [2:49:15<34:05, 11.49s/it] 80%|████████  | 719/896 [2:49:26<33:54, 11.49s/it] 80%|████████  | 720/896 [2:49:38<33:43, 11.49s/it] 80%|████████  | 721/896 [2:49:49<33:31, 11.49s/it] 81%|████████  | 722/896 [2:50:00<33:19, 11.49s/it] 81%|████████  | 723/896 [2:50:12<33:10, 11.51s/it] 81%|████████  | 724/896 [2:50:24<32:59, 11.51s/it] 81%|████████  | 725/896 [2:50:35<32:47, 11.50s/it] 81%|████████  | 726/896 [2:50:47<32:35, 11.50s/it] 81%|████████  | 727/896 [2:50:58<32:23, 11.50s/it] 81%|████████▏ | 728/896 [2:51:09<32:10, 11.49s/it] 81%|████████▏ | 729/896 [2:51:21<31:59, 11.50s/it] 81%|████████▏ | 730/896 [2:51:32<31:48, 11.50s/it] 82%|████████▏ | 731/896 [2:51:44<31:36, 11.50s/it][INFO|trainer.py:749] 2023-08-04 01:44:07,205 >> The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: sentence, context, id. If sentence, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3083] 2023-08-04 01:44:07,207 >> ***** Running Evaluation *****
[INFO|trainer.py:3085] 2023-08-04 01:44:07,207 >>   Num examples = 400
[INFO|trainer.py:3088] 2023-08-04 01:44:07,207 >>   Batch size = 8
{'eval_loss': 0.0010055970633402467, 'eval_accuracy': 1.0, 'eval_runtime': 25.3991, 'eval_samples_per_second': 15.749, 'eval_steps_per_second': 1.969, 'epoch': 12.0}

  0%|          | 0/50 [00:00<?, ?it/s][A
  4%|▍         | 2/50 [00:00<00:12,  3.97it/s][A
  6%|▌         | 3/50 [00:01<00:16,  2.80it/s][A
  8%|▊         | 4/50 [00:01<00:18,  2.42it/s][A
 10%|█         | 5/50 [00:02<00:20,  2.25it/s][A
 12%|█▏        | 6/50 [00:02<00:20,  2.15it/s][A
 14%|█▍        | 7/50 [00:03<00:20,  2.09it/s][A
 16%|█▌        | 8/50 [00:03<00:20,  2.05it/s][A
 18%|█▊        | 9/50 [00:04<00:20,  2.02it/s][A
 20%|██        | 10/50 [00:04<00:19,  2.01it/s][A
 22%|██▏       | 11/50 [00:05<00:19,  2.00it/s][A
 24%|██▍       | 12/50 [00:05<00:19,  1.99it/s][A
 26%|██▌       | 13/50 [00:06<00:18,  1.98it/s][A
 28%|██▊       | 14/50 [00:06<00:18,  1.98it/s][A
 30%|███       | 15/50 [00:07<00:17,  1.98it/s][A
 32%|███▏      | 16/50 [00:07<00:17,  1.98it/s][A
 34%|███▍      | 17/50 [00:08<00:16,  1.98it/s][A
 36%|███▌      | 18/50 [00:08<00:16,  1.98it/s][A
 38%|███▊      | 19/50 [00:09<00:15,  1.98it/s][A
 40%|████      | 20/50 [00:09<00:15,  1.98it/s][A
 42%|████▏     | 21/50 [00:10<00:14,  1.98it/s][A
 44%|████▍     | 22/50 [00:10<00:14,  1.98it/s][A
 46%|████▌     | 23/50 [00:11<00:13,  1.98it/s][A
 48%|████▊     | 24/50 [00:11<00:13,  1.97it/s][A
 50%|█████     | 25/50 [00:12<00:12,  1.97it/s][A
 52%|█████▏    | 26/50 [00:12<00:12,  1.97it/s][A
 54%|█████▍    | 27/50 [00:13<00:11,  1.97it/s][A
 56%|█████▌    | 28/50 [00:13<00:11,  1.97it/s][A
 58%|█████▊    | 29/50 [00:14<00:10,  1.97it/s][A
 60%|██████    | 30/50 [00:14<00:10,  1.98it/s][A
 62%|██████▏   | 31/50 [00:15<00:09,  1.97it/s][A
 64%|██████▍   | 32/50 [00:15<00:09,  1.97it/s][A
 66%|██████▌   | 33/50 [00:16<00:08,  1.97it/s][A
 68%|██████▊   | 34/50 [00:16<00:08,  1.97it/s][A
 70%|███████   | 35/50 [00:17<00:07,  1.97it/s][A
 72%|███████▏  | 36/50 [00:17<00:07,  1.97it/s][A
 74%|███████▍  | 37/50 [00:18<00:06,  1.98it/s][A
 76%|███████▌  | 38/50 [00:18<00:06,  1.98it/s][A
 78%|███████▊  | 39/50 [00:19<00:05,  1.98it/s][A
 80%|████████  | 40/50 [00:19<00:05,  1.98it/s][A
 82%|████████▏ | 41/50 [00:20<00:04,  1.97it/s][A
 84%|████████▍ | 42/50 [00:20<00:04,  1.98it/s][A
 86%|████████▌ | 43/50 [00:21<00:03,  1.97it/s][A
 88%|████████▊ | 44/50 [00:21<00:03,  1.97it/s][A
 90%|█████████ | 45/50 [00:22<00:02,  1.97it/s][A
 92%|█████████▏| 46/50 [00:22<00:02,  1.97it/s][A
 94%|█████████▍| 47/50 [00:23<00:01,  1.97it/s][A
 96%|█████████▌| 48/50 [00:23<00:01,  1.97it/s][A
 98%|█████████▊| 49/50 [00:24<00:00,  1.97it/s][A
100%|██████████| 50/50 [00:24<00:00,  1.98it/s][A                                                   
                                               [A 82%|████████▏ | 731/896 [2:52:12<31:36, 11.50s/it]
100%|██████████| 50/50 [00:24<00:00,  1.98it/s][A
                                               [A[INFO|trainer.py:2809] 2023-08-04 01:44:32,637 >> Saving model checkpoint to ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-731
[INFO|configuration_utils.py:460] 2023-08-04 01:44:32,641 >> Configuration saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-731/config.json
[INFO|modeling_utils.py:1874] 2023-08-04 01:45:26,633 >> Model weights saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-731/pytorch_model.bin
[INFO|tokenization_utils_base.py:2227] 2023-08-04 01:45:26,874 >> tokenizer config file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-731/tokenizer_config.json
[INFO|tokenization_utils_base.py:2234] 2023-08-04 01:45:27,044 >> Special tokens file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-731/special_tokens_map.json
 82%|████████▏ | 732/896 [2:54:44<2:49:53, 62.15s/it] 82%|████████▏ | 733/896 [2:54:56<2:07:28, 46.92s/it] 82%|████████▏ | 734/896 [2:55:07<1:37:54, 36.26s/it] 82%|████████▏ | 735/896 [2:55:19<1:17:18, 28.81s/it] 82%|████████▏ | 736/896 [2:55:30<1:02:54, 23.59s/it] 82%|████████▏ | 737/896 [2:55:41<52:52, 19.95s/it]   82%|████████▏ | 738/896 [2:55:53<45:49, 17.40s/it] 82%|████████▏ | 739/896 [2:56:04<40:51, 15.61s/it] 83%|████████▎ | 740/896 [2:56:16<37:20, 14.36s/it] 83%|████████▎ | 741/896 [2:56:27<34:51, 13.49s/it] 83%|████████▎ | 742/896 [2:56:39<33:04, 12.88s/it] 83%|████████▎ | 743/896 [2:56:50<31:44, 12.45s/it] 83%|████████▎ | 744/896 [2:57:02<30:46, 12.15s/it] 83%|████████▎ | 745/896 [2:57:13<30:01, 11.93s/it] 83%|████████▎ | 746/896 [2:57:24<29:29, 11.79s/it] 83%|████████▎ | 747/896 [2:57:36<29:02, 11.70s/it] 83%|████████▎ | 748/896 [2:57:47<28:41, 11.63s/it] 84%|████████▎ | 749/896 [2:57:59<28:22, 11.58s/it] 84%|████████▎ | 750/896 [2:58:10<28:06, 11.55s/it] 84%|████████▍ | 751/896 [2:58:22<27:51, 11.53s/it] 84%|████████▍ | 752/896 [2:58:33<27:39, 11.52s/it] 84%|████████▍ | 753/896 [2:58:45<27:26, 11.52s/it] 84%|████████▍ | 754/896 [2:58:56<27:14, 11.51s/it] 84%|████████▍ | 755/896 [2:59:08<27:02, 11.51s/it] 84%|████████▍ | 756/896 [2:59:19<26:51, 11.51s/it] 84%|████████▍ | 757/896 [2:59:31<26:38, 11.50s/it] 85%|████████▍ | 758/896 [2:59:42<26:27, 11.50s/it] 85%|████████▍ | 759/896 [2:59:54<26:15, 11.50s/it] 85%|████████▍ | 760/896 [3:00:05<26:04, 11.50s/it] 85%|████████▍ | 761/896 [3:00:17<25:52, 11.50s/it] 85%|████████▌ | 762/896 [3:00:28<25:40, 11.49s/it] 85%|████████▌ | 763/896 [3:00:40<25:28, 11.49s/it] 85%|████████▌ | 764/896 [3:00:51<25:17, 11.49s/it] 85%|████████▌ | 765/896 [3:01:03<25:05, 11.49s/it] 85%|████████▌ | 766/896 [3:01:14<24:54, 11.50s/it] 86%|████████▌ | 767/896 [3:01:26<24:43, 11.50s/it] 86%|████████▌ | 768/896 [3:01:37<24:31, 11.49s/it] 86%|████████▌ | 769/896 [3:01:49<24:20, 11.50s/it] 86%|████████▌ | 770/896 [3:02:00<24:08, 11.49s/it] 86%|████████▌ | 771/896 [3:02:12<23:56, 11.49s/it] 86%|████████▌ | 772/896 [3:02:23<23:45, 11.49s/it] 86%|████████▋ | 773/896 [3:02:35<23:34, 11.50s/it] 86%|████████▋ | 774/896 [3:02:46<23:23, 11.51s/it] 86%|████████▋ | 775/896 [3:02:58<23:11, 11.50s/it] 87%|████████▋ | 776/896 [3:03:09<22:59, 11.50s/it] 87%|████████▋ | 777/896 [3:03:21<22:47, 11.49s/it] 87%|████████▋ | 778/896 [3:03:32<22:35, 11.48s/it] 87%|████████▋ | 779/896 [3:03:44<22:23, 11.49s/it] 87%|████████▋ | 780/896 [3:03:55<22:16, 11.52s/it] 87%|████████▋ | 781/896 [3:04:07<22:04, 11.52s/it] 87%|████████▋ | 782/896 [3:04:18<21:52, 11.51s/it] 87%|████████▋ | 783/896 [3:04:30<21:40, 11.51s/it] 88%|████████▊ | 784/896 [3:04:41<21:28, 11.51s/it] 88%|████████▊ | 785/896 [3:04:53<21:16, 11.50s/it] 88%|████████▊ | 786/896 [3:05:04<21:04, 11.49s/it] 88%|████████▊ | 787/896 [3:05:16<20:53, 11.50s/it][INFO|trainer.py:749] 2023-08-04 01:57:41,843 >> The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: sentence, context, id. If sentence, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3083] 2023-08-04 01:57:41,845 >> ***** Running Evaluation *****
[INFO|trainer.py:3085] 2023-08-04 01:57:41,846 >>   Num examples = 400
[INFO|trainer.py:3088] 2023-08-04 01:57:41,846 >>   Batch size = 8
{'eval_loss': 0.0008547091274522245, 'eval_accuracy': 1.0, 'eval_runtime': 25.3995, 'eval_samples_per_second': 15.748, 'eval_steps_per_second': 1.969, 'epoch': 13.0}

  0%|          | 0/50 [00:00<?, ?it/s][A
  4%|▍         | 2/50 [00:00<00:12,  3.96it/s][A
  6%|▌         | 3/50 [00:01<00:16,  2.80it/s][A
  8%|▊         | 4/50 [00:01<00:18,  2.42it/s][A
 10%|█         | 5/50 [00:02<00:20,  2.25it/s][A
 12%|█▏        | 6/50 [00:02<00:20,  2.15it/s][A
 14%|█▍        | 7/50 [00:03<00:20,  2.09it/s][A
 16%|█▌        | 8/50 [00:03<00:20,  2.05it/s][A
 18%|█▊        | 9/50 [00:04<00:20,  2.03it/s][A
 20%|██        | 10/50 [00:04<00:19,  2.01it/s][A
 22%|██▏       | 11/50 [00:05<00:19,  2.00it/s][A
 24%|██▍       | 12/50 [00:05<00:19,  1.99it/s][A
 26%|██▌       | 13/50 [00:06<00:18,  1.98it/s][A
 28%|██▊       | 14/50 [00:06<00:18,  1.98it/s][A
 30%|███       | 15/50 [00:07<00:17,  1.98it/s][A
 32%|███▏      | 16/50 [00:07<00:17,  1.98it/s][A
 34%|███▍      | 17/50 [00:08<00:16,  1.98it/s][A
 36%|███▌      | 18/50 [00:08<00:16,  1.97it/s][A
 38%|███▊      | 19/50 [00:09<00:15,  1.97it/s][A
 40%|████      | 20/50 [00:09<00:15,  1.98it/s][A
 42%|████▏     | 21/50 [00:10<00:14,  1.98it/s][A
 44%|████▍     | 22/50 [00:10<00:14,  1.98it/s][A
 46%|████▌     | 23/50 [00:11<00:13,  1.97it/s][A
 48%|████▊     | 24/50 [00:11<00:13,  1.97it/s][A
 50%|█████     | 25/50 [00:12<00:12,  1.97it/s][A
 52%|█████▏    | 26/50 [00:12<00:12,  1.97it/s][A
 54%|█████▍    | 27/50 [00:13<00:11,  1.97it/s][A
 56%|█████▌    | 28/50 [00:13<00:11,  1.97it/s][A
 58%|█████▊    | 29/50 [00:14<00:10,  1.97it/s][A
 60%|██████    | 30/50 [00:14<00:10,  1.97it/s][A
 62%|██████▏   | 31/50 [00:15<00:09,  1.97it/s][A
 64%|██████▍   | 32/50 [00:15<00:09,  1.97it/s][A
 66%|██████▌   | 33/50 [00:16<00:08,  1.97it/s][A
 68%|██████▊   | 34/50 [00:16<00:08,  1.97it/s][A
 70%|███████   | 35/50 [00:17<00:07,  1.97it/s][A
 72%|███████▏  | 36/50 [00:17<00:07,  1.97it/s][A
 74%|███████▍  | 37/50 [00:18<00:06,  1.97it/s][A
 76%|███████▌  | 38/50 [00:18<00:06,  1.98it/s][A
 78%|███████▊  | 39/50 [00:19<00:05,  1.98it/s][A
 80%|████████  | 40/50 [00:19<00:05,  1.98it/s][A
 82%|████████▏ | 41/50 [00:20<00:04,  1.97it/s][A
 84%|████████▍ | 42/50 [00:20<00:04,  1.97it/s][A
 86%|████████▌ | 43/50 [00:21<00:03,  1.97it/s][A
 88%|████████▊ | 44/50 [00:21<00:03,  1.97it/s][A
 90%|█████████ | 45/50 [00:22<00:02,  1.97it/s][A
 92%|█████████▏| 46/50 [00:22<00:02,  1.97it/s][A
 94%|█████████▍| 47/50 [00:23<00:01,  1.98it/s][A
 96%|█████████▌| 48/50 [00:23<00:01,  1.98it/s][A
 98%|█████████▊| 49/50 [00:24<00:00,  1.98it/s][A
100%|██████████| 50/50 [00:24<00:00,  1.98it/s][A                                                   
                                               [A 88%|████████▊ | 787/896 [3:05:47<20:53, 11.50s/it]
100%|██████████| 50/50 [00:24<00:00,  1.98it/s][A
                                               [A[INFO|trainer.py:2809] 2023-08-04 01:58:07,229 >> Saving model checkpoint to ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-787
[INFO|configuration_utils.py:460] 2023-08-04 01:58:07,232 >> Configuration saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-787/config.json
[INFO|modeling_utils.py:1874] 2023-08-04 01:59:13,097 >> Model weights saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-787/pytorch_model.bin
[INFO|tokenization_utils_base.py:2227] 2023-08-04 01:59:13,517 >> tokenizer config file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-787/tokenizer_config.json
[INFO|tokenization_utils_base.py:2234] 2023-08-04 01:59:13,669 >> Special tokens file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-787/special_tokens_map.json
 88%|████████▊ | 788/896 [3:08:21<1:54:24, 63.56s/it] 88%|████████▊ | 789/896 [3:08:32<1:25:25, 47.90s/it] 88%|████████▊ | 790/896 [3:08:44<1:05:15, 36.94s/it] 88%|████████▊ | 791/896 [3:08:55<51:14, 29.28s/it]   88%|████████▊ | 792/896 [3:09:06<41:28, 23.93s/it] 89%|████████▊ | 793/896 [3:09:18<34:38, 20.18s/it] 89%|████████▊ | 794/896 [3:09:29<29:50, 17.56s/it] 89%|████████▊ | 795/896 [3:09:41<26:28, 15.73s/it] 89%|████████▉ | 796/896 [3:09:52<24:04, 14.45s/it] 89%|████████▉ | 797/896 [3:10:04<22:22, 13.56s/it] 89%|████████▉ | 798/896 [3:10:15<21:08, 12.94s/it] 89%|████████▉ | 799/896 [3:10:27<20:13, 12.51s/it] 89%|████████▉ | 800/896 [3:10:38<19:32, 12.21s/it] 89%|████████▉ | 801/896 [3:10:50<19:00, 12.00s/it] 90%|████████▉ | 802/896 [3:11:01<18:34, 11.86s/it] 90%|████████▉ | 803/896 [3:11:13<18:13, 11.75s/it] 90%|████████▉ | 804/896 [3:11:24<17:53, 11.67s/it] 90%|████████▉ | 805/896 [3:11:36<17:38, 11.63s/it] 90%|████████▉ | 806/896 [3:11:47<17:23, 11.59s/it] 90%|█████████ | 807/896 [3:11:59<17:09, 11.57s/it] 90%|█████████ | 808/896 [3:12:10<16:56, 11.55s/it] 90%|█████████ | 809/896 [3:12:22<16:44, 11.54s/it] 90%|█████████ | 810/896 [3:12:33<16:31, 11.53s/it] 91%|█████████ | 811/896 [3:12:45<16:19, 11.52s/it] 91%|█████████ | 812/896 [3:12:56<16:07, 11.52s/it] 91%|█████████ | 813/896 [3:13:08<15:56, 11.52s/it] 91%|█████████ | 814/896 [3:13:19<15:44, 11.52s/it] 91%|█████████ | 815/896 [3:13:31<15:32, 11.52s/it] 91%|█████████ | 816/896 [3:13:42<15:20, 11.51s/it] 91%|█████████ | 817/896 [3:13:54<15:09, 11.51s/it] 91%|█████████▏| 818/896 [3:14:05<14:58, 11.51s/it] 91%|█████████▏| 819/896 [3:14:17<14:45, 11.51s/it] 92%|█████████▏| 820/896 [3:14:28<14:34, 11.51s/it] 92%|█████████▏| 821/896 [3:14:40<14:23, 11.51s/it] 92%|█████████▏| 822/896 [3:14:51<14:11, 11.51s/it] 92%|█████████▏| 823/896 [3:15:03<13:59, 11.51s/it] 92%|█████████▏| 824/896 [3:15:14<13:48, 11.51s/it] 92%|█████████▏| 825/896 [3:15:26<13:36, 11.50s/it] 92%|█████████▏| 826/896 [3:15:37<13:25, 11.51s/it] 92%|█████████▏| 827/896 [3:15:49<13:14, 11.51s/it] 92%|█████████▏| 828/896 [3:16:00<13:02, 11.50s/it] 93%|█████████▎| 829/896 [3:16:12<12:51, 11.51s/it] 93%|█████████▎| 830/896 [3:16:23<12:39, 11.51s/it] 93%|█████████▎| 831/896 [3:16:35<12:27, 11.51s/it] 93%|█████████▎| 832/896 [3:16:47<12:16, 11.51s/it] 93%|█████████▎| 833/896 [3:16:58<12:04, 11.50s/it] 93%|█████████▎| 834/896 [3:17:09<11:53, 11.50s/it] 93%|█████████▎| 835/896 [3:17:21<11:41, 11.50s/it] 93%|█████████▎| 836/896 [3:17:32<11:29, 11.50s/it] 93%|█████████▎| 837/896 [3:17:44<11:18, 11.50s/it] 94%|█████████▎| 838/896 [3:17:55<11:06, 11.50s/it] 94%|█████████▎| 839/896 [3:18:07<10:55, 11.49s/it] 94%|█████████▍| 840/896 [3:18:18<10:43, 11.50s/it] 94%|█████████▍| 841/896 [3:18:30<10:32, 11.50s/it] 94%|█████████▍| 842/896 [3:18:41<10:20, 11.49s/it] 94%|█████████▍| 843/896 [3:18:53<10:09, 11.50s/it][INFO|trainer.py:749] 2023-08-04 02:11:21,904 >> The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: sentence, context, id. If sentence, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3083] 2023-08-04 02:11:21,906 >> ***** Running Evaluation *****
[INFO|trainer.py:3085] 2023-08-04 02:11:21,906 >>   Num examples = 400
[INFO|trainer.py:3088] 2023-08-04 02:11:21,906 >>   Batch size = 8
{'eval_loss': 0.002548997290432453, 'eval_accuracy': 0.9975, 'eval_runtime': 25.3664, 'eval_samples_per_second': 15.769, 'eval_steps_per_second': 1.971, 'epoch': 13.99}

  0%|          | 0/50 [00:00<?, ?it/s][A
  4%|▍         | 2/50 [00:00<00:12,  3.94it/s][A
  6%|▌         | 3/50 [00:01<00:16,  2.79it/s][A
  8%|▊         | 4/50 [00:01<00:19,  2.41it/s][A
 10%|█         | 5/50 [00:02<00:20,  2.24it/s][A
 12%|█▏        | 6/50 [00:02<00:20,  2.14it/s][A
 14%|█▍        | 7/50 [00:03<00:20,  2.09it/s][A
 16%|█▌        | 8/50 [00:03<00:20,  2.05it/s][A
 18%|█▊        | 9/50 [00:04<00:20,  2.02it/s][A
 20%|██        | 10/50 [00:04<00:19,  2.01it/s][A
 22%|██▏       | 11/50 [00:05<00:19,  1.99it/s][A
 24%|██▍       | 12/50 [00:05<00:19,  1.99it/s][A
 26%|██▌       | 13/50 [00:06<00:18,  1.98it/s][A
 28%|██▊       | 14/50 [00:06<00:18,  1.98it/s][A
 30%|███       | 15/50 [00:07<00:17,  1.97it/s][A
 32%|███▏      | 16/50 [00:07<00:17,  1.97it/s][A
 34%|███▍      | 17/50 [00:08<00:16,  1.97it/s][A
 36%|███▌      | 18/50 [00:08<00:16,  1.97it/s][A
 38%|███▊      | 19/50 [00:09<00:15,  1.98it/s][A
 40%|████      | 20/50 [00:09<00:15,  1.98it/s][A
 42%|████▏     | 21/50 [00:10<00:14,  1.98it/s][A
 44%|████▍     | 22/50 [00:10<00:14,  1.98it/s][A
 46%|████▌     | 23/50 [00:11<00:13,  1.97it/s][A
 48%|████▊     | 24/50 [00:11<00:13,  1.97it/s][A
 50%|█████     | 25/50 [00:12<00:12,  1.97it/s][A
 52%|█████▏    | 26/50 [00:12<00:12,  1.97it/s][A
 54%|█████▍    | 27/50 [00:13<00:11,  1.97it/s][A
 56%|█████▌    | 28/50 [00:13<00:11,  1.97it/s][A
 58%|█████▊    | 29/50 [00:14<00:10,  1.97it/s][A
 60%|██████    | 30/50 [00:14<00:10,  1.97it/s][A
 62%|██████▏   | 31/50 [00:15<00:09,  1.97it/s][A
 64%|██████▍   | 32/50 [00:15<00:09,  1.97it/s][A
 66%|██████▌   | 33/50 [00:16<00:08,  1.97it/s][A
 68%|██████▊   | 34/50 [00:16<00:08,  1.97it/s][A
 70%|███████   | 35/50 [00:17<00:07,  1.97it/s][A
 72%|███████▏  | 36/50 [00:17<00:07,  1.97it/s][A
 74%|███████▍  | 37/50 [00:18<00:06,  1.97it/s][A
 76%|███████▌  | 38/50 [00:18<00:06,  1.97it/s][A
 78%|███████▊  | 39/50 [00:19<00:05,  1.97it/s][A
 80%|████████  | 40/50 [00:19<00:05,  1.97it/s][A
 82%|████████▏ | 41/50 [00:20<00:04,  1.97it/s][A
 84%|████████▍ | 42/50 [00:20<00:04,  1.97it/s][A
 86%|████████▌ | 43/50 [00:21<00:03,  1.97it/s][A
 88%|████████▊ | 44/50 [00:21<00:03,  1.97it/s][A
 90%|█████████ | 45/50 [00:22<00:02,  1.97it/s][A
 92%|█████████▏| 46/50 [00:22<00:02,  1.97it/s][A
 94%|█████████▍| 47/50 [00:23<00:01,  1.97it/s][A
 96%|█████████▌| 48/50 [00:23<00:01,  1.97it/s][A
 98%|█████████▊| 49/50 [00:24<00:00,  1.97it/s][A
100%|██████████| 50/50 [00:24<00:00,  1.97it/s][A                                                   
                                               [A 94%|█████████▍| 843/896 [3:19:28<10:09, 11.50s/it]
100%|██████████| 50/50 [00:26<00:00,  1.97it/s][A
                                               [A[INFO|trainer.py:2809] 2023-08-04 02:11:48,468 >> Saving model checkpoint to ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-843
[INFO|configuration_utils.py:460] 2023-08-04 02:11:48,471 >> Configuration saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-843/config.json
[INFO|modeling_utils.py:1874] 2023-08-04 02:12:53,168 >> Model weights saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-843/pytorch_model.bin
[INFO|tokenization_utils_base.py:2227] 2023-08-04 02:12:53,172 >> tokenizer config file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-843/tokenizer_config.json
[INFO|tokenization_utils_base.py:2234] 2023-08-04 02:12:53,173 >> Special tokens file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-843/special_tokens_map.json
 94%|█████████▍| 844/896 [3:21:52<53:28, 61.70s/it] 94%|█████████▍| 845/896 [3:22:03<39:36, 46.59s/it] 94%|█████████▍| 846/896 [3:22:15<30:01, 36.03s/it] 95%|█████████▍| 847/896 [3:22:26<23:23, 28.64s/it] 95%|█████████▍| 848/896 [3:22:37<18:47, 23.48s/it] 95%|█████████▍| 849/896 [3:22:49<15:34, 19.88s/it] 95%|█████████▍| 850/896 [3:23:00<13:18, 17.35s/it] 95%|█████████▍| 851/896 [3:23:12<11:41, 15.58s/it] 95%|█████████▌| 852/896 [3:23:23<10:31, 14.35s/it] 95%|█████████▌| 853/896 [3:23:35<09:40, 13.49s/it] 95%|█████████▌| 854/896 [3:23:46<09:01, 12.88s/it] 95%|█████████▌| 855/896 [3:23:58<08:30, 12.46s/it] 96%|█████████▌| 856/896 [3:24:09<08:06, 12.16s/it] 96%|█████████▌| 857/896 [3:24:21<07:46, 11.95s/it] 96%|█████████▌| 858/896 [3:24:32<07:28, 11.81s/it] 96%|█████████▌| 859/896 [3:24:44<07:13, 11.71s/it] 96%|█████████▌| 860/896 [3:24:55<06:58, 11.64s/it] 96%|█████████▌| 861/896 [3:25:06<06:45, 11.59s/it] 96%|█████████▌| 862/896 [3:25:18<06:33, 11.56s/it] 96%|█████████▋| 863/896 [3:25:29<06:20, 11.54s/it] 96%|█████████▋| 864/896 [3:25:41<06:08, 11.53s/it] 97%|█████████▋| 865/896 [3:25:52<05:57, 11.52s/it] 97%|█████████▋| 866/896 [3:26:04<05:45, 11.52s/it] 97%|█████████▋| 867/896 [3:26:15<05:33, 11.51s/it] 97%|█████████▋| 868/896 [3:26:27<05:22, 11.51s/it] 97%|█████████▋| 869/896 [3:26:39<05:10, 11.51s/it] 97%|█████████▋| 870/896 [3:26:50<04:59, 11.51s/it] 97%|█████████▋| 871/896 [3:27:02<04:47, 11.51s/it] 97%|█████████▋| 872/896 [3:27:13<04:36, 11.51s/it] 97%|█████████▋| 873/896 [3:27:25<04:24, 11.51s/it] 98%|█████████▊| 874/896 [3:27:36<04:13, 11.50s/it] 98%|█████████▊| 875/896 [3:27:48<04:01, 11.51s/it] 98%|█████████▊| 876/896 [3:27:59<03:50, 11.51s/it] 98%|█████████▊| 877/896 [3:28:11<03:38, 11.51s/it] 98%|█████████▊| 878/896 [3:28:22<03:27, 11.50s/it] 98%|█████████▊| 879/896 [3:28:34<03:15, 11.51s/it] 98%|█████████▊| 880/896 [3:28:45<03:04, 11.50s/it] 98%|█████████▊| 881/896 [3:28:57<02:52, 11.51s/it] 98%|█████████▊| 882/896 [3:29:08<02:41, 11.50s/it] 99%|█████████▊| 883/896 [3:29:20<02:29, 11.49s/it] 99%|█████████▊| 884/896 [3:29:31<02:17, 11.50s/it] 99%|█████████▉| 885/896 [3:29:43<02:06, 11.50s/it] 99%|█████████▉| 886/896 [3:29:54<01:54, 11.50s/it] 99%|█████████▉| 887/896 [3:30:06<01:43, 11.50s/it] 99%|█████████▉| 888/896 [3:30:17<01:31, 11.50s/it] 99%|█████████▉| 889/896 [3:30:29<01:20, 11.50s/it] 99%|█████████▉| 890/896 [3:30:40<01:09, 11.50s/it] 99%|█████████▉| 891/896 [3:30:52<00:57, 11.50s/it]100%|█████████▉| 892/896 [3:31:03<00:46, 11.51s/it]100%|█████████▉| 893/896 [3:31:15<00:34, 11.51s/it]100%|█████████▉| 894/896 [3:31:26<00:23, 11.51s/it]100%|█████████▉| 895/896 [3:31:38<00:11, 11.51s/it]100%|██████████| 896/896 [3:31:49<00:00, 11.50s/it][INFO|trainer.py:749] 2023-08-04 02:24:09,401 >> The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: sentence, context, id. If sentence, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3083] 2023-08-04 02:24:09,403 >> ***** Running Evaluation *****
[INFO|trainer.py:3085] 2023-08-04 02:24:09,403 >>   Num examples = 400
[INFO|trainer.py:3088] 2023-08-04 02:24:09,403 >>   Batch size = 8
{'eval_loss': 0.0009436844848096371, 'eval_accuracy': 1.0, 'eval_runtime': 26.039, 'eval_samples_per_second': 15.362, 'eval_steps_per_second': 1.92, 'epoch': 14.99}

  0%|          | 0/50 [00:00<?, ?it/s][A
  4%|▍         | 2/50 [00:00<00:12,  3.94it/s][A
  6%|▌         | 3/50 [00:01<00:16,  2.79it/s][A
  8%|▊         | 4/50 [00:01<00:19,  2.41it/s][A
 10%|█         | 5/50 [00:02<00:20,  2.24it/s][A
 12%|█▏        | 6/50 [00:02<00:20,  2.14it/s][A
 14%|█▍        | 7/50 [00:03<00:20,  2.08it/s][A
 16%|█▌        | 8/50 [00:03<00:20,  2.05it/s][A
 18%|█▊        | 9/50 [00:04<00:20,  2.02it/s][A
 20%|██        | 10/50 [00:04<00:19,  2.01it/s][A
 22%|██▏       | 11/50 [00:05<00:19,  2.00it/s][A
 24%|██▍       | 12/50 [00:05<00:19,  1.98it/s][A
 26%|██▌       | 13/50 [00:06<00:18,  1.98it/s][A
 28%|██▊       | 14/50 [00:06<00:18,  1.98it/s][A
 30%|███       | 15/50 [00:07<00:17,  1.97it/s][A
 32%|███▏      | 16/50 [00:07<00:17,  1.97it/s][A
 34%|███▍      | 17/50 [00:08<00:16,  1.97it/s][A
 36%|███▌      | 18/50 [00:08<00:16,  1.97it/s][A
 38%|███▊      | 19/50 [00:09<00:15,  1.97it/s][A
 40%|████      | 20/50 [00:09<00:15,  1.98it/s][A
 42%|████▏     | 21/50 [00:10<00:14,  1.98it/s][A
 44%|████▍     | 22/50 [00:10<00:14,  1.98it/s][A
 46%|████▌     | 23/50 [00:11<00:13,  1.97it/s][A
 48%|████▊     | 24/50 [00:11<00:13,  1.97it/s][A
 50%|█████     | 25/50 [00:12<00:12,  1.97it/s][A
 52%|█████▏    | 26/50 [00:12<00:12,  1.97it/s][A
 54%|█████▍    | 27/50 [00:13<00:11,  1.97it/s][A
 56%|█████▌    | 28/50 [00:13<00:11,  1.97it/s][A
 58%|█████▊    | 29/50 [00:14<00:10,  1.97it/s][A
 60%|██████    | 30/50 [00:14<00:10,  1.97it/s][A
 62%|██████▏   | 31/50 [00:15<00:09,  1.97it/s][A
 64%|██████▍   | 32/50 [00:15<00:09,  1.97it/s][A
 66%|██████▌   | 33/50 [00:16<00:08,  1.97it/s][A
 68%|██████▊   | 34/50 [00:16<00:08,  1.97it/s][A
 70%|███████   | 35/50 [00:17<00:07,  1.97it/s][A
 72%|███████▏  | 36/50 [00:17<00:07,  1.97it/s][A
 74%|███████▍  | 37/50 [00:18<00:06,  1.97it/s][A
 76%|███████▌  | 38/50 [00:18<00:06,  1.97it/s][A
 78%|███████▊  | 39/50 [00:19<00:05,  1.97it/s][A
 80%|████████  | 40/50 [00:19<00:05,  1.97it/s][A
 82%|████████▏ | 41/50 [00:20<00:04,  1.97it/s][A
 84%|████████▍ | 42/50 [00:20<00:04,  1.97it/s][A
 86%|████████▌ | 43/50 [00:21<00:03,  1.97it/s][A
 88%|████████▊ | 44/50 [00:21<00:03,  1.97it/s][A
 90%|█████████ | 45/50 [00:22<00:02,  1.97it/s][A
 92%|█████████▏| 46/50 [00:22<00:02,  1.97it/s][A
 94%|█████████▍| 47/50 [00:23<00:01,  1.97it/s][A
 96%|█████████▌| 48/50 [00:23<00:01,  1.97it/s][A
 98%|█████████▊| 49/50 [00:24<00:00,  1.97it/s][A
100%|██████████| 50/50 [00:24<00:00,  1.98it/s][A                                                   
                                               [A100%|██████████| 896/896 [3:32:15<00:00, 11.50s/it]
100%|██████████| 50/50 [00:24<00:00,  1.98it/s][A
                                               [A[INFO|trainer.py:2809] 2023-08-04 02:24:34,845 >> Saving model checkpoint to ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-896
[INFO|configuration_utils.py:460] 2023-08-04 02:24:34,848 >> Configuration saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-896/config.json
[INFO|modeling_utils.py:1874] 2023-08-04 02:25:28,605 >> Model weights saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-896/pytorch_model.bin
[INFO|tokenization_utils_base.py:2227] 2023-08-04 02:25:28,635 >> tokenizer config file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-896/tokenizer_config.json
[INFO|tokenization_utils_base.py:2234] 2023-08-04 02:25:28,636 >> Special tokens file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/checkpoint-896/special_tokens_map.json
[INFO|trainer.py:1929] 2023-08-04 02:27:03,629 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 896/896 [3:34:43<00:00, 11.50s/it]100%|██████████| 896/896 [3:34:43<00:00, 14.38s/it]
[INFO|trainer.py:2809] 2023-08-04 02:27:03,641 >> Saving model checkpoint to ../../output/task1-deberta-v2-xlarge-mnli-2-final
[INFO|configuration_utils.py:460] 2023-08-04 02:27:03,644 >> Configuration saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/config.json
[INFO|modeling_utils.py:1874] 2023-08-04 02:27:39,059 >> Model weights saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/pytorch_model.bin
[INFO|tokenization_utils_base.py:2227] 2023-08-04 02:27:39,064 >> tokenizer config file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/tokenizer_config.json
[INFO|tokenization_utils_base.py:2234] 2023-08-04 02:27:39,065 >> Special tokens file saved in ../../output/task1-deberta-v2-xlarge-mnli-2-final/special_tokens_map.json
{'eval_loss': 0.0010822825133800507, 'eval_accuracy': 1.0, 'eval_runtime': 25.4339, 'eval_samples_per_second': 15.727, 'eval_steps_per_second': 1.966, 'epoch': 15.93}
{'train_runtime': 12889.7818, 'train_samples_per_second': 4.469, 'train_steps_per_second': 0.07, 'train_loss': 0.2448975709932191, 'epoch': 15.93}
***** train metrics *****
  epoch                    =      15.93
  train_loss               =     0.2449
  train_runtime            = 3:34:49.78
  train_samples            =       3600
  train_samples_per_second =      4.469
  train_steps_per_second   =       0.07
08/04/2023 02:27:39 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:749] 2023-08-04 02:27:39,353 >> The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: sentence, context, id. If sentence, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3083] 2023-08-04 02:27:39,354 >> ***** Running Evaluation *****
[INFO|trainer.py:3085] 2023-08-04 02:27:39,354 >>   Num examples = 400
[INFO|trainer.py:3088] 2023-08-04 02:27:39,354 >>   Batch size = 8
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:11,  4.01it/s]  6%|▌         | 3/50 [00:00<00:16,  2.84it/s]  8%|▊         | 4/50 [00:01<00:18,  2.46it/s] 10%|█         | 5/50 [00:01<00:19,  2.28it/s] 12%|█▏        | 6/50 [00:02<00:20,  2.18it/s] 14%|█▍        | 7/50 [00:02<00:20,  2.12it/s] 16%|█▌        | 8/50 [00:03<00:20,  2.09it/s] 18%|█▊        | 9/50 [00:03<00:19,  2.06it/s] 20%|██        | 10/50 [00:04<00:19,  2.04it/s] 22%|██▏       | 11/50 [00:04<00:19,  2.03it/s] 24%|██▍       | 12/50 [00:05<00:18,  2.02it/s] 26%|██▌       | 13/50 [00:05<00:18,  2.01it/s] 28%|██▊       | 14/50 [00:06<00:17,  2.01it/s] 30%|███       | 15/50 [00:06<00:17,  2.00it/s] 32%|███▏      | 16/50 [00:07<00:16,  2.01it/s] 34%|███▍      | 17/50 [00:07<00:16,  2.01it/s] 36%|███▌      | 18/50 [00:08<00:15,  2.00it/s] 38%|███▊      | 19/50 [00:08<00:15,  2.00it/s] 40%|████      | 20/50 [00:09<00:14,  2.01it/s] 42%|████▏     | 21/50 [00:09<00:14,  2.01it/s] 44%|████▍     | 22/50 [00:10<00:13,  2.00it/s] 46%|████▌     | 23/50 [00:10<00:13,  2.00it/s] 48%|████▊     | 24/50 [00:11<00:13,  2.00it/s] 50%|█████     | 25/50 [00:11<00:12,  2.00it/s] 52%|█████▏    | 26/50 [00:12<00:11,  2.00it/s] 54%|█████▍    | 27/50 [00:12<00:11,  2.00it/s] 56%|█████▌    | 28/50 [00:13<00:11,  2.00it/s] 58%|█████▊    | 29/50 [00:13<00:10,  2.00it/s] 60%|██████    | 30/50 [00:14<00:10,  2.00it/s] 62%|██████▏   | 31/50 [00:14<00:09,  2.00it/s] 64%|██████▍   | 32/50 [00:15<00:09,  2.00it/s] 66%|██████▌   | 33/50 [00:15<00:08,  1.99it/s] 68%|██████▊   | 34/50 [00:16<00:08,  1.99it/s] 70%|███████   | 35/50 [00:16<00:07,  1.99it/s] 72%|███████▏  | 36/50 [00:17<00:07,  1.99it/s] 74%|███████▍  | 37/50 [00:18<00:06,  1.99it/s] 76%|███████▌  | 38/50 [00:18<00:06,  1.99it/s] 78%|███████▊  | 39/50 [00:19<00:05,  2.00it/s] 80%|████████  | 40/50 [00:19<00:05,  2.00it/s] 82%|████████▏ | 41/50 [00:20<00:04,  1.99it/s] 84%|████████▍ | 42/50 [00:20<00:04,  2.00it/s] 86%|████████▌ | 43/50 [00:21<00:03,  1.99it/s] 88%|████████▊ | 44/50 [00:21<00:03,  1.99it/s] 90%|█████████ | 45/50 [00:22<00:02,  1.99it/s] 92%|█████████▏| 46/50 [00:22<00:02,  1.99it/s] 94%|█████████▍| 47/50 [00:23<00:01,  1.99it/s] 96%|█████████▌| 48/50 [00:23<00:01,  1.99it/s] 98%|█████████▊| 49/50 [00:24<00:00,  1.99it/s]100%|██████████| 50/50 [00:24<00:00,  2.00it/s]100%|██████████| 50/50 [00:24<00:00,  2.04it/s]
[INFO|modelcard.py:452] 2023-08-04 02:28:04,588 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 1.0}]}
***** eval metrics *****
  epoch                   =      15.93
  eval_accuracy           =        1.0
  eval_loss               =     0.0011
  eval_runtime            = 0:00:25.05
  eval_samples            =        400
  eval_samples_per_second =     15.964
  eval_steps_per_second   =      1.995
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  eval/accuracy ▁▄▆▆▇▇███████████
wandb:                      eval/loss █▆▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:                   eval/runtime ▅▄▃▃▄▃▃▄▃▃▃▃▃▃█▄▁
wandb:        eval/samples_per_second ▄▅▆▆▅▆▅▅▆▆▅▅▅▆▁▅█
wandb:          eval/steps_per_second ▄▅▆▆▅▆▅▅▆▆▅▆▆▆▁▅█
wandb:                    train/epoch ▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇████
wandb:              train/global_step ▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇████
wandb:            train/learning_rate ▁
wandb:                     train/loss ▁
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                  eval/accuracy 1.0
wandb:                      eval/loss 0.00108
wandb:                   eval/runtime 25.0571
wandb:        eval/samples_per_second 15.964
wandb:          eval/steps_per_second 1.995
wandb:                    train/epoch 15.93
wandb:              train/global_step 896
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.4259
wandb:               train/total_flos 1.2144709424539238e+17
wandb:               train/train_loss 0.2449
wandb:            train/train_runtime 12889.7818
wandb: train/train_samples_per_second 4.469
wandb:   train/train_steps_per_second 0.07
wandb: 
wandb: 🚀 View run task1-deberta-v2-xlarge-mnli-2-final at: https://wandb.ai/ym_k/huggingface/runs/6izkxu5g
wandb: ️⚡ View job at https://wandb.ai/ym_k/huggingface/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjg3NzUxMjEw/version_details/v3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230803_225215-6izkxu5g/logs
